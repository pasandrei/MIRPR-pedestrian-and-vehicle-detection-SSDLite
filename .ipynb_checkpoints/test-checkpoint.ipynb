{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from architectures.backbones import MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNet.mobilenet_v2(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1280, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(1,3,512,512)\n",
    "\n",
    "# default os=32, expect 512//32 with 1280 channels output\n",
    "b = model(a)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2223872\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687680\n"
     ]
    }
   ],
   "source": [
    "model_half_width = MobileNet.mobilenet_v2(width_mult=0.5)\n",
    "total_params = sum(p.numel() for p in model_half_width.parameters())\n",
    "print(total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.2500, 0.2500],\n",
      "        [0.0000, 0.2500, 0.2500, 0.5000],\n",
      "        [0.0000, 0.5000, 0.2500, 0.7500],\n",
      "        [0.0000, 0.7500, 0.2500, 1.0000],\n",
      "        [0.2500, 0.0000, 0.5000, 0.2500],\n",
      "        [0.2500, 0.2500, 0.5000, 0.5000],\n",
      "        [0.2500, 0.5000, 0.5000, 0.7500],\n",
      "        [0.2500, 0.7500, 0.5000, 1.0000],\n",
      "        [0.5000, 0.0000, 0.7500, 0.2500],\n",
      "        [0.5000, 0.2500, 0.7500, 0.5000],\n",
      "        [0.5000, 0.5000, 0.7500, 0.7500],\n",
      "        [0.5000, 0.7500, 0.7500, 1.0000],\n",
      "        [0.7500, 0.0000, 1.0000, 0.2500],\n",
      "        [0.7500, 0.2500, 1.0000, 0.5000],\n",
      "        [0.7500, 0.5000, 1.0000, 0.7500],\n",
      "        [0.7500, 0.7500, 1.0000, 1.0000]]) torch.Size([16, 4])\n"
     ]
    }
   ],
   "source": [
    "from train.helpers import *\n",
    "\n",
    "anchors, grid_sz = create_anchors()\n",
    "anchor_cnr = hw2corners(anchors[:,:2], anchors[:,2:])\n",
    "print(anchor_cnr, anchor_cnr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlaps = jaccard(anchor_cnr[:3,:], anchor_cnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print(overlaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
      "indices=tensor([0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))\n",
      "torch.return_types.max(\n",
      "values=tensor([1., 1., 1.]),\n",
      "indices=tensor([0, 1, 2]))\n"
     ]
    }
   ],
   "source": [
    "print(overlaps.max(0))\n",
    "print(overlaps.max(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=1.61s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from data.dataloaders import get_dataloaders\n",
    "valid_dataloader = get_dataloaders()\n",
    "x, y = next(iter(valid_dataloader))\n",
    "\n",
    "def prepare_gt(y):\n",
    "    gt_bbox, gt_clas = [], []\n",
    "    for obj in y:\n",
    "        gt_bbox.append(obj['bbox'])\n",
    "        gt_clas.append(obj['category_id'])\n",
    "    return [torch.FloatTensor(gt_bbox), torch.IntTensor(gt_clas)]\n",
    "gt = prepare_gt(y)\n",
    "overlaps = jaccard(gt[0]/400, anchor_cnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5924, 0.3563, 0.0618, 0.1737],\n",
      "        [0.0176, 0.4194, 0.3733, 0.2372],\n",
      "        [1.3930, 0.5230, 0.2034, 0.1968],\n",
      "        [0.8975, 0.5451, 0.1400, 0.2571],\n",
      "        [0.7267, 0.5450, 0.1546, 0.2462],\n",
      "        [1.0330, 0.5575, 0.0754, 0.2034],\n",
      "        [0.7935, 0.5481, 0.0540, 0.0290],\n",
      "        [1.0320, 0.3940, 0.1326, 0.3450],\n",
      "        [0.9611, 0.4305, 0.0378, 0.0894],\n",
      "        [1.2805, 0.5144, 0.0368, 0.0399],\n",
      "        [1.2328, 0.4358, 0.0507, 0.2708],\n",
      "        [1.5119, 0.7647, 0.0358, 0.1143],\n",
      "        [1.5331, 0.7706, 0.0322, 0.1161],\n",
      "        [1.1194, 0.3028, 0.0349, 0.0547],\n",
      "        [1.3727, 0.7736, 0.0917, 0.2242],\n",
      "        [0.8769, 0.5221, 0.0284, 0.0564],\n",
      "        [1.0306, 0.5476, 0.0241, 0.0313],\n",
      "        [0.6031, 0.4875, 0.0356, 0.0441],\n",
      "        [0.8420, 0.4988, 0.0243, 0.0418],\n",
      "        [0.8030, 0.5781, 0.3139, 0.2223]]) torch.Size([20, 4])\n",
      "tensor([[0.0000, 0.0000, 0.2500, 0.2500],\n",
      "        [0.0000, 0.2500, 0.2500, 0.5000],\n",
      "        [0.0000, 0.5000, 0.2500, 0.7500],\n",
      "        [0.0000, 0.7500, 0.2500, 1.0000],\n",
      "        [0.2500, 0.0000, 0.5000, 0.2500],\n",
      "        [0.2500, 0.2500, 0.5000, 0.5000],\n",
      "        [0.2500, 0.5000, 0.5000, 0.7500],\n",
      "        [0.2500, 0.7500, 0.5000, 1.0000],\n",
      "        [0.5000, 0.0000, 0.7500, 0.2500],\n",
      "        [0.5000, 0.2500, 0.7500, 0.5000],\n",
      "        [0.5000, 0.5000, 0.7500, 0.7500],\n",
      "        [0.5000, 0.7500, 0.7500, 1.0000],\n",
      "        [0.7500, 0.0000, 1.0000, 0.2500],\n",
      "        [0.7500, 0.2500, 1.0000, 0.5000],\n",
      "        [0.7500, 0.5000, 1.0000, 0.7500],\n",
      "        [0.7500, 0.7500, 1.0000, 1.0000]]) torch.Size([16, 4])\n"
     ]
    }
   ],
   "source": [
    "print(gt[0]/400, gt[0].shape) \n",
    "print(anchor_cnr, anchor_cnr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]) torch.Size([20, 16])\n"
     ]
    }
   ],
   "source": [
    "print(overlaps, overlaps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt[0] = gt[0][:10,:]\n",
    "gt[1] = gt[1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = [torch.rand(16,3), torch.rand(16,4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]) torch.Size([10, 16])\n",
      "tensor(186.5933, dtype=torch.float64) tensor(19.9424)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(206.5356, dtype=torch.float64)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from train.loss_fn import *\n",
    "ssd_loss(pred,gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[153.0064,  80.8823, 198.8781,  35.6136],\n",
      "        [180.8414, 182.4262,  22.0338,  69.5659],\n",
      "        [ 10.8446, 196.4840, 187.8881, 181.4716],\n",
      "        [ 35.2291, 117.1281,  13.3889, 146.4478],\n",
      "        [168.3110,  85.3607, 106.4572,  50.5541],\n",
      "        [ 88.6454,  57.9817, 132.9944, 109.4358],\n",
      "        [ 53.2612,  36.3674,  48.3278,  85.6277],\n",
      "        [ 66.2226,  31.7417, 158.3183,  22.4716],\n",
      "        [ 60.2845, 142.4056, 140.0734,   3.2031],\n",
      "        [ 93.0411, 133.1347, 161.5353, 198.7372],\n",
      "        [ 26.2235, 184.2980, 150.0192,  86.2551],\n",
      "        [ 42.5029,  20.7951, 135.3477,  30.4437],\n",
      "        [107.6766, 179.3199,  22.5212, 163.7270],\n",
      "        [172.6823, 112.1219,  74.8049,  48.4421],\n",
      "        [ 19.8044, 169.8008,  35.1151,  18.4487],\n",
      "        [ 63.3850,  49.6614,   4.9729, 127.8176]]) torch.Size([16, 4])\n",
      "tensor([[236.9800, 142.5100,  24.7000,  69.5000],\n",
      "        [  7.0300, 167.7600, 149.3200,  94.8700],\n",
      "        [557.2100, 209.1900,  81.3500,  78.7300],\n",
      "        [358.9800, 218.0500,  56.0000, 102.8300],\n",
      "        [290.6900, 218.0000,  61.8300,  98.4800],\n",
      "        [413.2000, 223.0100,  30.1700,  81.3600],\n",
      "        [317.4000, 219.2400,  21.5800,  11.5900],\n",
      "        [412.8000, 157.6100,  53.0500, 138.0100],\n",
      "        [384.4300, 172.2100,  15.1200,  35.7400],\n",
      "        [512.2200, 205.7500,  14.7400,  15.9700],\n",
      "        [493.1000, 174.3400,  20.2900, 108.3100],\n",
      "        [604.7700, 305.8900,  14.3400,  45.7100],\n",
      "        [613.2400, 308.2400,  12.8800,  46.4400],\n",
      "        [447.7700, 121.1200,  13.9700,  21.8800],\n",
      "        [549.0600, 309.4300,  36.6800,  89.6700],\n",
      "        [350.7600, 208.8400,  11.3700,  22.5500],\n",
      "        [412.2500, 219.0200,   9.6300,  12.5200],\n",
      "        [241.2400, 194.9900,  14.2200,  17.6300],\n",
      "        [336.7900, 199.5000,   9.7300,  16.7300],\n",
      "        [321.2100, 231.2200, 125.5600,  88.9300]]) torch.Size([20, 4])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(16,4) * 200\n",
    "b = gt[0]\n",
    "print(a, a.shape)\n",
    "print(b, b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap = jaccard(anchor_cnr,anchor_cnr+0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0870, 0.4706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0870, 0.4706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0870, 0.4706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0870, 0.0000, 0.0000, 0.0000, 0.4706, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0204, 0.0870, 0.0000, 0.0000, 0.0870, 0.4706, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0204, 0.0870, 0.0000, 0.0000, 0.0870, 0.4706, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0204, 0.0870, 0.0000, 0.0000, 0.0870, 0.4706, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0870, 0.0000, 0.0000, 0.0000, 0.4706,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0204, 0.0870, 0.0000, 0.0000, 0.0870,\n",
      "         0.4706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0204, 0.0870, 0.0000, 0.0000,\n",
      "         0.0870, 0.4706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0204, 0.0870, 0.0000,\n",
      "         0.0000, 0.0870, 0.4706, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0870,\n",
      "         0.0000, 0.0000, 0.0000, 0.4706, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0204,\n",
      "         0.0870, 0.0000, 0.0000, 0.0870, 0.4706, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0204, 0.0870, 0.0000, 0.0000, 0.0870, 0.4706, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0204, 0.0870, 0.0000, 0.0000, 0.0870, 0.4706]]) torch.Size([16, 16])\n"
     ]
    }
   ],
   "source": [
    "print(overlap, overlap.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.2500, 0.2500],\n",
      "        [0.0000, 0.2500, 0.2500, 0.5000],\n",
      "        [0.0000, 0.5000, 0.2500, 0.7500],\n",
      "        [0.0000, 0.7500, 0.2500, 1.0000],\n",
      "        [0.2500, 0.0000, 0.5000, 0.2500],\n",
      "        [0.2500, 0.2500, 0.5000, 0.5000],\n",
      "        [0.2500, 0.5000, 0.5000, 0.7500],\n",
      "        [0.2500, 0.7500, 0.5000, 1.0000],\n",
      "        [0.5000, 0.0000, 0.7500, 0.2500],\n",
      "        [0.5000, 0.2500, 0.7500, 0.5000],\n",
      "        [0.5000, 0.5000, 0.7500, 0.7500],\n",
      "        [0.5000, 0.7500, 0.7500, 1.0000],\n",
      "        [0.7500, 0.0000, 1.0000, 0.2500],\n",
      "        [0.7500, 0.2500, 1.0000, 0.5000],\n",
      "        [0.7500, 0.5000, 1.0000, 0.7500],\n",
      "        [0.7500, 0.7500, 1.0000, 1.0000]]) tensor([[0.0500, 0.0500, 0.3000, 0.3000],\n",
      "        [0.0500, 0.3000, 0.3000, 0.5500],\n",
      "        [0.0500, 0.5500, 0.3000, 0.8000],\n",
      "        [0.0500, 0.8000, 0.3000, 1.0500],\n",
      "        [0.3000, 0.0500, 0.5500, 0.3000],\n",
      "        [0.3000, 0.3000, 0.5500, 0.5500],\n",
      "        [0.3000, 0.5500, 0.5500, 0.8000],\n",
      "        [0.3000, 0.8000, 0.5500, 1.0500],\n",
      "        [0.5500, 0.0500, 0.8000, 0.3000],\n",
      "        [0.5500, 0.3000, 0.8000, 0.5500],\n",
      "        [0.5500, 0.5500, 0.8000, 0.8000],\n",
      "        [0.5500, 0.8000, 0.8000, 1.0500],\n",
      "        [0.8000, 0.0500, 1.0500, 0.3000],\n",
      "        [0.8000, 0.3000, 1.0500, 0.5500],\n",
      "        [0.8000, 0.5500, 1.0500, 0.8000],\n",
      "        [0.8000, 0.8000, 1.0500, 1.0500]])\n"
     ]
    }
   ],
   "source": [
    "print(anchor_cnr,anchor_cnr+0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=2.05s)\n",
      "creating index...\n",
      "index created!\n",
      "(640, 426)\n",
      "Epoch: 0 of 10\n",
      "Batch: 0 of 5000\n",
      "Batch_loss: 104.55514112706297\n",
      "(640, 426)\n",
      "Model saved succesfully\n"
     ]
    }
   ],
   "source": [
    "import main\n",
    "main.run('misc/experiments/ssdnet/params.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=1.22s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "from architectures.models import SSDNet\n",
    "from data import dataloaders\n",
    "model = SSDNet.SSD_Head()\n",
    "train_loader, valid_loader = dataloaders.get_dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 426)\n",
      "<built-in method size of Tensor object at 0x000001970503C688>\n"
     ]
    }
   ],
   "source": [
    "from train.helpers import *\n",
    "x, y = next(iter(valid_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0386, 0.1631, 0.3703, 0.3345],\n",
       "          [0.0110, 0.2227, 0.2333, 0.3938],\n",
       "          [0.1271, 0.1848, 0.8706, 0.4911],\n",
       "          [0.0875, 0.2414, 0.5609, 0.5119],\n",
       "          [0.0966, 0.2312, 0.4542, 0.5117],\n",
       "          [0.0471, 0.1910, 0.6456, 0.5235],\n",
       "          [0.0337, 0.0272, 0.4959, 0.5146],\n",
       "          [0.0829, 0.3240, 0.6450, 0.3700],\n",
       "          [0.0236, 0.0839, 0.6007, 0.4042],\n",
       "          [0.0230, 0.0375, 0.8003, 0.4830],\n",
       "          [0.0317, 0.2542, 0.7705, 0.4092],\n",
       "          [0.0224, 0.1073, 0.9450, 0.7181],\n",
       "          [0.0201, 0.1090, 0.9582, 0.7236],\n",
       "          [0.0218, 0.0514, 0.6996, 0.2843],\n",
       "          [0.0573, 0.2105, 0.8579, 0.7264],\n",
       "          [0.0178, 0.0529, 0.5481, 0.4902],\n",
       "          [0.0150, 0.0294, 0.6441, 0.5141],\n",
       "          [0.0222, 0.0414, 0.3769, 0.4577],\n",
       "          [0.0152, 0.0393, 0.5262, 0.4683],\n",
       "          [0.1962, 0.2088, 0.5019, 0.5428]]]), torch.Size([1, 20, 4]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt[0], gt[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 224, 224]), torch.Size([16, 4]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, anchor_cnr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlaps = jaccard(gt[0].squeeze(), anchor_cnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.8183e-01, 1.7610e-01, 0.0000e+00, 0.0000e+00, 9.5932e-02, 9.3126e-02,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [6.4249e-02, 4.6626e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [2.8388e-02, 1.1368e-01, 0.0000e+00, 0.0000e+00, 5.9499e-02, 2.6209e-01,\n",
       "          0.0000e+00, 0.0000e+00, 5.9499e-02, 2.6209e-01, 0.0000e+00, 0.0000e+00,\n",
       "          2.7854e-02, 1.1137e-01, 0.0000e+00, 0.0000e+00],\n",
       "         [7.4015e-03, 2.7098e-01, 1.0213e-02, 0.0000e+00, 1.1433e-02, 4.8812e-01,\n",
       "          1.5799e-02, 0.0000e+00, 2.7614e-03, 8.6852e-02, 3.8037e-03, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [1.8055e-02, 3.0806e-01, 1.1180e-02, 0.0000e+00, 2.4181e-02, 4.5672e-01,\n",
       "          1.4939e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [4.7976e-02, 2.4060e-01, 1.8567e-02, 0.0000e+00, 5.9791e-02, 3.1407e-01,\n",
       "          2.2980e-02, 0.0000e+00, 3.3980e-02, 1.6174e-01, 1.3259e-02, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [2.0109e-01, 2.3133e-01, 1.1130e-02, 0.0000e+00, 2.3515e-01, 2.7167e-01,\n",
       "          1.2676e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 9.5305e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4965e-01,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 8.1666e-02, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [1.7926e-01, 1.6437e-01, 0.0000e+00, 0.0000e+00, 2.0175e-01, 1.8469e-01,\n",
       "          0.0000e+00, 0.0000e+00, 7.2503e-02, 6.6982e-02, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [1.3378e-01, 1.4858e-01, 0.0000e+00, 0.0000e+00, 1.4938e-01, 1.6616e-01,\n",
       "          0.0000e+00, 0.0000e+00, 1.4938e-01, 1.6616e-01, 0.0000e+00, 0.0000e+00,\n",
       "          2.6875e-02, 2.9540e-02, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 2.3633e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8027e-01,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8027e-01, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 1.8251e-02, 0.0000e+00, 0.0000e+00],\n",
       "         [5.4725e-02, 9.9989e-02, 8.6111e-02, 0.0000e+00, 6.0438e-02, 1.1092e-01,\n",
       "          9.5397e-02, 0.0000e+00, 6.0438e-02, 1.1092e-01, 9.5397e-02, 0.0000e+00,\n",
       "          4.6511e-02, 8.4438e-02, 7.2861e-02, 0.0000e+00],\n",
       "         [5.3429e-02, 9.8825e-02, 8.7462e-02, 0.0000e+00, 5.8380e-02, 1.0841e-01,\n",
       "          9.5854e-02, 0.0000e+00, 5.8380e-02, 1.0841e-01, 9.5854e-02, 0.0000e+00,\n",
       "          4.8146e-02, 8.8674e-02, 7.8563e-02, 0.0000e+00],\n",
       "         [2.5888e-01, 3.6838e-02, 0.0000e+00, 0.0000e+00, 2.9085e-01, 4.0505e-02,\n",
       "          0.0000e+00, 0.0000e+00, 2.1940e-01, 3.2084e-02, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [1.6270e-02, 1.1273e-01, 1.0099e-01, 0.0000e+00, 2.1212e-02, 1.5133e-01,\n",
       "          1.3509e-01, 0.0000e+00, 2.1212e-02, 1.5133e-01, 1.3509e-01, 0.0000e+00,\n",
       "          9.0465e-03, 6.0145e-02, 5.4150e-02, 0.0000e+00],\n",
       "         [1.8407e-01, 2.3382e-01, 0.0000e+00, 0.0000e+00, 2.0098e-01, 2.5629e-01,\n",
       "          0.0000e+00, 0.0000e+00, 3.3242e-02, 4.0821e-02, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [1.6423e-01, 1.9027e-01, 9.1183e-03, 0.0000e+00, 1.7660e-01, 2.0495e-01,\n",
       "          9.7080e-03, 0.0000e+00, 9.4739e-02, 1.0873e-01, 5.5743e-03, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [2.9213e-01, 2.9051e-01, 0.0000e+00, 0.0000e+00, 1.4415e-01, 1.4345e-01,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [2.1302e-01, 2.2239e-01, 0.0000e+00, 0.0000e+00, 2.2998e-01, 2.4025e-01,\n",
       "          0.0000e+00, 0.0000e+00, 2.0014e-02, 2.0749e-02, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [1.3667e-02, 8.9002e-02, 1.4180e-02, 0.0000e+00, 6.6825e-02, 6.1209e-01,\n",
       "          6.9469e-02, 0.0000e+00, 4.7393e-04, 2.8796e-03, 4.9147e-04, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]),\n",
       " torch.Size([20, 16]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlaps, overlaps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1818)\n",
      "tensor(0.4663)\n",
      "tensor(0.2621)\n",
      "tensor(0.4881)\n",
      "tensor(0.4567)\n",
      "tensor(0.3141)\n",
      "tensor(0.2717)\n",
      "tensor(0.1497)\n",
      "tensor(0.2017)\n",
      "tensor(0.1662)\n",
      "tensor(0.2803)\n",
      "tensor(0.1109)\n",
      "tensor(0.1084)\n",
      "tensor(0.2908)\n",
      "tensor(0.1513)\n",
      "tensor(0.2563)\n",
      "tensor(0.2050)\n",
      "tensor(0.2921)\n",
      "tensor(0.2402)\n",
      "tensor(0.6121)\n"
     ]
    }
   ],
   "source": [
    "for line in overlaps:\n",
    "    print(torch.max(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.return_types.max(\n",
       " values=tensor([0.2921, 0.4663, 0.1010, 0.0000, 0.2908, 0.6121, 0.1351, 0.0000, 0.2194,\n",
       "         0.2803, 0.1351, 0.0000, 0.0481, 0.1114, 0.0786, 0.0000]),\n",
       " indices=tensor([17,  1, 14, 19, 13, 19, 14, 19, 13, 10, 14, 19, 12,  2, 12, 19])),\n",
       " torch.Size([16]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlaps.max(0), overlaps.max(0)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0693, 0.0072, 0.3586, 0.3113],\n",
       "        [0.0349, 0.2649, 0.3598, 0.5605],\n",
       "        [0.0791, 0.5525, 0.3587, 0.8196],\n",
       "        [0.0846, 0.7567, 0.3437, 1.0111],\n",
       "        [0.2952, 0.0377, 0.6299, 0.3811],\n",
       "        [0.2874, 0.3238, 0.5389, 0.5993],\n",
       "        [0.3091, 0.5242, 0.5956, 0.8185],\n",
       "        [0.2728, 0.7740, 0.6150, 1.0976],\n",
       "        [0.4841, 0.0264, 0.7930, 0.3346],\n",
       "        [0.5584, 0.3162, 0.8387, 0.6135],\n",
       "        [0.5554, 0.5268, 0.8782, 0.8677],\n",
       "        [0.5082, 0.7945, 0.7821, 1.0864],\n",
       "        [0.8036, 0.0340, 1.0770, 0.3708],\n",
       "        [0.8137, 0.2888, 1.0646, 0.5420],\n",
       "        [0.8101, 0.5385, 1.0740, 0.8475],\n",
       "        [0.7441, 0.7850, 1.0332, 1.0720]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actn_to_bb(torch.rand(16,4), anchors, 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=1.59s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from data.dataset import CocoDetection\n",
    "\n",
    "composed_transforms = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "validation_dataset = CocoDetection(root='../../COCO/val2017/val2017',\n",
    "                                          annFile='../../COCO/annotations_trainval2017/annotations/instances_val2017.json',\n",
    "                                          transform=composed_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 426)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Image' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-8df4a90b2d00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Popovici_Galea_Faraoanu\\drl_zice_ca_se_poate_schimba_DA_MA\\data\\dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;31m# bring target in correct format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepare_gt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pil_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Popovici_Galea_Faraoanu\\drl_zice_ca_se_poate_schimba_DA_MA\\train\\helpers.py\u001b[0m in \u001b[0;36mprepare_gt\u001b[1;34m(y, x)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[0mgt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgt_bbox\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIntTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgt_clas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m     \u001b[0mx_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbbox\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mnew_bbox\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Image' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "x,y = next(iter(validation_dataset))\n",
    "x.size\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
