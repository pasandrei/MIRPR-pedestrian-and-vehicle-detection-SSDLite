{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nExample usage of functionalities\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Example usage of functionalities\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nStarting point is main.run() function\\n\\n    Arguments:\\n    train_model - train model\\n    load_checkpoint - load a pretrained model\\n    validate - run evaluation\\n    cross_validate - cross validate for best nms thresold and positive confidence\\n    mixed_precision - use mixed_precision training\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Starting point is main.run() function\n",
    "\n",
    "    Arguments:\n",
    "    train_model - train model\n",
    "    load_checkpoint - load a pretrained model\n",
    "    validate - run evaluation\n",
    "    cross_validate - cross validate for best nms thresold and positive confidence\n",
    "    mixed_precision - use mixed_precision training\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer : rmsprop\n",
      "learning_rate : 0.04\n",
      "lr_policy : retina\n",
      "batch_size : 48\n",
      "mapping_threshold : 0.5\n",
      "conf_threshold : 0.1\n",
      "suppress_threshold : 0.5\n",
      "weight_decay : 4e-05\n",
      "loss_type : softmax\n",
      "use_focal_loss : 0\n",
      "use_hard_negative_mining : 1\n",
      "n_epochs : 80\n",
      "first_decay : 28\n",
      "second_decay : 51\n",
      "third_decay : 68\n",
      "decay_rate : 0.1\n",
      "freeze_backbone : 0\n",
      "zero_bn_bias_decay : 1\n",
      "input_height : 320\n",
      "input_width : 320\n",
      "warm_up : 4\n",
      "channels_list : [576, 1280, 512, 256, 256, 128]\n",
      "List of anchors per feature map cell:  [4, 6, 6, 6, 6, 6]\n",
      "Model ID:  ssdlite\n",
      "-------------------------------------------------------\n",
      "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Total number of parameters of model:  4646218\n",
      "Total number of trainable parameters of model:  4646218\n",
      "Total number of parameters given to optimizer: \n",
      "4646218\n",
      "Total number of trainable parameters given to optimizer: \n",
      "4646218\n",
      "-------------------------------------------------------\n",
      "loading annotations into memory...\n",
      "Done (t=21.38s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.75s)\n",
      "creating index...\n",
      "index created!\n",
      "Train size:  2464 118287 118287\n",
      "Val size:  105 5000 5000\n",
      "-------------------------------------------------------\n",
      "2020-08-25 11:31:17.817498\n",
      "Total number of parameters trained this epoch:  4646218\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 512.0\n",
      "2020-08-25 11:34:18.415779\n",
      "Epoch: 0 of 80\n",
      "Batch: 245 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.07541499153627612 Classification 0.3930625905027881\n",
      "Mean and max gradients over whole network:  tensor(24.9646) tensor(409.8560)\n",
      "Mean and max weights over whole network:  tensor(0.1856) tensor(0.4217)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.0010373782467532468\n",
      "2020-08-25 11:35:42.709328\n",
      "Epoch: 0 of 80\n",
      "Batch: 491 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.06146338636555323 Classification 0.13411919380914228\n",
      "Mean and max gradients over whole network:  tensor(0.6002) tensor(10.4373)\n",
      "Mean and max weights over whole network:  tensor(0.1903) tensor(0.4483)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.0020347564935064935\n",
      "2020-08-25 11:37:10.668609\n",
      "Epoch: 0 of 80\n",
      "Batch: 737 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.05891801069583996 Classification 0.11730045427474872\n",
      "Mean and max gradients over whole network:  tensor(0.4352) tensor(7.4223)\n",
      "Mean and max weights over whole network:  tensor(0.1914) tensor(0.4697)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.0030321347402597404\n",
      "2020-08-25 11:38:35.089707\n",
      "Epoch: 0 of 80\n",
      "Batch: 983 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.057090696563242574 Classification 0.11410569684292243\n",
      "Mean and max gradients over whole network:  tensor(0.3617) tensor(7.1778)\n",
      "Mean and max weights over whole network:  tensor(0.1927) tensor(0.4976)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.004029512987012987\n",
      "2020-08-25 11:40:02.941889\n",
      "Epoch: 0 of 80\n",
      "Batch: 1229 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.05579298487321794 Classification 0.1121606238812289\n",
      "Mean and max gradients over whole network:  tensor(0.4353) tensor(7.6666)\n",
      "Mean and max weights over whole network:  tensor(0.1928) tensor(0.5275)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.005026891233766234\n",
      "2020-08-25 11:41:27.453636\n",
      "Epoch: 0 of 80\n",
      "Batch: 1475 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.05387169455851966 Classification 0.11022895340350908\n",
      "Mean and max gradients over whole network:  tensor(1.5552) tensor(34.3026)\n",
      "Mean and max weights over whole network:  tensor(0.1948) tensor(0.5704)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.006024269480519481\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 256.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 128.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 64.0\n",
      "2020-08-25 11:42:53.963563\n",
      "Epoch: 0 of 80\n",
      "Batch: 1721 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.07399938073826999 Classification 0.14073558143645445\n",
      "Mean and max gradients over whole network:  tensor(0.0152) tensor(0.4595)\n",
      "Mean and max weights over whole network:  tensor(0.2143) tensor(0.6750)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.007021647727272727\n",
      "2020-08-25 11:44:18.873668\n",
      "Epoch: 0 of 80\n",
      "Batch: 1967 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.07091692754327443 Classification 0.12914526078920702\n",
      "Mean and max gradients over whole network:  tensor(0.0163) tensor(0.5063)\n",
      "Mean and max weights over whole network:  tensor(0.2196) tensor(0.7402)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.008019025974025974\n",
      "2020-08-25 11:45:43.803256\n",
      "Epoch: 0 of 80\n",
      "Batch: 2213 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.0672586723596746 Classification 0.12255569012345983\n",
      "Mean and max gradients over whole network:  tensor(0.0215) tensor(0.8648)\n",
      "Mean and max weights over whole network:  tensor(0.2202) tensor(0.7633)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00901640422077922\n",
      "2020-08-25 11:47:08.447817\n",
      "Epoch: 0 of 80\n",
      "Batch: 2459 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.06383695065732894 Classification 0.11944621199676338\n",
      "Mean and max gradients over whole network:  tensor(0.0202) tensor(0.5258)\n",
      "Mean and max weights over whole network:  tensor(0.2207) tensor(0.7886)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.010013782467532468\n",
      "Total number of parameters trained this epoch:  4646218\n",
      "2020-08-25 11:49:57.896067\n",
      "Epoch: 1 of 80\n",
      "Batch: 245 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.06288466798419229 Classification 0.11988264386892965\n",
      "Mean and max gradients over whole network:  tensor(0.0175) tensor(0.4199)\n",
      "Mean and max weights over whole network:  tensor(0.2224) tensor(0.8311)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.011027378246753249\n",
      "2020-08-25 11:51:23.337449\n",
      "Epoch: 1 of 80\n",
      "Batch: 491 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.06042366143729952 Classification 0.11713370729268081\n",
      "Mean and max gradients over whole network:  tensor(0.0173) tensor(0.4029)\n",
      "Mean and max weights over whole network:  tensor(0.2270) tensor(0.8841)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.012024756493506494\n",
      "2020-08-25 11:52:48.338000\n",
      "Epoch: 1 of 80\n",
      "Batch: 737 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.058949296107783225 Classification 0.1170330598425413\n",
      "Mean and max gradients over whole network:  tensor(0.0214) tensor(0.4860)\n",
      "Mean and max weights over whole network:  tensor(0.2307) tensor(0.9335)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.013022134740259742\n",
      "2020-08-25 11:54:13.267305\n",
      "Epoch: 1 of 80\n",
      "Batch: 983 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.05844328629211359 Classification 0.11463556024763319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean and max gradients over whole network:  tensor(0.0195) tensor(0.4427)\n",
      "Mean and max weights over whole network:  tensor(0.2348) tensor(0.9845)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.014019512987012987\n",
      "2020-08-25 11:55:37.982028\n",
      "Epoch: 1 of 80\n",
      "Batch: 1229 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.05658287223842409 Classification 0.1125029265315229\n",
      "Mean and max gradients over whole network:  tensor(0.0375) tensor(0.8065)\n",
      "Mean and max weights over whole network:  tensor(0.2387) tensor(1.0407)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.015016891233766236\n",
      "2020-08-25 11:57:03.371616\n",
      "Epoch: 1 of 80\n",
      "Batch: 1475 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.056542418432752616 Classification 0.11204308315828887\n",
      "Mean and max gradients over whole network:  tensor(0.0389) tensor(0.7805)\n",
      "Mean and max weights over whole network:  tensor(0.2427) tensor(1.0974)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.01601426948051948\n",
      "2020-08-25 11:58:30.439125\n",
      "Epoch: 1 of 80\n",
      "Batch: 1721 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.05549657960652013 Classification 0.11155426239741204\n",
      "Mean and max gradients over whole network:  tensor(0.0367) tensor(0.7762)\n",
      "Mean and max weights over whole network:  tensor(0.2462) tensor(1.1349)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.017011647727272726\n",
      "2020-08-25 11:59:56.486694\n",
      "Epoch: 1 of 80\n",
      "Batch: 1967 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.055920141458834415 Classification 0.11109148333389261\n",
      "Mean and max gradients over whole network:  tensor(0.0382) tensor(0.7131)\n",
      "Mean and max weights over whole network:  tensor(0.2520) tensor(1.2024)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.018009025974025976\n"
     ]
    }
   ],
   "source": [
    "# train from scratch\n",
    "import main\n",
    "main.run(train_model=True, load_checkpoint=False, cross_validate=False,\n",
    "        validate=False, mixed_precision=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer : sgd\n",
      "learning_rate : 0.02\n",
      "lr_policy : retina\n",
      "batch_size : 48\n",
      "mapping_threshold : 0.5\n",
      "conf_threshold : 0.1\n",
      "suppress_threshold : 0.5333333333333333\n",
      "weight_decay : 0.0002\n",
      "loss_type : softmax\n",
      "use_focal_loss : 0\n",
      "use_hard_negative_mining : 1\n",
      "n_epochs : 64\n",
      "first_decay : 22\n",
      "second_decay : 42\n",
      "third_decay : 55\n",
      "decay_rate : 0.1\n",
      "freeze_backbone : 0\n",
      "zero_bn_bias_decay : 1\n",
      "input_height : 320\n",
      "input_width : 320\n",
      "warm_up : 3\n",
      "channels_list : [576, 1280, 512, 256, 256, 128]\n",
      "List of anchors per feature map cell:  [4, 6, 6, 6, 6, 6]\n",
      "Model ID:  ssdlite\n",
      "-------------------------------------------------------\n",
      "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Model loaded successfully from epoch:  8\n",
      "Total number of parameters of model:  4646218\n",
      "Total number of trainable parameters of model:  4646218\n",
      "Total number of parameters given to optimizer: \n",
      "4646218\n",
      "Total number of trainable parameters given to optimizer: \n",
      "4646218\n",
      "-------------------------------------------------------\n",
      "loading annotations into memory...\n",
      "Done (t=20.84s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.77s)\n",
      "creating index...\n",
      "index created!\n",
      "Train size:  2464 118287 118287\n",
      "Val size:  105 5000 5000\n",
      "-------------------------------------------------------\n",
      "2020-08-23 10:25:02.672718\n",
      "Total number of parameters trained this epoch:  4646218\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "2020-08-23 10:27:55.809604\n",
      "Epoch: 8 of 64\n",
      "Batch: 245 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03634742405114135 Classification 0.0725949010672931\n",
      "Mean and max gradients over whole network:  tensor(11.7369) tensor(132.2793)\n",
      "Mean and max weights over whole network:  tensor(0.2282) tensor(0.6736)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "2020-08-23 10:29:15.922303\n",
      "Epoch: 8 of 64\n",
      "Batch: 491 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.036118800996684124 Classification 0.07219067460233926\n",
      "Mean and max gradients over whole network:  tensor(6.5951) tensor(86.2006)\n",
      "Mean and max weights over whole network:  tensor(0.2286) tensor(0.6735)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 10:30:35.208312\n",
      "Epoch: 8 of 64\n",
      "Batch: 737 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03632088568879337 Classification 0.07258307023180856\n",
      "Mean and max gradients over whole network:  tensor(5.2095) tensor(65.5140)\n",
      "Mean and max weights over whole network:  tensor(0.2290) tensor(0.6750)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 10:31:52.040358\n",
      "Epoch: 8 of 64\n",
      "Batch: 983 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03589348207280888 Classification 0.07224632424067676\n",
      "Mean and max gradients over whole network:  tensor(7.8488) tensor(93.7909)\n",
      "Mean and max weights over whole network:  tensor(0.2292) tensor(0.6756)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 10:33:10.945324\n",
      "Epoch: 8 of 64\n",
      "Batch: 1229 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.036396744017436256 Classification 0.07287161375287425\n",
      "Mean and max gradients over whole network:  tensor(5.5195) tensor(64.6864)\n",
      "Mean and max weights over whole network:  tensor(0.2296) tensor(0.6768)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 10:34:28.187473\n",
      "Epoch: 8 of 64\n",
      "Batch: 1475 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03619162398100222 Classification 0.07273273638431942\n",
      "Mean and max gradients over whole network:  tensor(6.4018) tensor(74.8117)\n",
      "Mean and max weights over whole network:  tensor(0.2299) tensor(0.6778)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "2020-08-23 10:35:46.726059\n",
      "Epoch: 8 of 64\n",
      "Batch: 1721 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03673757646020835 Classification 0.07249189826450374\n",
      "Mean and max gradients over whole network:  tensor(3.0124) tensor(38.2238)\n",
      "Mean and max weights over whole network:  tensor(0.2302) tensor(0.6779)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 10:37:05.068291\n",
      "Epoch: 8 of 64\n",
      "Batch: 1967 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.036249561280739015 Classification 0.0726701618654295\n",
      "Mean and max gradients over whole network:  tensor(2.8372) tensor(34.9304)\n",
      "Mean and max weights over whole network:  tensor(0.2305) tensor(0.6794)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 10:38:21.702595\n",
      "Epoch: 8 of 64\n",
      "Batch: 2213 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03607648841249264 Classification 0.07230321043309804\n",
      "Mean and max gradients over whole network:  tensor(3.2874) tensor(42.3353)\n",
      "Mean and max weights over whole network:  tensor(0.2308) tensor(0.6808)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 10:39:39.362769\n",
      "Epoch: 8 of 64\n",
      "Batch: 2459 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.035658866288216136 Classification 0.07195684782211696\n",
      "Mean and max gradients over whole network:  tensor(3.9037) tensor(46.2139)\n",
      "Mean and max weights over whole network:  tensor(0.2312) tensor(0.6815)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "Total number of parameters trained this epoch:  4646218\n",
      "2020-08-23 10:42:34.635174\n",
      "Epoch: 9 of 64\n",
      "Batch: 245 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.036185226627804726 Classification 0.07151851312416356\n",
      "Mean and max gradients over whole network:  tensor(3.8484) tensor(47.7302)\n",
      "Mean and max weights over whole network:  tensor(0.2314) tensor(0.6824)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 10:43:52.798074\n",
      "Epoch: 9 of 64\n",
      "Batch: 491 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03571046166990185 Classification 0.07143532381794317\n",
      "Mean and max gradients over whole network:  tensor(3.5072) tensor(40.3228)\n",
      "Mean and max weights over whole network:  tensor(0.2317) tensor(0.6835)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 10:45:11.166101\n",
      "Epoch: 9 of 64\n",
      "Batch: 737 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03567868223802507 Classification 0.07192677231177405\n",
      "Mean and max gradients over whole network:  tensor(3.3194) tensor(41.4245)\n",
      "Mean and max weights over whole network:  tensor(0.2320) tensor(0.6830)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 10:46:28.997731\n",
      "Epoch: 9 of 64\n",
      "Batch: 983 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03562955968182908 Classification 0.07191833692191416\n",
      "Mean and max gradients over whole network:  tensor(3.2741) tensor(36.7374)\n",
      "Mean and max weights over whole network:  tensor(0.2323) tensor(0.6845)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 10:47:47.110605\n",
      "Epoch: 9 of 64\n",
      "Batch: 1229 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03531282584922424 Classification 0.07116004160345409\n",
      "Mean and max gradients over whole network:  tensor(6.0950) tensor(70.9059)\n",
      "Mean and max weights over whole network:  tensor(0.2326) tensor(0.6845)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-23 10:49:04.540536\n",
      "Epoch: 9 of 64\n",
      "Batch: 1475 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03588344424276494 Classification 0.07166382195907557\n",
      "Mean and max gradients over whole network:  tensor(7.6780) tensor(110.1553)\n",
      "Mean and max weights over whole network:  tensor(0.2328) tensor(0.6859)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 10:50:23.575565\n",
      "Epoch: 9 of 64\n",
      "Batch: 1721 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03551328670849322 Classification 0.07185065956296637\n",
      "Mean and max gradients over whole network:  tensor(5.7593) tensor(66.8034)\n",
      "Mean and max weights over whole network:  tensor(0.2331) tensor(0.6872)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 10:51:42.020136\n",
      "Epoch: 9 of 64\n",
      "Batch: 1967 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03577287936315627 Classification 0.07111374371581608\n",
      "Mean and max gradients over whole network:  tensor(5.8105) tensor(66.1517)\n",
      "Mean and max weights over whole network:  tensor(0.2334) tensor(0.6877)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 10:53:01.109677\n",
      "Epoch: 9 of 64\n",
      "Batch: 2213 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03553727986972507 Classification 0.07147279888553025\n",
      "Mean and max gradients over whole network:  tensor(6.3550) tensor(76.0519)\n",
      "Mean and max weights over whole network:  tensor(0.2336) tensor(0.6876)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 10:54:19.393321\n",
      "Epoch: 9 of 64\n",
      "Batch: 2459 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03553736764119893 Classification 0.07104253451917876\n",
      "Mean and max gradients over whole network:  tensor(6.4965) tensor(80.5239)\n",
      "Mean and max weights over whole network:  tensor(0.2339) tensor(0.6883)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "Validation start...\n",
      "2020-08-23 10:54:35.450043\n",
      "Batch: 9 of 105\n",
      "Loss in the past 480 samples: Localization 0.037358342111110686 Classification 0.0712628056605657\n",
      "Batch: 19 of 105\n",
      "Loss in the past 480 samples: Localization 0.03686114350954692 Classification 0.06865257521470387\n",
      "Batch: 29 of 105\n",
      "Loss in the past 480 samples: Localization 0.037255242963631946 Classification 0.07052814066410065\n",
      "Batch: 39 of 105\n",
      "Loss in the past 480 samples: Localization 0.03374455620845159 Classification 0.06855256954828898\n",
      "Batch: 49 of 105\n",
      "Loss in the past 480 samples: Localization 0.037436788280804954 Classification 0.07317008823156357\n",
      "Batch: 59 of 105\n",
      "Loss in the past 480 samples: Localization 0.03751453012228012 Classification 0.07249470005432765\n",
      "Batch: 69 of 105\n",
      "Loss in the past 480 samples: Localization 0.03749058370788892 Classification 0.07258738974730174\n",
      "Batch: 79 of 105\n",
      "Loss in the past 480 samples: Localization 0.03829307680328687 Classification 0.07094349960486095\n",
      "Batch: 89 of 105\n",
      "Loss in the past 480 samples: Localization 0.037286821256081265 Classification 0.07203275312980016\n",
      "Batch: 99 of 105\n",
      "Loss in the past 480 samples: Localization 0.03954009811083476 Classification 0.0719530055920283\n",
      "loading annotations into memory...\n",
      "Done (t=0.82s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.35s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=28.15s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.44s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.176\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.085\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.073\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.171\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.143\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.146\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.009\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.109\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.287\n",
      "Model saved succesfully\n",
      "Model saved succesfully by loss\n",
      "Average train loss at eval start: Localization: 0.035933929644439075; Classification: 0.071976891087979\n",
      "Total number of parameters trained this epoch:  4646218\n",
      "2020-08-23 10:58:39.938041\n",
      "Epoch: 10 of 64\n",
      "Batch: 245 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.035048415162537476 Classification 0.07029175419148391\n",
      "Mean and max gradients over whole network:  tensor(7.3242) tensor(86.9864)\n",
      "Mean and max weights over whole network:  tensor(0.2343) tensor(0.6898)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 11:00:02.335768\n",
      "Epoch: 10 of 64\n",
      "Batch: 491 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03550694520436328 Classification 0.0709074770370473\n",
      "Mean and max gradients over whole network:  tensor(5.5766) tensor(64.9979)\n",
      "Mean and max weights over whole network:  tensor(0.2345) tensor(0.6904)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 11:01:25.162314\n",
      "Epoch: 10 of 64\n",
      "Batch: 737 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.0353478259207595 Classification 0.0703917875845581\n",
      "Mean and max gradients over whole network:  tensor(6.7033) tensor(79.0361)\n",
      "Mean and max weights over whole network:  tensor(0.2349) tensor(0.6914)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 11:02:46.525493\n",
      "Epoch: 10 of 64\n",
      "Batch: 983 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03512811255931531 Classification 0.07025617924405307\n",
      "Mean and max gradients over whole network:  tensor(13.8887) tensor(157.1315)\n",
      "Mean and max weights over whole network:  tensor(0.2351) tensor(0.6919)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 11:04:06.204519\n",
      "Epoch: 10 of 64\n",
      "Batch: 1229 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.0354465349781804 Classification 0.07081918400235293\n",
      "Mean and max gradients over whole network:  tensor(13.2969) tensor(172.4646)\n",
      "Mean and max weights over whole network:  tensor(0.2354) tensor(0.6927)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 11:05:22.830103\n",
      "Epoch: 10 of 64\n",
      "Batch: 1475 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03489018999908352 Classification 0.07040487296455275\n",
      "Mean and max gradients over whole network:  tensor(13.4517) tensor(178.2000)\n",
      "Mean and max weights over whole network:  tensor(0.2356) tensor(0.6941)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 11:06:42.371906\n",
      "Epoch: 10 of 64\n",
      "Batch: 1721 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03529931756296778 Classification 0.07065583977515136\n",
      "Mean and max gradients over whole network:  tensor(12.7262) tensor(144.0559)\n",
      "Mean and max weights over whole network:  tensor(0.2359) tensor(0.6943)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 11:08:01.891747\n",
      "Epoch: 10 of 64\n",
      "Batch: 1967 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.034933509855331765 Classification 0.07228025957578565\n",
      "Mean and max gradients over whole network:  tensor(13.4585) tensor(152.2272)\n",
      "Mean and max weights over whole network:  tensor(0.2362) tensor(0.6967)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 11:09:19.538954\n",
      "Epoch: 10 of 64\n",
      "Batch: 2213 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03510042409182887 Classification 0.0713074020940437\n",
      "Mean and max gradients over whole network:  tensor(15.1029) tensor(193.4284)\n",
      "Mean and max weights over whole network:  tensor(0.2365) tensor(0.6969)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-23 11:10:38.196794\n",
      "Epoch: 10 of 64\n",
      "Batch: 2459 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03537143586168121 Classification 0.0712012408306282\n",
      "Mean and max gradients over whole network:  tensor(7.9373) tensor(97.1268)\n",
      "Mean and max weights over whole network:  tensor(0.2368) tensor(0.6988)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "Total number of parameters trained this epoch:  4646218\n",
      "2020-08-23 11:13:16.725391\n",
      "Epoch: 11 of 64\n",
      "Batch: 245 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03483816470476347 Classification 0.06989639248385986\n",
      "Mean and max gradients over whole network:  tensor(7.1348) tensor(88.7532)\n",
      "Mean and max weights over whole network:  tensor(0.2371) tensor(0.6988)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 11:14:38.587833\n",
      "Epoch: 11 of 64\n",
      "Batch: 491 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.0347136288154416 Classification 0.06987451628698566\n",
      "Mean and max gradients over whole network:  tensor(7.3405) tensor(102.8666)\n",
      "Mean and max weights over whole network:  tensor(0.2374) tensor(0.6995)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 11:15:59.923387\n",
      "Epoch: 11 of 64\n",
      "Batch: 737 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.034979078333148464 Classification 0.06986021771421277\n",
      "Mean and max gradients over whole network:  tensor(7.4282) tensor(92.3352)\n",
      "Mean and max weights over whole network:  tensor(0.2377) tensor(0.7000)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 11:17:21.144854\n",
      "Epoch: 11 of 64\n",
      "Batch: 983 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03492153306721349 Classification 0.07010888928158819\n",
      "Mean and max gradients over whole network:  tensor(7.5818) tensor(102.0541)\n",
      "Mean and max weights over whole network:  tensor(0.2380) tensor(0.7008)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 11:18:41.107776\n",
      "Epoch: 11 of 64\n",
      "Batch: 1229 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03480323243553076 Classification 0.07067972106662224\n",
      "Mean and max gradients over whole network:  tensor(6.5857) tensor(72.1080)\n",
      "Mean and max weights over whole network:  tensor(0.2383) tensor(0.7012)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 11:20:01.277104\n",
      "Epoch: 11 of 64\n",
      "Batch: 1475 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.034866331352127924 Classification 0.07010110182975365\n",
      "Mean and max gradients over whole network:  tensor(6.4719) tensor(75.2551)\n",
      "Mean and max weights over whole network:  tensor(0.2386) tensor(0.7018)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 11:21:21.659545\n",
      "Epoch: 11 of 64\n",
      "Batch: 1721 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03476461181593781 Classification 0.07013142125070257\n",
      "Mean and max gradients over whole network:  tensor(7.3852) tensor(87.4263)\n",
      "Mean and max weights over whole network:  tensor(0.2389) tensor(0.7030)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 11:22:41.122974\n",
      "Epoch: 11 of 64\n",
      "Batch: 1967 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03487045732818968 Classification 0.07008852272579663\n",
      "Mean and max gradients over whole network:  tensor(12.1840) tensor(160.4864)\n",
      "Mean and max weights over whole network:  tensor(0.2391) tensor(0.7048)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "2020-08-23 11:24:00.911571\n",
      "Epoch: 11 of 64\n",
      "Batch: 2213 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03457343691409765 Classification 0.07026449554577106\n",
      "Mean and max gradients over whole network:  tensor(6.3779) tensor(70.4992)\n",
      "Mean and max weights over whole network:  tensor(0.2393) tensor(0.7061)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 11:25:21.406982\n",
      "Epoch: 11 of 64\n",
      "Batch: 2459 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03461666245689883 Classification 0.06994441385837752\n",
      "Mean and max gradients over whole network:  tensor(6.5319) tensor(76.1740)\n",
      "Mean and max weights over whole network:  tensor(0.2396) tensor(0.7066)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "Validation start...\n",
      "2020-08-23 11:25:37.627362\n",
      "Batch: 9 of 105\n",
      "Loss in the past 480 samples: Localization 0.037285977602005006 Classification 0.06994066586097082\n",
      "Batch: 19 of 105\n",
      "Loss in the past 480 samples: Localization 0.036073079456885655 Classification 0.06811717450618744\n",
      "Batch: 29 of 105\n",
      "Loss in the past 480 samples: Localization 0.03743516008059184 Classification 0.06929977138837179\n",
      "Batch: 39 of 105\n",
      "Loss in the past 480 samples: Localization 0.03396341850360234 Classification 0.06783257474501928\n",
      "Batch: 49 of 105\n",
      "Loss in the past 480 samples: Localization 0.036724974711736046 Classification 0.07139919300874074\n",
      "Batch: 59 of 105\n",
      "Loss in the past 480 samples: Localization 0.037898736695448555 Classification 0.07200132956107458\n",
      "Batch: 69 of 105\n",
      "Loss in the past 480 samples: Localization 0.03710431804259618 Classification 0.07125546038150787\n",
      "Batch: 79 of 105\n",
      "Loss in the past 480 samples: Localization 0.038782038788000746 Classification 0.07029998550812404\n",
      "Batch: 89 of 105\n",
      "Loss in the past 480 samples: Localization 0.037314414978027344 Classification 0.06971906572580337\n",
      "Batch: 99 of 105\n",
      "Loss in the past 480 samples: Localization 0.03908130849401156 Classification 0.07186119109392167\n",
      "loading annotations into memory...\n",
      "Done (t=0.78s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.34s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=27.38s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=2.99s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.094\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.183\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.088\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.078\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.175\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.110\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.148\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.152\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.011\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.125\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.291\n",
      "Model saved succesfully\n",
      "Model saved succesfully by loss\n",
      "Average train loss at eval start: Localization: 0.03499746336237096; Classification: 0.07046381108230954\n",
      "Total number of parameters trained this epoch:  4646218\n",
      "2020-08-23 11:29:54.787111\n",
      "Epoch: 12 of 64\n",
      "Batch: 245 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03442806682895193 Classification 0.06951166037217711\n",
      "Mean and max gradients over whole network:  tensor(6.4615) tensor(72.7031)\n",
      "Mean and max weights over whole network:  tensor(0.2399) tensor(0.7070)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 11:31:14.896542\n",
      "Epoch: 12 of 64\n",
      "Batch: 491 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03460603801982836 Classification 0.06914155720291422\n",
      "Mean and max gradients over whole network:  tensor(6.9856) tensor(94.2349)\n",
      "Mean and max weights over whole network:  tensor(0.2401) tensor(0.7078)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 11:32:34.785655\n",
      "Epoch: 12 of 64\n",
      "Batch: 737 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03446392667527767 Classification 0.06973338710664087\n",
      "Mean and max gradients over whole network:  tensor(8.3489) tensor(100.2942)\n",
      "Mean and max weights over whole network:  tensor(0.2404) tensor(0.7088)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-23 11:33:53.923989\n",
      "Epoch: 12 of 64\n",
      "Batch: 983 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.034604366969690735 Classification 0.06959934379188672\n",
      "Mean and max gradients over whole network:  tensor(6.0924) tensor(69.8205)\n",
      "Mean and max weights over whole network:  tensor(0.2406) tensor(0.7097)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 11:35:12.595430\n",
      "Epoch: 12 of 64\n",
      "Batch: 1229 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03474047576105045 Classification 0.06920137173599666\n",
      "Mean and max gradients over whole network:  tensor(8.3040) tensor(99.4648)\n",
      "Mean and max weights over whole network:  tensor(0.2410) tensor(0.7098)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 11:36:29.373334\n",
      "Epoch: 12 of 64\n",
      "Batch: 1475 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03449237240644974 Classification 0.06947722685773199\n",
      "Mean and max gradients over whole network:  tensor(7.0642) tensor(97.5649)\n",
      "Mean and max weights over whole network:  tensor(0.2412) tensor(0.7107)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 11:37:47.140123\n",
      "Epoch: 12 of 64\n",
      "Batch: 1721 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.034466273850461006 Classification 0.06929589892790569\n",
      "Mean and max gradients over whole network:  tensor(14.7216) tensor(185.3544)\n",
      "Mean and max weights over whole network:  tensor(0.2415) tensor(0.7107)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "2020-08-23 11:39:04.889140\n",
      "Epoch: 12 of 64\n",
      "Batch: 1967 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03441119574636302 Classification 0.06941566293236363\n",
      "Mean and max gradients over whole network:  tensor(6.2267) tensor(81.0808)\n",
      "Mean and max weights over whole network:  tensor(0.2418) tensor(0.7117)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 11:40:23.088449\n",
      "Epoch: 12 of 64\n",
      "Batch: 2213 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.034601204753487415 Classification 0.06949170442616068\n",
      "Mean and max gradients over whole network:  tensor(6.9531) tensor(86.4945)\n",
      "Mean and max weights over whole network:  tensor(0.2420) tensor(0.7120)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 11:41:41.399345\n",
      "Epoch: 12 of 64\n",
      "Batch: 2459 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.034371606632057565 Classification 0.06972057636837325\n",
      "Mean and max gradients over whole network:  tensor(7.5544) tensor(88.8333)\n",
      "Mean and max weights over whole network:  tensor(0.2422) tensor(0.7130)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "Total number of parameters trained this epoch:  4646218\n",
      "2020-08-23 11:44:22.522968\n",
      "Epoch: 13 of 64\n",
      "Batch: 245 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.033696888120678385 Classification 0.06849796755042503\n",
      "Mean and max gradients over whole network:  tensor(8.4699) tensor(100.2242)\n",
      "Mean and max weights over whole network:  tensor(0.2425) tensor(0.7148)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 11:45:42.636697\n",
      "Epoch: 13 of 64\n",
      "Batch: 491 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.0345270272172725 Classification 0.06873921018225068\n",
      "Mean and max gradients over whole network:  tensor(6.2271) tensor(71.2253)\n",
      "Mean and max weights over whole network:  tensor(0.2428) tensor(0.7153)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 11:47:03.402073\n",
      "Epoch: 13 of 64\n",
      "Batch: 737 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.0341330232618624 Classification 0.06855700782886366\n",
      "Mean and max gradients over whole network:  tensor(7.6683) tensor(90.4192)\n",
      "Mean and max weights over whole network:  tensor(0.2431) tensor(0.7151)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 11:48:23.869097\n",
      "Epoch: 13 of 64\n",
      "Batch: 983 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03417671832248447 Classification 0.06907223702123172\n",
      "Mean and max gradients over whole network:  tensor(6.9490) tensor(84.2406)\n",
      "Mean and max weights over whole network:  tensor(0.2433) tensor(0.7161)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 11:49:40.398006\n",
      "Epoch: 13 of 64\n",
      "Batch: 1229 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03427981673096254 Classification 0.06882353716587955\n",
      "Mean and max gradients over whole network:  tensor(7.2314) tensor(88.2205)\n",
      "Mean and max weights over whole network:  tensor(0.2436) tensor(0.7170)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 11:50:55.408293\n",
      "Epoch: 13 of 64\n",
      "Batch: 1475 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.034410118955745285 Classification 0.06966012118631586\n",
      "Mean and max gradients over whole network:  tensor(6.4235) tensor(74.8388)\n",
      "Mean and max weights over whole network:  tensor(0.2438) tensor(0.7176)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 11:52:10.464612\n",
      "Epoch: 13 of 64\n",
      "Batch: 1721 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03381204051861595 Classification 0.068968172379464\n",
      "Mean and max gradients over whole network:  tensor(13.2232) tensor(159.6836)\n",
      "Mean and max weights over whole network:  tensor(0.2441) tensor(0.7176)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 11:53:25.786653\n",
      "Epoch: 13 of 64\n",
      "Batch: 1967 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.034239010557249636 Classification 0.06916840525904322\n",
      "Mean and max gradients over whole network:  tensor(13.9224) tensor(161.4498)\n",
      "Mean and max weights over whole network:  tensor(0.2444) tensor(0.7184)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 11:54:41.413273\n",
      "Epoch: 13 of 64\n",
      "Batch: 2213 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.034189690883728224 Classification 0.06896603911065151\n",
      "Mean and max gradients over whole network:  tensor(11.6640) tensor(136.3303)\n",
      "Mean and max weights over whole network:  tensor(0.2446) tensor(0.7198)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 11:55:57.783423\n",
      "Epoch: 13 of 64\n",
      "Batch: 2459 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.034393849169335716 Classification 0.06930293215484154\n",
      "Mean and max gradients over whole network:  tensor(16.0981) tensor(220.1727)\n",
      "Mean and max weights over whole network:  tensor(0.2448) tensor(0.7203)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "Validation start...\n",
      "2020-08-23 11:56:12.251978\n",
      "Batch: 9 of 105\n",
      "Loss in the past 480 samples: Localization 0.03624478578567505 Classification 0.06953650961319606\n",
      "Batch: 19 of 105\n",
      "Loss in the past 480 samples: Localization 0.03532319118579229 Classification 0.06726980706055959\n",
      "Batch: 29 of 105\n",
      "Loss in the past 480 samples: Localization 0.03698226138949394 Classification 0.06906745731830596\n",
      "Batch: 39 of 105\n",
      "Loss in the past 480 samples: Localization 0.03294146607319514 Classification 0.0665831650296847\n",
      "Batch: 49 of 105\n",
      "Loss in the past 480 samples: Localization 0.03619100699822108 Classification 0.07063375413417816\n",
      "Batch: 59 of 105\n",
      "Loss in the past 480 samples: Localization 0.036545901000499724 Classification 0.07082566569248835\n",
      "Batch: 69 of 105\n",
      "Loss in the past 480 samples: Localization 0.03543984318772952 Classification 0.0700257509946823\n",
      "Batch: 79 of 105\n",
      "Loss in the past 480 samples: Localization 0.03769430244962375 Classification 0.06886127988497416\n",
      "Batch: 89 of 105\n",
      "Loss in the past 480 samples: Localization 0.03653026421864827 Classification 0.0693760668238004\n",
      "Batch: 99 of 105\n",
      "Loss in the past 480 samples: Localization 0.03763760502139727 Classification 0.07018480350573858\n",
      "loading annotations into memory...\n",
      "Done (t=0.79s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=5.07s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE (t=23.51s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=3.06s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.100\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.190\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.095\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.078\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.196\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.117\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.156\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.160\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.128\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.311\n",
      "Model saved succesfully\n",
      "Model saved succesfully by loss\n",
      "Average train loss at eval start: Localization: 0.03434620528086207; Classification: 0.0692105867315125\n",
      "Total number of parameters trained this epoch:  4646218\n",
      "2020-08-23 12:00:16.182114\n",
      "Epoch: 14 of 64\n",
      "Batch: 245 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03393501848951588 Classification 0.06815818428670165\n",
      "Mean and max gradients over whole network:  tensor(14.5443) tensor(177.6396)\n",
      "Mean and max weights over whole network:  tensor(0.2451) tensor(0.7212)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "2020-08-23 12:01:38.498476\n",
      "Epoch: 14 of 64\n",
      "Batch: 491 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.034355666740799984 Classification 0.06843085261945156\n",
      "Mean and max gradients over whole network:  tensor(7.1865) tensor(80.4385)\n",
      "Mean and max weights over whole network:  tensor(0.2453) tensor(0.7218)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 12:02:58.319671\n",
      "Epoch: 14 of 64\n",
      "Batch: 737 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03366279413262357 Classification 0.06862713471256944\n",
      "Mean and max gradients over whole network:  tensor(6.3276) tensor(72.2073)\n",
      "Mean and max weights over whole network:  tensor(0.2456) tensor(0.7216)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 12:04:16.199222\n",
      "Epoch: 14 of 64\n",
      "Batch: 983 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03398017376297858 Classification 0.06846610844377579\n",
      "Mean and max gradients over whole network:  tensor(6.9537) tensor(76.3477)\n",
      "Mean and max weights over whole network:  tensor(0.2458) tensor(0.7234)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 12:05:34.654729\n",
      "Epoch: 14 of 64\n",
      "Batch: 1229 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.033909815901178655 Classification 0.06842685064810725\n",
      "Mean and max gradients over whole network:  tensor(8.0336) tensor(95.9241)\n",
      "Mean and max weights over whole network:  tensor(0.2460) tensor(0.7254)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 12:06:53.436647\n",
      "Epoch: 14 of 64\n",
      "Batch: 1475 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.033729808975445225 Classification 0.06846582679567621\n",
      "Mean and max gradients over whole network:  tensor(6.3581) tensor(75.5164)\n",
      "Mean and max weights over whole network:  tensor(0.2463) tensor(0.7269)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 12:08:12.953022\n",
      "Epoch: 14 of 64\n",
      "Batch: 1721 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03382497921909097 Classification 0.06835465088769349\n",
      "Mean and max gradients over whole network:  tensor(6.2325) tensor(72.4679)\n",
      "Mean and max weights over whole network:  tensor(0.2465) tensor(0.7268)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 12:09:32.159078\n",
      "Epoch: 14 of 64\n",
      "Batch: 1967 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03375376508568684 Classification 0.06853863810943717\n",
      "Mean and max gradients over whole network:  tensor(6.4979) tensor(73.7114)\n",
      "Mean and max weights over whole network:  tensor(0.2468) tensor(0.7275)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 12:10:51.261304\n",
      "Epoch: 14 of 64\n",
      "Batch: 2213 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.033925038426710664 Classification 0.06826788861415574\n",
      "Mean and max gradients over whole network:  tensor(6.3565) tensor(70.8484)\n",
      "Mean and max weights over whole network:  tensor(0.2471) tensor(0.7291)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 12:12:09.507642\n",
      "Epoch: 14 of 64\n",
      "Batch: 2459 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03368070881137357 Classification 0.06876485419224918\n",
      "Mean and max gradients over whole network:  tensor(12.4618) tensor(135.9895)\n",
      "Mean and max weights over whole network:  tensor(0.2473) tensor(0.7295)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "Total number of parameters trained this epoch:  4646218\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "2020-08-23 12:14:58.276113\n",
      "Epoch: 15 of 64\n",
      "Batch: 245 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03361279327614197 Classification 0.06724184254805247\n",
      "Mean and max gradients over whole network:  tensor(6.7057) tensor(83.3021)\n",
      "Mean and max weights over whole network:  tensor(0.2476) tensor(0.7308)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 12:16:18.527225\n",
      "Epoch: 15 of 64\n",
      "Batch: 491 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03435786447025896 Classification 0.06850897839802714\n",
      "Mean and max gradients over whole network:  tensor(6.0587) tensor(68.7487)\n",
      "Mean and max weights over whole network:  tensor(0.2479) tensor(0.7320)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 12:17:37.235830\n",
      "Epoch: 15 of 64\n",
      "Batch: 737 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03381670299705451 Classification 0.06796745057432309\n",
      "Mean and max gradients over whole network:  tensor(7.4459) tensor(88.5239)\n",
      "Mean and max weights over whole network:  tensor(0.2482) tensor(0.7322)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 12:18:54.629706\n",
      "Epoch: 15 of 64\n",
      "Batch: 983 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.033147601587420236 Classification 0.06808754200050178\n",
      "Mean and max gradients over whole network:  tensor(8.3597) tensor(95.7381)\n",
      "Mean and max weights over whole network:  tensor(0.2484) tensor(0.7328)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 12:20:12.165982\n",
      "Epoch: 15 of 64\n",
      "Batch: 1229 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03364164989976702 Classification 0.06801792367444776\n",
      "Mean and max gradients over whole network:  tensor(9.1375) tensor(108.9178)\n",
      "Mean and max weights over whole network:  tensor(0.2486) tensor(0.7336)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 12:21:29.154020\n",
      "Epoch: 15 of 64\n",
      "Batch: 1475 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.033869504686293565 Classification 0.0681980578153114\n",
      "Mean and max gradients over whole network:  tensor(7.7772) tensor(93.4987)\n",
      "Mean and max weights over whole network:  tensor(0.2489) tensor(0.7342)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 12:22:44.997846\n",
      "Epoch: 15 of 64\n",
      "Batch: 1721 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03402690894316206 Classification 0.06836547052391823\n",
      "Mean and max gradients over whole network:  tensor(8.4735) tensor(107.5929)\n",
      "Mean and max weights over whole network:  tensor(0.2492) tensor(0.7359)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 12:24:01.047641\n",
      "Epoch: 15 of 64\n",
      "Batch: 1967 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.033650102956992826 Classification 0.06878166706339131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean and max gradients over whole network:  tensor(6.5964) tensor(85.4679)\n",
      "Mean and max weights over whole network:  tensor(0.2493) tensor(0.7361)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 12:25:17.401103\n",
      "Epoch: 15 of 64\n",
      "Batch: 2213 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03360665455299018 Classification 0.06824129313068984\n",
      "Mean and max gradients over whole network:  tensor(12.3454) tensor(138.7523)\n",
      "Mean and max weights over whole network:  tensor(0.2497) tensor(0.7373)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 12:26:34.879586\n",
      "Epoch: 15 of 64\n",
      "Batch: 2459 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03413717622356363 Classification 0.0682171649604955\n",
      "Mean and max gradients over whole network:  tensor(13.5423) tensor(162.7812)\n",
      "Mean and max weights over whole network:  tensor(0.2499) tensor(0.7381)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "Validation start...\n",
      "2020-08-23 12:26:49.202647\n",
      "Batch: 9 of 105\n",
      "Loss in the past 480 samples: Localization 0.03596222574512164 Classification 0.06757025967041651\n",
      "Batch: 19 of 105\n",
      "Loss in the past 480 samples: Localization 0.03475105737646421 Classification 0.06646570811669032\n",
      "Batch: 29 of 105\n",
      "Loss in the past 480 samples: Localization 0.03620361735423406 Classification 0.0679320494333903\n",
      "Batch: 39 of 105\n",
      "Loss in the past 480 samples: Localization 0.03261496648192406 Classification 0.06577519178390503\n",
      "Batch: 49 of 105\n",
      "Loss in the past 480 samples: Localization 0.03566119745373726 Classification 0.06975490897893906\n",
      "Batch: 59 of 105\n",
      "Loss in the past 480 samples: Localization 0.036216780294974646 Classification 0.069596961637338\n",
      "Batch: 69 of 105\n",
      "Loss in the past 480 samples: Localization 0.035622929533322654 Classification 0.06972921490669251\n",
      "Batch: 79 of 105\n",
      "Loss in the past 480 samples: Localization 0.037252762168645856 Classification 0.06787052104870478\n",
      "Batch: 89 of 105\n",
      "Loss in the past 480 samples: Localization 0.036198533574740094 Classification 0.06854705562194188\n",
      "Batch: 99 of 105\n",
      "Loss in the past 480 samples: Localization 0.03777741913994153 Classification 0.07009879450003306\n",
      "loading annotations into memory...\n",
      "Done (t=0.80s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.32s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=26.59s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=2.92s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.100\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.194\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.094\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.082\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.196\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.115\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.154\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.158\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.123\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.310\n",
      "Model saved succesfully\n",
      "Model saved succesfully by loss\n",
      "Average train loss at eval start: Localization: 0.03383084391493855; Classification: 0.06829825405905739\n",
      "Total number of parameters trained this epoch:  4646218\n",
      "2020-08-23 12:30:44.641457\n",
      "Epoch: 16 of 64\n",
      "Batch: 245 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03319876026210746 Classification 0.06749795478210863\n",
      "Mean and max gradients over whole network:  tensor(13.1165) tensor(155.1278)\n",
      "Mean and max weights over whole network:  tensor(0.2502) tensor(0.7397)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 12:32:02.643880\n",
      "Epoch: 16 of 64\n",
      "Batch: 491 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03331206940861575 Classification 0.06726507281223287\n",
      "Mean and max gradients over whole network:  tensor(13.9989) tensor(167.7441)\n",
      "Mean and max weights over whole network:  tensor(0.2504) tensor(0.7400)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 12:33:19.554200\n",
      "Epoch: 16 of 64\n",
      "Batch: 737 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03349207757611262 Classification 0.06744089526777991\n",
      "Mean and max gradients over whole network:  tensor(15.0283) tensor(176.6392)\n",
      "Mean and max weights over whole network:  tensor(0.2507) tensor(0.7402)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 12:34:37.890609\n",
      "Epoch: 16 of 64\n",
      "Batch: 983 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.033530689735561205 Classification 0.06803903744876547\n",
      "Mean and max gradients over whole network:  tensor(14.2149) tensor(180.3571)\n",
      "Mean and max weights over whole network:  tensor(0.2508) tensor(0.7411)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 12:35:57.108829\n",
      "Epoch: 16 of 64\n",
      "Batch: 1229 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.033359956591917574 Classification 0.06774699465853735\n",
      "Mean and max gradients over whole network:  tensor(11.5599) tensor(133.9216)\n",
      "Mean and max weights over whole network:  tensor(0.2511) tensor(0.7421)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 12:37:13.215064\n",
      "Epoch: 16 of 64\n",
      "Batch: 1475 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03396953687798686 Classification 0.06838925633084807\n",
      "Mean and max gradients over whole network:  tensor(12.6138) tensor(133.7542)\n",
      "Mean and max weights over whole network:  tensor(0.2513) tensor(0.7425)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "2020-08-23 12:38:28.147655\n",
      "Epoch: 16 of 64\n",
      "Batch: 1721 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.033520472829096364 Classification 0.06823687334128511\n",
      "Mean and max gradients over whole network:  tensor(7.1081) tensor(85.7372)\n",
      "Mean and max weights over whole network:  tensor(0.2515) tensor(0.7429)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 12:39:42.297111\n",
      "Epoch: 16 of 64\n",
      "Batch: 1967 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03378986612689204 Classification 0.0682312075886623\n",
      "Mean and max gradients over whole network:  tensor(7.5004) tensor(87.0331)\n",
      "Mean and max weights over whole network:  tensor(0.2518) tensor(0.7431)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 12:40:56.355485\n",
      "Epoch: 16 of 64\n",
      "Batch: 2213 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.033534799790802365 Classification 0.06773726149464687\n",
      "Mean and max gradients over whole network:  tensor(7.2563) tensor(82.1417)\n",
      "Mean and max weights over whole network:  tensor(0.2520) tensor(0.7454)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 12:42:09.885725\n",
      "Epoch: 16 of 64\n",
      "Batch: 2459 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.0333944319729721 Classification 0.06779982321226823\n",
      "Mean and max gradients over whole network:  tensor(6.9441) tensor(74.1386)\n",
      "Mean and max weights over whole network:  tensor(0.2523) tensor(0.7453)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "Total number of parameters trained this epoch:  4646218\n",
      "2020-08-23 12:44:45.676636\n",
      "Epoch: 17 of 64\n",
      "Batch: 245 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.033323683733054936 Classification 0.06724257347221943\n",
      "Mean and max gradients over whole network:  tensor(7.3972) tensor(100.9326)\n",
      "Mean and max weights over whole network:  tensor(0.2525) tensor(0.7462)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 12:46:03.190340\n",
      "Epoch: 17 of 64\n",
      "Batch: 491 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03340113594078113 Classification 0.06739649063526454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean and max gradients over whole network:  tensor(7.3857) tensor(89.8615)\n",
      "Mean and max weights over whole network:  tensor(0.2527) tensor(0.7469)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 12:47:21.170962\n",
      "Epoch: 17 of 64\n",
      "Batch: 737 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03340692638462475 Classification 0.06734623519708793\n",
      "Mean and max gradients over whole network:  tensor(7.4254) tensor(86.4435)\n",
      "Mean and max weights over whole network:  tensor(0.2529) tensor(0.7482)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 12:48:39.284024\n",
      "Epoch: 17 of 64\n",
      "Batch: 983 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03334988183203105 Classification 0.06747452726935953\n",
      "Mean and max gradients over whole network:  tensor(8.0095) tensor(90.0713)\n",
      "Mean and max weights over whole network:  tensor(0.2531) tensor(0.7480)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 12:49:56.972700\n",
      "Epoch: 17 of 64\n",
      "Batch: 1229 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03329480272846493 Classification 0.0676608620297295\n",
      "Mean and max gradients over whole network:  tensor(11.6671) tensor(133.2169)\n",
      "Mean and max weights over whole network:  tensor(0.2534) tensor(0.7488)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 12:51:14.844998\n",
      "Epoch: 17 of 64\n",
      "Batch: 1475 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.033455583774219685 Classification 0.06781669631398467\n",
      "Mean and max gradients over whole network:  tensor(15.0186) tensor(163.9360)\n",
      "Mean and max weights over whole network:  tensor(0.2536) tensor(0.7500)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 12:52:30.904824\n",
      "Epoch: 17 of 64\n",
      "Batch: 1721 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03331362463150244 Classification 0.06731883513168267\n",
      "Mean and max gradients over whole network:  tensor(13.1496) tensor(150.9044)\n",
      "Mean and max weights over whole network:  tensor(0.2538) tensor(0.7502)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 12:53:47.165965\n",
      "Epoch: 17 of 64\n",
      "Batch: 1967 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03370386183383019 Classification 0.06765596340423032\n",
      "Mean and max gradients over whole network:  tensor(16.6965) tensor(199.5892)\n",
      "Mean and max weights over whole network:  tensor(0.2540) tensor(0.7505)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 12:55:03.743396\n",
      "Epoch: 17 of 64\n",
      "Batch: 2213 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.0329938253493813 Classification 0.06747129860366909\n",
      "Mean and max gradients over whole network:  tensor(14.0889) tensor(164.0941)\n",
      "Mean and max weights over whole network:  tensor(0.2543) tensor(0.7509)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 12:56:19.271106\n",
      "Epoch: 17 of 64\n",
      "Batch: 2459 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03355585835207769 Classification 0.06753954644691007\n",
      "Mean and max gradients over whole network:  tensor(12.5932) tensor(145.0079)\n",
      "Mean and max weights over whole network:  tensor(0.2544) tensor(0.7528)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "Validation start...\n",
      "2020-08-23 12:56:33.802700\n",
      "Batch: 9 of 105\n",
      "Loss in the past 480 samples: Localization 0.03512988686561584 Classification 0.06771149635314941\n",
      "Batch: 19 of 105\n",
      "Loss in the past 480 samples: Localization 0.03405874967575073 Classification 0.065624637901783\n",
      "Batch: 29 of 105\n",
      "Loss in the past 480 samples: Localization 0.03585388610760371 Classification 0.0670431633790334\n",
      "Batch: 39 of 105\n",
      "Loss in the past 480 samples: Localization 0.03190825109680494 Classification 0.06426282624403636\n",
      "Batch: 49 of 105\n",
      "Loss in the past 480 samples: Localization 0.03537392194072406 Classification 0.0690920521815618\n",
      "Batch: 59 of 105\n",
      "Loss in the past 480 samples: Localization 0.035387698312600455 Classification 0.06982754667599995\n",
      "Batch: 69 of 105\n",
      "Loss in the past 480 samples: Localization 0.03452272390325864 Classification 0.0684330071012179\n",
      "Batch: 79 of 105\n",
      "Loss in the past 480 samples: Localization 0.03664848953485489 Classification 0.0675656815369924\n",
      "Batch: 89 of 105\n",
      "Loss in the past 480 samples: Localization 0.03570866510272026 Classification 0.06759688258171082\n",
      "Batch: 99 of 105\n",
      "Loss in the past 480 samples: Localization 0.03700870300332705 Classification 0.06911110579967499\n",
      "loading annotations into memory...\n",
      "Done (t=0.79s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.43s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=29.22s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=3.19s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.200\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.101\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.084\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.204\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.120\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.163\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.168\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.138\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.325\n",
      "Model saved succesfully\n",
      "Model saved succesfully by loss\n",
      "Average train loss at eval start: Localization: 0.03343899570640993; Classification: 0.06765442489957903\n",
      "Total number of parameters trained this epoch:  4646218\n"
     ]
    }
   ],
   "source": [
    "# train from scratch\n",
    "import main\n",
    "main.run(train_model=True, load_checkpoint=True, cross_validate=False,\n",
    "        validate=False, mixed_precision=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer : sgd\n",
      "learning_rate : 0.02\n",
      "lr_policy : retina\n",
      "batch_size : 48\n",
      "mapping_threshold : 0.5\n",
      "conf_threshold : 0.1\n",
      "suppress_threshold : 0.5333333333333333\n",
      "weight_decay : 0.0002\n",
      "loss_type : softmax\n",
      "use_focal_loss : 0\n",
      "use_hard_negative_mining : 1\n",
      "n_epochs : 64\n",
      "first_decay : 20\n",
      "second_decay : 38\n",
      "third_decay : 53\n",
      "decay_rate : 0.1\n",
      "freeze_backbone : 0\n",
      "zero_bn_bias_decay : 1\n",
      "input_height : 320\n",
      "input_width : 320\n",
      "warm_up : 3\n",
      "channels_list : [576, 1280, 512, 256, 256, 128]\n",
      "List of anchors per feature map cell:  [4, 6, 6, 6, 6, 6]\n",
      "Model ID:  ssdlite\n",
      "-------------------------------------------------------\n",
      "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Model loaded successfully from epoch:  18\n",
      "Total number of parameters of model:  4646218\n",
      "Total number of trainable parameters of model:  4646218\n",
      "Total number of parameters given to optimizer: \n",
      "4646218\n",
      "Total number of trainable parameters given to optimizer: \n",
      "4646218\n",
      "-------------------------------------------------------\n",
      "loading annotations into memory...\n",
      "Done (t=21.58s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.78s)\n",
      "creating index...\n",
      "index created!\n",
      "Train size:  2464 118287 118287\n",
      "Val size:  105 5000 5000\n",
      "-------------------------------------------------------\n",
      "2020-08-23 13:13:43.736949\n",
      "Total number of parameters trained this epoch:  4646218\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "2020-08-23 13:16:42.259758\n",
      "Epoch: 18 of 64\n",
      "Batch: 245 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03314323418427935 Classification 0.06681900083776413\n",
      "Mean and max gradients over whole network:  tensor(12.4443) tensor(139.1607)\n",
      "Mean and max weights over whole network:  tensor(0.2546) tensor(0.7534)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "2020-08-23 13:18:05.327695\n",
      "Epoch: 18 of 64\n",
      "Batch: 491 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03283253444363754 Classification 0.06638672374451386\n",
      "Mean and max gradients over whole network:  tensor(6.6892) tensor(76.5823)\n",
      "Mean and max weights over whole network:  tensor(0.2549) tensor(0.7529)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 13:19:29.103105\n",
      "Epoch: 18 of 64\n",
      "Batch: 737 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03295673102867312 Classification 0.06670402561826758\n",
      "Mean and max gradients over whole network:  tensor(5.7184) tensor(62.8335)\n",
      "Mean and max weights over whole network:  tensor(0.2551) tensor(0.7539)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 13:20:49.806959\n",
      "Epoch: 18 of 64\n",
      "Batch: 983 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03272050632249695 Classification 0.06649318442435122\n",
      "Mean and max gradients over whole network:  tensor(8.5975) tensor(96.7963)\n",
      "Mean and max weights over whole network:  tensor(0.2554) tensor(0.7543)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 13:22:09.551245\n",
      "Epoch: 18 of 64\n",
      "Batch: 1229 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03312534548160506 Classification 0.06740280218563752\n",
      "Mean and max gradients over whole network:  tensor(6.2126) tensor(71.1250)\n",
      "Mean and max weights over whole network:  tensor(0.2556) tensor(0.7556)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 13:23:26.398147\n",
      "Epoch: 18 of 64\n",
      "Batch: 1475 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03308334044082378 Classification 0.06728595487147489\n",
      "Mean and max gradients over whole network:  tensor(7.2185) tensor(84.3983)\n",
      "Mean and max weights over whole network:  tensor(0.2558) tensor(0.7563)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 13:24:43.228409\n",
      "Epoch: 18 of 64\n",
      "Batch: 1721 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.0335651348196071 Classification 0.06722306896273683\n",
      "Mean and max gradients over whole network:  tensor(6.9603) tensor(83.7414)\n",
      "Mean and max weights over whole network:  tensor(0.2560) tensor(0.7581)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 13:26:00.528221\n",
      "Epoch: 18 of 64\n",
      "Batch: 1967 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03334990031714362 Classification 0.06760753398422949\n",
      "Mean and max gradients over whole network:  tensor(5.6890) tensor(69.7378)\n",
      "Mean and max weights over whole network:  tensor(0.2563) tensor(0.7584)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 13:27:17.505995\n",
      "Epoch: 18 of 64\n",
      "Batch: 2213 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.033262063887949556 Classification 0.06732076792132241\n",
      "Mean and max gradients over whole network:  tensor(6.4639) tensor(79.3060)\n",
      "Mean and max weights over whole network:  tensor(0.2565) tensor(0.7600)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 13:28:35.319216\n",
      "Epoch: 18 of 64\n",
      "Batch: 2459 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03294025578594143 Classification 0.06724815432052948\n",
      "Mean and max gradients over whole network:  tensor(16.3225) tensor(191.3797)\n",
      "Mean and max weights over whole network:  tensor(0.2568) tensor(0.7597)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "Total number of parameters trained this epoch:  4646218\n",
      "2020-08-23 13:31:21.994480\n",
      "Epoch: 19 of 64\n",
      "Batch: 245 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03315179458842045 Classification 0.06621198652963328\n",
      "Mean and max gradients over whole network:  tensor(15.0074) tensor(185.6011)\n",
      "Mean and max weights over whole network:  tensor(0.2570) tensor(0.7604)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "2020-08-23 13:32:42.597933\n",
      "Epoch: 19 of 64\n",
      "Batch: 491 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.037716548496145544 Classification 0.0797051229895292\n",
      "Mean and max gradients over whole network:  tensor(7.1692) tensor(82.1399)\n",
      "Mean and max weights over whole network:  tensor(0.2582) tensor(0.7730)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 13:34:03.529754\n",
      "Epoch: 19 of 64\n",
      "Batch: 737 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03447064608941233 Classification 0.07078022980270024\n",
      "Mean and max gradients over whole network:  tensor(7.0478) tensor(85.5458)\n",
      "Mean and max weights over whole network:  tensor(0.2585) tensor(0.7722)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 13:35:24.175521\n",
      "Epoch: 19 of 64\n",
      "Batch: 983 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03394484962147426 Classification 0.06890360922186678\n",
      "Mean and max gradients over whole network:  tensor(6.2736) tensor(72.5274)\n",
      "Mean and max weights over whole network:  tensor(0.2587) tensor(0.7724)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 13:36:44.118762\n",
      "Epoch: 19 of 64\n",
      "Batch: 1229 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03312455770890241 Classification 0.06750253945346771\n",
      "Mean and max gradients over whole network:  tensor(6.4008) tensor(76.9268)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7730)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-23 13:38:03.046276\n",
      "Epoch: 19 of 64\n",
      "Batch: 1475 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.033592848697813545 Classification 0.06806193385020827\n",
      "Mean and max gradients over whole network:  tensor(7.3840) tensor(105.0510)\n",
      "Mean and max weights over whole network:  tensor(0.2591) tensor(0.7733)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 13:39:21.142954\n",
      "Epoch: 19 of 64\n",
      "Batch: 1721 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03321107159946669 Classification 0.06795643064064708\n",
      "Mean and max gradients over whole network:  tensor(6.2088) tensor(74.9834)\n",
      "Mean and max weights over whole network:  tensor(0.2592) tensor(0.7740)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 13:40:39.589398\n",
      "Epoch: 19 of 64\n",
      "Batch: 1967 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.033516491765817655 Classification 0.06763050707213601\n",
      "Mean and max gradients over whole network:  tensor(6.6903) tensor(76.9529)\n",
      "Mean and max weights over whole network:  tensor(0.2595) tensor(0.7751)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 13:41:59.286032\n",
      "Epoch: 19 of 64\n",
      "Batch: 2213 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03327237995376755 Classification 0.06776614874843659\n",
      "Mean and max gradients over whole network:  tensor(6.3130) tensor(74.5834)\n",
      "Mean and max weights over whole network:  tensor(0.2596) tensor(0.7752)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "2020-08-23 13:43:20.875195\n",
      "Epoch: 19 of 64\n",
      "Batch: 2459 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03318519708586902 Classification 0.06706479121110627\n",
      "Mean and max gradients over whole network:  tensor(13.0838) tensor(163.5188)\n",
      "Mean and max weights over whole network:  tensor(0.2598) tensor(0.7762)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.02\n",
      "Validation start...\n",
      "2020-08-23 13:43:38.304113\n",
      "Batch: 9 of 105\n",
      "Loss in the past 480 samples: Localization 0.0357205331325531 Classification 0.06802131334940592\n",
      "Batch: 19 of 105\n",
      "Loss in the past 480 samples: Localization 0.033808916062116626 Classification 0.06584844291210175\n",
      "Batch: 29 of 105\n",
      "Loss in the past 480 samples: Localization 0.03539192130168279 Classification 0.06673914144436519\n",
      "Batch: 39 of 105\n",
      "Loss in the past 480 samples: Localization 0.03152435297767321 Classification 0.06510153214136759\n",
      "Batch: 49 of 105\n",
      "Loss in the past 480 samples: Localization 0.03487918972969055 Classification 0.0695083071788152\n",
      "Batch: 59 of 105\n",
      "Loss in the past 480 samples: Localization 0.03557963222265244 Classification 0.0695855696996053\n",
      "Batch: 69 of 105\n",
      "Loss in the past 480 samples: Localization 0.03531349450349808 Classification 0.06922156562407812\n",
      "Batch: 79 of 105\n",
      "Loss in the past 480 samples: Localization 0.03618326261639595 Classification 0.067599951227506\n",
      "Batch: 89 of 105\n",
      "Loss in the past 480 samples: Localization 0.03513616994023323 Classification 0.0679130216439565\n",
      "Batch: 99 of 105\n",
      "Loss in the past 480 samples: Localization 0.03692847788333893 Classification 0.0692210927605629\n",
      "loading annotations into memory...\n",
      "Done (t=0.83s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.35s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=28.21s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=3.27s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.106\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.202\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.103\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.088\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.122\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.168\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.172\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.143\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.331\n",
      "Model saved succesfully\n",
      "Average train loss at eval start: Localization: 0.033504040693621395; Classification: 0.06809308310873333\n",
      "Total number of parameters trained this epoch:  4646218\n",
      "2020-08-23 13:47:51.858226\n",
      "Epoch: 20 of 64\n",
      "Batch: 245 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03164683365664346 Classification 0.06343189988355973\n",
      "Mean and max gradients over whole network:  tensor(15.0771) tensor(174.9733)\n",
      "Mean and max weights over whole network:  tensor(0.2599) tensor(0.7759)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 13:49:18.584466\n",
      "Epoch: 20 of 64\n",
      "Batch: 491 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03134044332475197 Classification 0.06252847674497097\n",
      "Mean and max gradients over whole network:  tensor(12.1778) tensor(136.4422)\n",
      "Mean and max weights over whole network:  tensor(0.2599) tensor(0.7756)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 13:50:45.126048\n",
      "Epoch: 20 of 64\n",
      "Batch: 737 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03092876059535719 Classification 0.061437287829755764\n",
      "Mean and max gradients over whole network:  tensor(12.1704) tensor(141.5436)\n",
      "Mean and max weights over whole network:  tensor(0.2599) tensor(0.7753)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 13:52:11.861320\n",
      "Epoch: 20 of 64\n",
      "Batch: 983 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.030567258485368273 Classification 0.06092392822833565\n",
      "Mean and max gradients over whole network:  tensor(13.7443) tensor(150.8931)\n",
      "Mean and max weights over whole network:  tensor(0.2599) tensor(0.7749)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "2020-08-23 13:53:37.501126\n",
      "Epoch: 20 of 64\n",
      "Batch: 1229 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.030775434178550068 Classification 0.06111047681431137\n",
      "Mean and max gradients over whole network:  tensor(6.6564) tensor(85.0596)\n",
      "Mean and max weights over whole network:  tensor(0.2599) tensor(0.7747)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 13:55:02.180444\n",
      "Epoch: 20 of 64\n",
      "Batch: 1475 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.030189282556132572 Classification 0.06059617278617895\n",
      "Mean and max gradients over whole network:  tensor(6.1403) tensor(66.3569)\n",
      "Mean and max weights over whole network:  tensor(0.2598) tensor(0.7748)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 13:56:27.131267\n",
      "Epoch: 20 of 64\n",
      "Batch: 1721 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.03043843919870653 Classification 0.06056189761171496\n",
      "Mean and max gradients over whole network:  tensor(5.9187) tensor(68.5979)\n",
      "Mean and max weights over whole network:  tensor(0.2598) tensor(0.7744)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 13:57:48.127141\n",
      "Epoch: 20 of 64\n",
      "Batch: 1967 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.029879911063203642 Classification 0.060370832923951186\n",
      "Mean and max gradients over whole network:  tensor(6.0738) tensor(68.1839)\n",
      "Mean and max weights over whole network:  tensor(0.2598) tensor(0.7744)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 13:59:07.496061\n",
      "Epoch: 20 of 64\n",
      "Batch: 2213 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.030021041076438538 Classification 0.06055591368497549\n",
      "Mean and max gradients over whole network:  tensor(6.8343) tensor(80.7173)\n",
      "Mean and max weights over whole network:  tensor(0.2598) tensor(0.7742)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-23 14:00:32.961371\n",
      "Epoch: 20 of 64\n",
      "Batch: 2459 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.030254752135414096 Classification 0.06045523188947662\n",
      "Mean and max gradients over whole network:  tensor(7.9499) tensor(91.9166)\n",
      "Mean and max weights over whole network:  tensor(0.2598) tensor(0.7741)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "Total number of parameters trained this epoch:  4646218\n",
      "2020-08-23 14:03:29.648367\n",
      "Epoch: 21 of 64\n",
      "Batch: 245 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.029914531543810515 Classification 0.05967151313050976\n",
      "Mean and max gradients over whole network:  tensor(6.3954) tensor(71.8756)\n",
      "Mean and max weights over whole network:  tensor(0.2598) tensor(0.7740)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 14:04:57.588542\n",
      "Epoch: 21 of 64\n",
      "Batch: 491 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02965695307991369 Classification 0.05965387031718644\n",
      "Mean and max gradients over whole network:  tensor(6.3832) tensor(80.0356)\n",
      "Mean and max weights over whole network:  tensor(0.2598) tensor(0.7738)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 14:06:24.551263\n",
      "Epoch: 21 of 64\n",
      "Batch: 737 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.030042037973559 Classification 0.059741783473226756\n",
      "Mean and max gradients over whole network:  tensor(14.6382) tensor(155.4420)\n",
      "Mean and max weights over whole network:  tensor(0.2598) tensor(0.7737)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 14:07:50.209649\n",
      "Epoch: 21 of 64\n",
      "Batch: 983 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.029902287453493773 Classification 0.059717440669775655\n",
      "Mean and max gradients over whole network:  tensor(15.5840) tensor(197.3056)\n",
      "Mean and max weights over whole network:  tensor(0.2598) tensor(0.7737)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 14:09:11.913282\n",
      "Epoch: 21 of 64\n",
      "Batch: 1229 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.029797754242895096 Classification 0.05996494792745042\n",
      "Mean and max gradients over whole network:  tensor(13.1726) tensor(141.3474)\n",
      "Mean and max weights over whole network:  tensor(0.2598) tensor(0.7738)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 14:10:34.042045\n",
      "Epoch: 21 of 64\n",
      "Batch: 1475 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.029859516325439543 Classification 0.05947446469772799\n",
      "Mean and max gradients over whole network:  tensor(12.6293) tensor(141.8076)\n",
      "Mean and max weights over whole network:  tensor(0.2598) tensor(0.7736)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 14:11:57.499523\n",
      "Epoch: 21 of 64\n",
      "Batch: 1721 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.029678583740784224 Classification 0.059226768247803374\n",
      "Mean and max gradients over whole network:  tensor(17.4778) tensor(213.5752)\n",
      "Mean and max weights over whole network:  tensor(0.2598) tensor(0.7736)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 14:13:22.468296\n",
      "Epoch: 21 of 64\n",
      "Batch: 1967 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.029790605844924767 Classification 0.05939120102704056\n",
      "Mean and max gradients over whole network:  tensor(11.7957) tensor(151.2133)\n",
      "Mean and max weights over whole network:  tensor(0.2598) tensor(0.7735)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 14:14:46.386196\n",
      "Epoch: 21 of 64\n",
      "Batch: 2213 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.029509050786737503 Classification 0.05955746697216499\n",
      "Mean and max gradients over whole network:  tensor(14.4940) tensor(163.5885)\n",
      "Mean and max weights over whole network:  tensor(0.2598) tensor(0.7733)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 14:16:09.878729\n",
      "Epoch: 21 of 64\n",
      "Batch: 2459 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.029377161275322843 Classification 0.059472735072700636\n",
      "Mean and max gradients over whole network:  tensor(11.8532) tensor(128.6040)\n",
      "Mean and max weights over whole network:  tensor(0.2598) tensor(0.7734)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "Validation start...\n",
      "2020-08-23 14:16:28.806993\n",
      "Batch: 9 of 105\n",
      "Loss in the past 480 samples: Localization 0.03174955720702807 Classification 0.05921515623728434\n",
      "Batch: 19 of 105\n",
      "Loss in the past 480 samples: Localization 0.030357415974140167 Classification 0.05818634033203125\n",
      "Batch: 29 of 105\n",
      "Loss in the past 480 samples: Localization 0.032511062920093536 Classification 0.05929524600505829\n",
      "Batch: 39 of 105\n",
      "Loss in the past 480 samples: Localization 0.028443073232968647 Classification 0.057468888660271965\n",
      "Batch: 49 of 105\n",
      "Loss in the past 480 samples: Localization 0.03127440984050433 Classification 0.06153634041547775\n",
      "Batch: 59 of 105\n",
      "Loss in the past 480 samples: Localization 0.03208784138162931 Classification 0.061806870996952055\n",
      "Batch: 69 of 105\n",
      "Loss in the past 480 samples: Localization 0.03132564872503281 Classification 0.060957761108875276\n",
      "Batch: 79 of 105\n",
      "Loss in the past 480 samples: Localization 0.03304595773418744 Classification 0.0600453128417333\n",
      "Batch: 89 of 105\n",
      "Loss in the past 480 samples: Localization 0.03176000714302063 Classification 0.060552668074766794\n",
      "Batch: 99 of 105\n",
      "Loss in the past 480 samples: Localization 0.03317452023426692 Classification 0.061592743794123335\n",
      "loading annotations into memory...\n",
      "Done (t=0.81s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.38s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=36.90s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=3.21s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.142\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.255\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.140\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.012\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.115\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.273\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.150\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.200\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.205\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.019\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.177\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.397\n",
      "Model saved succesfully\n",
      "Model saved succesfully by loss\n",
      "Average train loss at eval start: Localization: 0.030176499233995086; Classification: 0.0603833989607579\n",
      "Total number of parameters trained this epoch:  4646218\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "2020-08-23 14:20:51.570103\n",
      "Epoch: 22 of 64\n",
      "Batch: 245 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.029258740031056933 Classification 0.05898198915448615\n",
      "Mean and max gradients over whole network:  tensor(13.0881) tensor(132.4343)\n",
      "Mean and max weights over whole network:  tensor(0.2598) tensor(0.7733)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 14:22:16.528941\n",
      "Epoch: 22 of 64\n",
      "Batch: 491 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.029600974263214484 Classification 0.05874494552046949\n",
      "Mean and max gradients over whole network:  tensor(15.1770) tensor(210.6707)\n",
      "Mean and max weights over whole network:  tensor(0.2598) tensor(0.7732)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 14:23:38.058117\n",
      "Epoch: 22 of 64\n",
      "Batch: 737 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02950291526390285 Classification 0.05931633670478655\n",
      "Mean and max gradients over whole network:  tensor(15.2509) tensor(199.6557)\n",
      "Mean and max weights over whole network:  tensor(0.2598) tensor(0.7730)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-23 14:25:03.678994\n",
      "Epoch: 22 of 64\n",
      "Batch: 983 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02950894629183985 Classification 0.05896243648881189\n",
      "Mean and max gradients over whole network:  tensor(11.4810) tensor(129.8408)\n",
      "Mean and max weights over whole network:  tensor(0.2597) tensor(0.7731)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 14:26:24.636914\n",
      "Epoch: 22 of 64\n",
      "Batch: 1229 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.029628941329917932 Classification 0.05867061317774661\n",
      "Mean and max gradients over whole network:  tensor(18.5785) tensor(224.2326)\n",
      "Mean and max weights over whole network:  tensor(0.2597) tensor(0.7728)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 14:27:43.868492\n",
      "Epoch: 22 of 64\n",
      "Batch: 1475 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.029466875664748475 Classification 0.05895234143669366\n",
      "Mean and max gradients over whole network:  tensor(11.0077) tensor(143.6891)\n",
      "Mean and max weights over whole network:  tensor(0.2597) tensor(0.7727)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 14:29:02.219355\n",
      "Epoch: 22 of 64\n",
      "Batch: 1721 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02937239650788346 Classification 0.05866319601371036\n",
      "Mean and max gradients over whole network:  tensor(16.5107) tensor(220.2251)\n",
      "Mean and max weights over whole network:  tensor(0.2597) tensor(0.7727)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "2020-08-23 14:30:20.998887\n",
      "Epoch: 22 of 64\n",
      "Batch: 1967 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.029081488336085627 Classification 0.05856794621643981\n",
      "Mean and max gradients over whole network:  tensor(5.8760) tensor(72.3610)\n",
      "Mean and max weights over whole network:  tensor(0.2597) tensor(0.7725)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 14:31:39.000103\n",
      "Epoch: 22 of 64\n",
      "Batch: 2213 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02940040996404198 Classification 0.058685774766009675\n",
      "Mean and max gradients over whole network:  tensor(6.5006) tensor(75.9652)\n",
      "Mean and max weights over whole network:  tensor(0.2597) tensor(0.7726)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 14:32:56.084956\n",
      "Epoch: 22 of 64\n",
      "Batch: 2459 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.029188315124127277 Classification 0.05895200188001643\n",
      "Mean and max gradients over whole network:  tensor(6.3223) tensor(72.3549)\n",
      "Mean and max weights over whole network:  tensor(0.2597) tensor(0.7725)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "Total number of parameters trained this epoch:  4646218\n",
      "2020-08-23 14:35:51.668027\n",
      "Epoch: 23 of 64\n",
      "Batch: 245 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02874736599927026 Classification 0.058147126399889226\n",
      "Mean and max gradients over whole network:  tensor(8.6057) tensor(107.7261)\n",
      "Mean and max weights over whole network:  tensor(0.2597) tensor(0.7724)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 14:37:06.574314\n",
      "Epoch: 23 of 64\n",
      "Batch: 491 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02956758136671733 Classification 0.05832396405256861\n",
      "Mean and max gradients over whole network:  tensor(6.1564) tensor(69.2512)\n",
      "Mean and max weights over whole network:  tensor(0.2597) tensor(0.7723)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 14:38:21.578335\n",
      "Epoch: 23 of 64\n",
      "Batch: 737 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.029042802831829403 Classification 0.05809419830317097\n",
      "Mean and max gradients over whole network:  tensor(7.4726) tensor(79.7075)\n",
      "Mean and max weights over whole network:  tensor(0.2597) tensor(0.7722)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 14:39:39.033531\n",
      "Epoch: 23 of 64\n",
      "Batch: 983 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02910240480126081 Classification 0.0583331681444716\n",
      "Mean and max gradients over whole network:  tensor(6.7327) tensor(71.9498)\n",
      "Mean and max weights over whole network:  tensor(0.2597) tensor(0.7723)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 14:40:56.935218\n",
      "Epoch: 23 of 64\n",
      "Batch: 1229 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.029196825792109415 Classification 0.058267187397815993\n",
      "Mean and max gradients over whole network:  tensor(7.8266) tensor(106.7912)\n",
      "Mean and max weights over whole network:  tensor(0.2597) tensor(0.7723)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 14:42:15.171980\n",
      "Epoch: 23 of 64\n",
      "Batch: 1475 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.029221178186416303 Classification 0.05875246660899987\n",
      "Mean and max gradients over whole network:  tensor(6.9305) tensor(85.1585)\n",
      "Mean and max weights over whole network:  tensor(0.2597) tensor(0.7722)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 14:43:32.519779\n",
      "Epoch: 23 of 64\n",
      "Batch: 1721 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028630007674215932 Classification 0.05813410807511994\n",
      "Mean and max gradients over whole network:  tensor(12.2589) tensor(139.3131)\n",
      "Mean and max weights over whole network:  tensor(0.2596) tensor(0.7720)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 14:44:51.219640\n",
      "Epoch: 23 of 64\n",
      "Batch: 1967 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02906390326980976 Classification 0.05848178622845389\n",
      "Mean and max gradients over whole network:  tensor(11.8132) tensor(145.2398)\n",
      "Mean and max weights over whole network:  tensor(0.2596) tensor(0.7718)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 14:46:09.215232\n",
      "Epoch: 23 of 64\n",
      "Batch: 2213 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.029184578450997346 Classification 0.058227014614314565\n",
      "Mean and max gradients over whole network:  tensor(12.3002) tensor(142.7701)\n",
      "Mean and max weights over whole network:  tensor(0.2596) tensor(0.7719)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 14:47:28.579851\n",
      "Epoch: 23 of 64\n",
      "Batch: 2459 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02924904659350067 Classification 0.058390730239834564\n",
      "Mean and max gradients over whole network:  tensor(15.8385) tensor(202.9599)\n",
      "Mean and max weights over whole network:  tensor(0.2596) tensor(0.7717)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "Validation start...\n",
      "2020-08-23 14:47:49.883908\n",
      "Batch: 9 of 105\n",
      "Loss in the past 480 samples: Localization 0.031155544022719067 Classification 0.05854437251885732\n",
      "Batch: 19 of 105\n",
      "Loss in the past 480 samples: Localization 0.0300236776471138 Classification 0.05736172695954641\n",
      "Batch: 29 of 105\n",
      "Loss in the past 480 samples: Localization 0.031904562811056775 Classification 0.058660956223805745\n",
      "Batch: 39 of 105\n",
      "Loss in the past 480 samples: Localization 0.02801188627878825 Classification 0.056661215424537656\n",
      "Batch: 49 of 105\n",
      "Loss in the past 480 samples: Localization 0.031092879424492518 Classification 0.06055151323477427\n",
      "Batch: 59 of 105\n",
      "Loss in the past 480 samples: Localization 0.03137370397647222 Classification 0.0613081693649292\n",
      "Batch: 69 of 105\n",
      "Loss in the past 480 samples: Localization 0.03089135338862737 Classification 0.06016959448655446\n",
      "Batch: 79 of 105\n",
      "Loss in the past 480 samples: Localization 0.032487569997708 Classification 0.05959527790546417\n",
      "Batch: 89 of 105\n",
      "Loss in the past 480 samples: Localization 0.031564725935459136 Classification 0.059801061451435086\n",
      "Batch: 99 of 105\n",
      "Loss in the past 480 samples: Localization 0.03261641611655553 Classification 0.06102415124575297\n",
      "loading annotations into memory...\n",
      "Done (t=0.85s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=3.28s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE (t=26.64s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=3.27s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.146\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.262\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.144\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.012\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.120\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.282\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.153\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.205\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.210\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.019\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.182\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.411\n",
      "Model saved succesfully\n",
      "Model saved succesfully by loss\n",
      "Average train loss at eval start: Localization: 0.029245683302891387; Classification: 0.058575770941963146\n",
      "Total number of parameters trained this epoch:  4646218\n",
      "2020-08-23 14:52:15.661264\n",
      "Epoch: 24 of 64\n",
      "Batch: 245 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028959361225528123 Classification 0.05796756718539933\n",
      "Mean and max gradients over whole network:  tensor(13.8291) tensor(177.9714)\n",
      "Mean and max weights over whole network:  tensor(0.2596) tensor(0.7717)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 14:53:40.473992\n",
      "Epoch: 24 of 64\n",
      "Batch: 491 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02923270528454606 Classification 0.05796444888521985\n",
      "Mean and max gradients over whole network:  tensor(15.6001) tensor(178.6400)\n",
      "Mean and max weights over whole network:  tensor(0.2596) tensor(0.7717)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 14:55:06.934414\n",
      "Epoch: 24 of 64\n",
      "Batch: 737 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02859937460704386 Classification 0.057865475594674344\n",
      "Mean and max gradients over whole network:  tensor(12.9856) tensor(139.5823)\n",
      "Mean and max weights over whole network:  tensor(0.2596) tensor(0.7714)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 14:56:32.142444\n",
      "Epoch: 24 of 64\n",
      "Batch: 983 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.029063161947136002 Classification 0.05803016722606127\n",
      "Mean and max gradients over whole network:  tensor(14.3291) tensor(174.9466)\n",
      "Mean and max weights over whole network:  tensor(0.2596) tensor(0.7712)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "2020-08-23 14:57:53.134038\n",
      "Epoch: 24 of 64\n",
      "Batch: 1229 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02887229006586036 Classification 0.05797589495576171\n",
      "Mean and max gradients over whole network:  tensor(17.2739) tensor(219.1373)\n",
      "Mean and max weights over whole network:  tensor(0.2596) tensor(0.7711)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 14:59:16.500744\n",
      "Epoch: 24 of 64\n",
      "Batch: 1475 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028610628047771248 Classification 0.05771851095403759\n",
      "Mean and max gradients over whole network:  tensor(13.9721) tensor(154.2652)\n",
      "Mean and max weights over whole network:  tensor(0.2596) tensor(0.7712)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 15:00:36.235560\n",
      "Epoch: 24 of 64\n",
      "Batch: 1721 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028914528341110805 Classification 0.05785945483904867\n",
      "Mean and max gradients over whole network:  tensor(13.2884) tensor(142.5640)\n",
      "Mean and max weights over whole network:  tensor(0.2596) tensor(0.7710)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 15:01:54.906864\n",
      "Epoch: 24 of 64\n",
      "Batch: 1967 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028767235415576273 Classification 0.05792631426962411\n",
      "Mean and max gradients over whole network:  tensor(14.3406) tensor(152.7483)\n",
      "Mean and max weights over whole network:  tensor(0.2596) tensor(0.7709)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 15:03:13.144693\n",
      "Epoch: 24 of 64\n",
      "Batch: 2213 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028824187552702784 Classification 0.05767565917193405\n",
      "Mean and max gradients over whole network:  tensor(15.0248) tensor(169.9725)\n",
      "Mean and max weights over whole network:  tensor(0.2596) tensor(0.7709)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 15:04:30.892684\n",
      "Epoch: 24 of 64\n",
      "Batch: 2459 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028603089312066232 Classification 0.05800707852291221\n",
      "Mean and max gradients over whole network:  tensor(12.6386) tensor(132.7447)\n",
      "Mean and max weights over whole network:  tensor(0.2596) tensor(0.7708)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "Total number of parameters trained this epoch:  4646218\n",
      "2020-08-23 15:07:16.884173\n",
      "Epoch: 25 of 64\n",
      "Batch: 245 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028654211985709544 Classification 0.05705522170396355\n",
      "Mean and max gradients over whole network:  tensor(14.5780) tensor(184.5151)\n",
      "Mean and max weights over whole network:  tensor(0.2595) tensor(0.7708)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 15:08:33.182543\n",
      "Epoch: 25 of 64\n",
      "Batch: 491 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028996407248705707 Classification 0.05757153401691416\n",
      "Mean and max gradients over whole network:  tensor(12.2771) tensor(136.5123)\n",
      "Mean and max weights over whole network:  tensor(0.2595) tensor(0.7708)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "2020-08-23 15:09:48.989377\n",
      "Epoch: 25 of 64\n",
      "Batch: 737 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028631822304512427 Classification 0.05735195262564553\n",
      "Mean and max gradients over whole network:  tensor(13.9702) tensor(158.8966)\n",
      "Mean and max weights over whole network:  tensor(0.2595) tensor(0.7706)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 15:11:04.995931\n",
      "Epoch: 25 of 64\n",
      "Batch: 983 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028201451928917633 Classification 0.05756166195724069\n",
      "Mean and max gradients over whole network:  tensor(17.8729) tensor(193.5626)\n",
      "Mean and max weights over whole network:  tensor(0.2595) tensor(0.7704)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 15:12:20.963358\n",
      "Epoch: 25 of 64\n",
      "Batch: 1229 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02867444578386581 Classification 0.057681584281488486\n",
      "Mean and max gradients over whole network:  tensor(21.6258) tensor(250.2279)\n",
      "Mean and max weights over whole network:  tensor(0.2595) tensor(0.7702)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 15:13:35.655266\n",
      "Epoch: 25 of 64\n",
      "Batch: 1475 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02873519692458919 Classification 0.0577522081128627\n",
      "Mean and max gradients over whole network:  tensor(17.0784) tensor(208.2678)\n",
      "Mean and max weights over whole network:  tensor(0.2595) tensor(0.7699)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 15:14:54.148305\n",
      "Epoch: 25 of 64\n",
      "Batch: 1721 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028792513080122994 Classification 0.05753004137012693\n",
      "Mean and max gradients over whole network:  tensor(18.5709) tensor(234.2571)\n",
      "Mean and max weights over whole network:  tensor(0.2595) tensor(0.7700)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-23 15:16:12.694749\n",
      "Epoch: 25 of 64\n",
      "Batch: 1967 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028514404748351915 Classification 0.05798933416766526\n",
      "Mean and max gradients over whole network:  tensor(14.7628) tensor(177.0989)\n",
      "Mean and max weights over whole network:  tensor(0.2595) tensor(0.7700)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 15:17:30.671614\n",
      "Epoch: 25 of 64\n",
      "Batch: 2213 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028633492153269165 Classification 0.057339261682214454\n",
      "Mean and max gradients over whole network:  tensor(13.9248) tensor(158.8916)\n",
      "Mean and max weights over whole network:  tensor(0.2595) tensor(0.7698)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 15:18:48.868863\n",
      "Epoch: 25 of 64\n",
      "Batch: 2459 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02907140440936011 Classification 0.05765739721334401\n",
      "Mean and max gradients over whole network:  tensor(17.3109) tensor(220.9173)\n",
      "Mean and max weights over whole network:  tensor(0.2595) tensor(0.7697)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "Validation start...\n",
      "2020-08-23 15:19:04.472031\n",
      "Batch: 9 of 105\n",
      "Loss in the past 480 samples: Localization 0.030896097918351493 Classification 0.05807082802057266\n",
      "Batch: 19 of 105\n",
      "Loss in the past 480 samples: Localization 0.029783464223146438 Classification 0.05722544193267822\n",
      "Batch: 29 of 105\n",
      "Loss in the past 480 samples: Localization 0.031881162772576015 Classification 0.058035269379615784\n",
      "Batch: 39 of 105\n",
      "Loss in the past 480 samples: Localization 0.02774956797560056 Classification 0.05648389458656311\n",
      "Batch: 49 of 105\n",
      "Loss in the past 480 samples: Localization 0.03035485123594602 Classification 0.060432393848896024\n",
      "Batch: 59 of 105\n",
      "Loss in the past 480 samples: Localization 0.031152886897325517 Classification 0.06061967263619105\n",
      "Batch: 69 of 105\n",
      "Loss in the past 480 samples: Localization 0.03070734441280365 Classification 0.06007049133380254\n",
      "Batch: 79 of 105\n",
      "Loss in the past 480 samples: Localization 0.032256389906009035 Classification 0.059059118231137596\n",
      "Batch: 89 of 105\n",
      "Loss in the past 480 samples: Localization 0.03126130476593971 Classification 0.05939928541580836\n",
      "Batch: 99 of 105\n",
      "Loss in the past 480 samples: Localization 0.032487128674983975 Classification 0.060519494613011676\n",
      "loading annotations into memory...\n",
      "Done (t=0.82s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=5.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=27.44s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=3.22s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.148\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.263\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.148\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.012\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.121\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.292\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.154\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.212\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.020\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.181\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.414\n",
      "Model saved succesfully\n",
      "Model saved succesfully by loss\n",
      "Average train loss at eval start: Localization: 0.028766592682268083; Classification: 0.05771631859104029\n",
      "Total number of parameters trained this epoch:  4646218\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "2020-08-23 15:23:29.617787\n",
      "Epoch: 26 of 64\n",
      "Batch: 245 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028263360393160405 Classification 0.05719365452120944\n",
      "Mean and max gradients over whole network:  tensor(14.0736) tensor(156.8269)\n",
      "Mean and max weights over whole network:  tensor(0.2595) tensor(0.7697)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 15:24:53.715394\n",
      "Epoch: 26 of 64\n",
      "Batch: 491 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02848617226733425 Classification 0.056933662937424044\n",
      "Mean and max gradients over whole network:  tensor(14.2743) tensor(172.8527)\n",
      "Mean and max weights over whole network:  tensor(0.2595) tensor(0.7695)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 15:26:16.816831\n",
      "Epoch: 26 of 64\n",
      "Batch: 737 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02855648062012706 Classification 0.05703213473726417\n",
      "Mean and max gradients over whole network:  tensor(15.2802) tensor(164.5924)\n",
      "Mean and max weights over whole network:  tensor(0.2595) tensor(0.7695)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 15:27:40.678399\n",
      "Epoch: 26 of 64\n",
      "Batch: 983 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02862537768353938 Classification 0.05756246966882773\n",
      "Mean and max gradients over whole network:  tensor(17.6936) tensor(215.5582)\n",
      "Mean and max weights over whole network:  tensor(0.2595) tensor(0.7694)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 15:29:01.167321\n",
      "Epoch: 26 of 64\n",
      "Batch: 1229 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028308671573555568 Classification 0.05705956084941461\n",
      "Mean and max gradients over whole network:  tensor(12.6469) tensor(135.4616)\n",
      "Mean and max weights over whole network:  tensor(0.2594) tensor(0.7695)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 15:30:21.397855\n",
      "Epoch: 26 of 64\n",
      "Batch: 1475 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028871949221989327 Classification 0.05764394883460146\n",
      "Mean and max gradients over whole network:  tensor(12.8100) tensor(141.8973)\n",
      "Mean and max weights over whole network:  tensor(0.2594) tensor(0.7694)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "2020-08-23 15:31:40.589798\n",
      "Epoch: 26 of 64\n",
      "Batch: 1721 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028563240810542248 Classification 0.05738320764971942\n",
      "Mean and max gradients over whole network:  tensor(6.4751) tensor(78.1213)\n",
      "Mean and max weights over whole network:  tensor(0.2594) tensor(0.7692)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 15:32:57.542223\n",
      "Epoch: 26 of 64\n",
      "Batch: 1967 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028673346924184138 Classification 0.05725473700580881\n",
      "Mean and max gradients over whole network:  tensor(7.5220) tensor(84.3807)\n",
      "Mean and max weights over whole network:  tensor(0.2594) tensor(0.7689)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 15:34:15.443535\n",
      "Epoch: 26 of 64\n",
      "Batch: 2213 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028496755524298686 Classification 0.05711522809454419\n",
      "Mean and max gradients over whole network:  tensor(7.7446) tensor(87.6134)\n",
      "Mean and max weights over whole network:  tensor(0.2594) tensor(0.7691)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 15:35:37.116816\n",
      "Epoch: 26 of 64\n",
      "Batch: 2459 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028466748371518403 Classification 0.057130627899473596\n",
      "Mean and max gradients over whole network:  tensor(7.9001) tensor(88.4712)\n",
      "Mean and max weights over whole network:  tensor(0.2594) tensor(0.7690)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "Total number of parameters trained this epoch:  4646218\n",
      "2020-08-23 15:38:46.375330\n",
      "Epoch: 27 of 64\n",
      "Batch: 245 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02828449896236422 Classification 0.056741999356242696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean and max gradients over whole network:  tensor(8.0034) tensor(110.8700)\n",
      "Mean and max weights over whole network:  tensor(0.2594) tensor(0.7690)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 15:40:13.636761\n",
      "Epoch: 27 of 64\n",
      "Batch: 491 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02845695447227173 Classification 0.05689279024355457\n",
      "Mean and max gradients over whole network:  tensor(8.6014) tensor(103.3556)\n",
      "Mean and max weights over whole network:  tensor(0.2594) tensor(0.7688)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 15:41:41.138078\n",
      "Epoch: 27 of 64\n",
      "Batch: 737 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028387908957555365 Classification 0.056703035686881884\n",
      "Mean and max gradients over whole network:  tensor(7.1632) tensor(76.4810)\n",
      "Mean and max weights over whole network:  tensor(0.2594) tensor(0.7688)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 15:43:08.114777\n",
      "Epoch: 27 of 64\n",
      "Batch: 983 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028317465414078577 Classification 0.05686365296120243\n",
      "Mean and max gradients over whole network:  tensor(8.1471) tensor(96.8505)\n",
      "Mean and max weights over whole network:  tensor(0.2594) tensor(0.7687)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 15:44:32.137676\n",
      "Epoch: 27 of 64\n",
      "Batch: 1229 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028153215552652433 Classification 0.056850308628101656\n",
      "Mean and max gradients over whole network:  tensor(13.2597) tensor(142.4416)\n",
      "Mean and max weights over whole network:  tensor(0.2594) tensor(0.7688)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 15:45:55.552289\n",
      "Epoch: 27 of 64\n",
      "Batch: 1475 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028453632366406884 Classification 0.05724270851793005\n",
      "Mean and max gradients over whole network:  tensor(16.0172) tensor(179.3932)\n",
      "Mean and max weights over whole network:  tensor(0.2594) tensor(0.7688)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 15:47:23.102152\n",
      "Epoch: 27 of 64\n",
      "Batch: 1721 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02828143454765078 Classification 0.05661648725914115\n",
      "Mean and max gradients over whole network:  tensor(14.2218) tensor(160.3642)\n",
      "Mean and max weights over whole network:  tensor(0.2594) tensor(0.7687)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 15:48:47.585958\n",
      "Epoch: 27 of 64\n",
      "Batch: 1967 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02850509718121067 Classification 0.05693852015061753\n",
      "Mean and max gradients over whole network:  tensor(19.1380) tensor(216.4543)\n",
      "Mean and max weights over whole network:  tensor(0.2594) tensor(0.7686)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 15:50:11.402391\n",
      "Epoch: 27 of 64\n",
      "Batch: 2213 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028110475175910525 Classification 0.056731110221648284\n",
      "Mean and max gradients over whole network:  tensor(15.2304) tensor(182.0927)\n",
      "Mean and max weights over whole network:  tensor(0.2594) tensor(0.7685)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 15:51:33.436174\n",
      "Epoch: 27 of 64\n",
      "Batch: 2459 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028481723240962844 Classification 0.056647824663618396\n",
      "Mean and max gradients over whole network:  tensor(15.3975) tensor(170.0626)\n",
      "Mean and max weights over whole network:  tensor(0.2593) tensor(0.7684)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "Validation start...\n",
      "2020-08-23 15:51:52.812493\n",
      "Batch: 9 of 105\n",
      "Loss in the past 480 samples: Localization 0.030885112285614014 Classification 0.05798637916644414\n",
      "Batch: 19 of 105\n",
      "Loss in the past 480 samples: Localization 0.029840890814860663 Classification 0.05703332523504893\n",
      "Batch: 29 of 105\n",
      "Loss in the past 480 samples: Localization 0.0318345899383227 Classification 0.057796005407969156\n",
      "Batch: 39 of 105\n",
      "Loss in the past 480 samples: Localization 0.0274646632373333 Classification 0.05580672075351079\n",
      "Batch: 49 of 105\n",
      "Loss in the past 480 samples: Localization 0.030526227255662283 Classification 0.06001383513212204\n",
      "Batch: 59 of 105\n",
      "Loss in the past 480 samples: Localization 0.031046278278032937 Classification 0.0601812223593394\n",
      "Batch: 69 of 105\n",
      "Loss in the past 480 samples: Localization 0.03041743114590645 Classification 0.05927436649799347\n",
      "Batch: 79 of 105\n",
      "Loss in the past 480 samples: Localization 0.032263443370660144 Classification 0.059033634761969246\n",
      "Batch: 89 of 105\n",
      "Loss in the past 480 samples: Localization 0.03132989605267843 Classification 0.059532945851484935\n",
      "Batch: 99 of 105\n",
      "Loss in the past 480 samples: Localization 0.032792900254329044 Classification 0.0606508602698644\n",
      "loading annotations into memory...\n",
      "Done (t=0.84s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.36s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=30.40s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=3.28s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.150\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.268\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.151\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.014\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.127\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.294\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.155\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.209\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.214\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.186\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.420\n",
      "Model saved succesfully\n",
      "Model saved succesfully by loss\n",
      "Average train loss at eval start: Localization: 0.028431723449937808; Classification: 0.05701870354995999\n",
      "Total number of parameters trained this epoch:  4646218\n",
      "2020-08-23 15:56:27.033360\n",
      "Epoch: 28 of 64\n",
      "Batch: 245 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028219552049388086 Classification 0.05697198848171932\n",
      "Mean and max gradients over whole network:  tensor(13.7449) tensor(146.3966)\n",
      "Mean and max weights over whole network:  tensor(0.2593) tensor(0.7682)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 15:57:54.814384\n",
      "Epoch: 28 of 64\n",
      "Batch: 491 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028804545257957323 Classification 0.05710361435565199\n",
      "Mean and max gradients over whole network:  tensor(15.3302) tensor(185.3554)\n",
      "Mean and max weights over whole network:  tensor(0.2593) tensor(0.7682)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "2020-08-23 15:59:17.782049\n",
      "Epoch: 28 of 64\n",
      "Batch: 737 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028351611606675757 Classification 0.057036019276151165\n",
      "Mean and max gradients over whole network:  tensor(16.5153) tensor(176.8391)\n",
      "Mean and max weights over whole network:  tensor(0.2593) tensor(0.7681)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "2020-08-23 16:00:40.931717\n",
      "Epoch: 28 of 64\n",
      "Batch: 983 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028479527777974523 Classification 0.057272435042270156\n",
      "Mean and max gradients over whole network:  tensor(8.7138) tensor(100.5722)\n",
      "Mean and max weights over whole network:  tensor(0.2593) tensor(0.7680)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-23 16:02:00.967055\n",
      "Epoch: 28 of 64\n",
      "Batch: 1229 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028597265673765967 Classification 0.057466384921939714\n",
      "Mean and max gradients over whole network:  tensor(7.6437) tensor(88.7785)\n",
      "Mean and max weights over whole network:  tensor(0.2593) tensor(0.7679)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 16:03:19.376285\n",
      "Epoch: 28 of 64\n",
      "Batch: 1475 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028583376660821884 Classification 0.0570436400086253\n",
      "Mean and max gradients over whole network:  tensor(6.7923) tensor(68.9798)\n",
      "Mean and max weights over whole network:  tensor(0.2593) tensor(0.7678)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 16:04:38.188162\n",
      "Epoch: 28 of 64\n",
      "Batch: 1721 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028444492472663806 Classification 0.05680974449730178\n",
      "Mean and max gradients over whole network:  tensor(8.2125) tensor(90.3734)\n",
      "Mean and max weights over whole network:  tensor(0.2593) tensor(0.7678)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 16:06:01.628380\n",
      "Epoch: 28 of 64\n",
      "Batch: 1967 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02816611144257593 Classification 0.056848680888249625\n",
      "Mean and max gradients over whole network:  tensor(6.1312) tensor(68.3997)\n",
      "Mean and max weights over whole network:  tensor(0.2593) tensor(0.7677)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 16:07:21.895635\n",
      "Epoch: 28 of 64\n",
      "Batch: 2213 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02827409903208415 Classification 0.056864161014072295\n",
      "Mean and max gradients over whole network:  tensor(8.2159) tensor(94.0412)\n",
      "Mean and max weights over whole network:  tensor(0.2593) tensor(0.7677)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 16:08:41.939753\n",
      "Epoch: 28 of 64\n",
      "Batch: 2459 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028695849545279817 Classification 0.05695947134478629\n",
      "Mean and max gradients over whole network:  tensor(7.1491) tensor(83.2332)\n",
      "Mean and max weights over whole network:  tensor(0.2593) tensor(0.7677)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "Total number of parameters trained this epoch:  4646218\n",
      "2020-08-23 16:11:29.100861\n",
      "Epoch: 29 of 64\n",
      "Batch: 245 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028340346505486867 Classification 0.05683663503587408\n",
      "Mean and max gradients over whole network:  tensor(7.9972) tensor(83.0882)\n",
      "Mean and max weights over whole network:  tensor(0.2593) tensor(0.7676)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 16:12:48.756147\n",
      "Epoch: 29 of 64\n",
      "Batch: 491 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02861327807694108 Classification 0.0568906655560341\n",
      "Mean and max gradients over whole network:  tensor(14.6125) tensor(162.4349)\n",
      "Mean and max weights over whole network:  tensor(0.2593) tensor(0.7675)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 16:14:08.142070\n",
      "Epoch: 29 of 64\n",
      "Batch: 737 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028502223609383835 Classification 0.05687788064240763\n",
      "Mean and max gradients over whole network:  tensor(18.5783) tensor(244.4068)\n",
      "Mean and max weights over whole network:  tensor(0.2593) tensor(0.7673)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 16:15:27.855032\n",
      "Epoch: 29 of 64\n",
      "Batch: 983 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028483284955344548 Classification 0.05699088937302592\n",
      "Mean and max gradients over whole network:  tensor(18.1436) tensor(255.5738)\n",
      "Mean and max weights over whole network:  tensor(0.2593) tensor(0.7672)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 16:16:46.095088\n",
      "Epoch: 29 of 64\n",
      "Batch: 1229 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028411377569645402 Classification 0.05643782558722225\n",
      "Mean and max gradients over whole network:  tensor(13.8577) tensor(176.2956)\n",
      "Mean and max weights over whole network:  tensor(0.2593) tensor(0.7671)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 16:18:06.004887\n",
      "Epoch: 29 of 64\n",
      "Batch: 1475 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02825229754292868 Classification 0.05663898991052374\n",
      "Mean and max gradients over whole network:  tensor(18.2464) tensor(214.7492)\n",
      "Mean and max weights over whole network:  tensor(0.2593) tensor(0.7671)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 16:19:23.185411\n",
      "Epoch: 29 of 64\n",
      "Batch: 1721 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028093549738408427 Classification 0.05724748748993163\n",
      "Mean and max gradients over whole network:  tensor(14.6211) tensor(160.9708)\n",
      "Mean and max weights over whole network:  tensor(0.2593) tensor(0.7672)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 16:20:40.039894\n",
      "Epoch: 29 of 64\n",
      "Batch: 1967 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028693890082965374 Classification 0.05700214298033133\n",
      "Mean and max gradients over whole network:  tensor(13.4647) tensor(149.5639)\n",
      "Mean and max weights over whole network:  tensor(0.2593) tensor(0.7670)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 16:21:58.455219\n",
      "Epoch: 29 of 64\n",
      "Batch: 2213 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028494812336152163 Classification 0.05687080218701505\n",
      "Mean and max gradients over whole network:  tensor(17.0958) tensor(209.3780)\n",
      "Mean and max weights over whole network:  tensor(0.2593) tensor(0.7669)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "2020-08-23 16:23:17.734253\n",
      "Epoch: 29 of 64\n",
      "Batch: 2459 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028493065028615438 Classification 0.056807312337040575\n",
      "Mean and max gradients over whole network:  tensor(nan) tensor(nan)\n",
      "Mean and max weights over whole network:  tensor(0.2592) tensor(0.7669)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "Validation start...\n",
      "2020-08-23 16:23:33.899797\n",
      "Batch: 9 of 105\n",
      "Loss in the past 480 samples: Localization 0.030838870257139207 Classification 0.0578126793106397\n",
      "Batch: 19 of 105\n",
      "Loss in the past 480 samples: Localization 0.029568143437306085 Classification 0.05724069277445475\n",
      "Batch: 29 of 105\n",
      "Loss in the past 480 samples: Localization 0.03154967054724693 Classification 0.05765596876541774\n",
      "Batch: 39 of 105\n",
      "Loss in the past 480 samples: Localization 0.027478710810343424 Classification 0.055634324252605435\n",
      "Batch: 49 of 105\n",
      "Loss in the past 480 samples: Localization 0.03032461404800415 Classification 0.060248731076717375\n",
      "Batch: 59 of 105\n",
      "Loss in the past 480 samples: Localization 0.03086799879868825 Classification 0.060024261474609375\n",
      "Batch: 69 of 105\n",
      "Loss in the past 480 samples: Localization 0.030175404002269108 Classification 0.05939580847819646\n",
      "Batch: 79 of 105\n",
      "Loss in the past 480 samples: Localization 0.032229387263456984 Classification 0.05907355397939682\n",
      "Batch: 89 of 105\n",
      "Loss in the past 480 samples: Localization 0.031222758690516154 Classification 0.058941554526487985\n",
      "Batch: 99 of 105\n",
      "Loss in the past 480 samples: Localization 0.03230926518638929 Classification 0.06032215555508932\n",
      "loading annotations into memory...\n",
      "Done (t=0.81s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.37s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=41.72s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=3.21s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.150\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.268\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.150\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.013\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.125\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.294\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.155\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.210\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.215\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.188\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved succesfully\n",
      "Model saved succesfully by loss\n",
      "Average train loss at eval start: Localization: 0.028450861384887227; Classification: 0.05694047906962797\n",
      "Total number of parameters trained this epoch:  4646218\n",
      "2020-08-23 16:27:54.844422\n",
      "Epoch: 30 of 64\n",
      "Batch: 245 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028419443837753158 Classification 0.05670613090843366\n",
      "Mean and max gradients over whole network:  tensor(18.0644) tensor(209.2952)\n",
      "Mean and max weights over whole network:  tensor(0.2592) tensor(0.7667)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "2020-08-23 16:29:14.991292\n",
      "Epoch: 30 of 64\n",
      "Batch: 491 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02837973199582843 Classification 0.05644917027737067\n",
      "Mean and max gradients over whole network:  tensor(7.4523) tensor(85.3699)\n",
      "Mean and max weights over whole network:  tensor(0.2592) tensor(0.7664)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 16:30:33.459047\n",
      "Epoch: 30 of 64\n",
      "Batch: 737 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028185786220035577 Classification 0.05690852292184907\n",
      "Mean and max gradients over whole network:  tensor(9.0757) tensor(111.3334)\n",
      "Mean and max weights over whole network:  tensor(0.2592) tensor(0.7664)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 16:31:54.500316\n",
      "Epoch: 30 of 64\n",
      "Batch: 983 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.0280428343682189 Classification 0.05663056132512364\n",
      "Mean and max gradients over whole network:  tensor(9.6400) tensor(112.0174)\n",
      "Mean and max weights over whole network:  tensor(0.2592) tensor(0.7664)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 16:33:12.668972\n",
      "Epoch: 30 of 64\n",
      "Batch: 1229 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02835729838851183 Classification 0.056892256729486515\n",
      "Mean and max gradients over whole network:  tensor(8.5113) tensor(133.0804)\n",
      "Mean and max weights over whole network:  tensor(0.2592) tensor(0.7665)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 16:34:35.249200\n",
      "Epoch: 30 of 64\n",
      "Batch: 1475 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028302566791937604 Classification 0.05646905082916503\n",
      "Mean and max gradients over whole network:  tensor(6.6939) tensor(72.3745)\n",
      "Mean and max weights over whole network:  tensor(0.2592) tensor(0.7664)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 16:35:56.447385\n",
      "Epoch: 30 of 64\n",
      "Batch: 1721 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02824866239153111 Classification 0.056446913740822294\n",
      "Mean and max gradients over whole network:  tensor(7.7663) tensor(87.8687)\n",
      "Mean and max weights over whole network:  tensor(0.2592) tensor(0.7663)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 16:37:16.196000\n",
      "Epoch: 30 of 64\n",
      "Batch: 1967 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027953997501714765 Classification 0.05659513593446917\n",
      "Mean and max gradients over whole network:  tensor(7.8780) tensor(90.7195)\n",
      "Mean and max weights over whole network:  tensor(0.2592) tensor(0.7662)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 16:38:36.696696\n",
      "Epoch: 30 of 64\n",
      "Batch: 2213 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02811619762058665 Classification 0.05675401064115488\n",
      "Mean and max gradients over whole network:  tensor(8.3349) tensor(95.0745)\n",
      "Mean and max weights over whole network:  tensor(0.2592) tensor(0.7661)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 16:39:55.897340\n",
      "Epoch: 30 of 64\n",
      "Batch: 2459 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028584190873999583 Classification 0.05700953577349826\n",
      "Mean and max gradients over whole network:  tensor(19.3333) tensor(207.2286)\n",
      "Mean and max weights over whole network:  tensor(0.2592) tensor(0.7660)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "Total number of parameters trained this epoch:  4646218\n",
      "2020-08-23 16:42:37.455610\n",
      "Epoch: 31 of 64\n",
      "Batch: 245 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02826872830932864 Classification 0.05635595866819707\n",
      "Mean and max gradients over whole network:  tensor(16.0704) tensor(166.2833)\n",
      "Mean and max weights over whole network:  tensor(0.2592) tensor(0.7660)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 16:43:56.992352\n",
      "Epoch: 31 of 64\n",
      "Batch: 491 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02853449273016556 Classification 0.05655077719672263\n",
      "Mean and max gradients over whole network:  tensor(18.5629) tensor(241.4356)\n",
      "Mean and max weights over whole network:  tensor(0.2592) tensor(0.7660)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 16:45:19.982253\n",
      "Epoch: 31 of 64\n",
      "Batch: 737 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028075125850838052 Classification 0.05647312266232198\n",
      "Mean and max gradients over whole network:  tensor(17.4504) tensor(197.2593)\n",
      "Mean and max weights over whole network:  tensor(0.2592) tensor(0.7659)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 16:46:47.860011\n",
      "Epoch: 31 of 64\n",
      "Batch: 983 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02856868770488394 Classification 0.056809825141255446\n",
      "Mean and max gradients over whole network:  tensor(17.1649) tensor(189.4947)\n",
      "Mean and max weights over whole network:  tensor(0.2592) tensor(0.7658)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 16:48:14.158765\n",
      "Epoch: 31 of 64\n",
      "Batch: 1229 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028023634444124652 Classification 0.05653608945730902\n",
      "Mean and max gradients over whole network:  tensor(14.5358) tensor(155.4375)\n",
      "Mean and max weights over whole network:  tensor(0.2592) tensor(0.7658)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 16:49:42.996829\n",
      "Epoch: 31 of 64\n",
      "Batch: 1475 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028228483533835023 Classification 0.056824712592573344\n",
      "Mean and max gradients over whole network:  tensor(19.4975) tensor(230.8453)\n",
      "Mean and max weights over whole network:  tensor(0.2591) tensor(0.7657)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 16:51:12.909908\n",
      "Epoch: 31 of 64\n",
      "Batch: 1721 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027834200580430225 Classification 0.05633263697792198\n",
      "Mean and max gradients over whole network:  tensor(16.0276) tensor(210.4654)\n",
      "Mean and max weights over whole network:  tensor(0.2591) tensor(0.7656)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 16:52:39.561179\n",
      "Epoch: 31 of 64\n",
      "Batch: 1967 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028110575359970896 Classification 0.05659176029648561\n",
      "Mean and max gradients over whole network:  tensor(14.5687) tensor(153.5809)\n",
      "Mean and max weights over whole network:  tensor(0.2591) tensor(0.7655)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "2020-08-23 16:54:01.060135\n",
      "Epoch: 31 of 64\n",
      "Batch: 2213 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02816217341700059 Classification 0.05655605755847321\n",
      "Mean and max gradients over whole network:  tensor(16.5611) tensor(185.3380)\n",
      "Mean and max weights over whole network:  tensor(0.2591) tensor(0.7654)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 16:55:18.414906\n",
      "Epoch: 31 of 64\n",
      "Batch: 2459 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.0280243260962611 Classification 0.05660063640131214\n",
      "Mean and max gradients over whole network:  tensor(16.6256) tensor(193.2531)\n",
      "Mean and max weights over whole network:  tensor(0.2591) tensor(0.7653)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation start...\n",
      "2020-08-23 16:55:34.610839\n",
      "Batch: 9 of 105\n",
      "Loss in the past 480 samples: Localization 0.03050082301100095 Classification 0.05768134146928787\n",
      "Batch: 19 of 105\n",
      "Loss in the past 480 samples: Localization 0.0294531486928463 Classification 0.056667488813400266\n",
      "Batch: 29 of 105\n",
      "Loss in the past 480 samples: Localization 0.0313019889096419 Classification 0.05739959627389908\n",
      "Batch: 39 of 105\n",
      "Loss in the past 480 samples: Localization 0.027422185242176055 Classification 0.05531638612349828\n",
      "Batch: 49 of 105\n",
      "Loss in the past 480 samples: Localization 0.03026210715373357 Classification 0.05994717975457509\n",
      "Batch: 59 of 105\n",
      "Loss in the past 480 samples: Localization 0.030677165339390435 Classification 0.059702664613723755\n",
      "Batch: 69 of 105\n",
      "Loss in the past 480 samples: Localization 0.03018046865860621 Classification 0.05963313281536102\n",
      "Batch: 79 of 105\n",
      "Loss in the past 480 samples: Localization 0.032016997287670775 Classification 0.0586032306154569\n",
      "Batch: 89 of 105\n",
      "Loss in the past 480 samples: Localization 0.030979292343060176 Classification 0.05860128253698349\n",
      "Batch: 99 of 105\n",
      "Loss in the past 480 samples: Localization 0.032188345491886136 Classification 0.0600065012772878\n",
      "loading annotations into memory...\n",
      "Done (t=0.81s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.39s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=34.70s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=3.14s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.153\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.271\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.154\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.014\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.129\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.299\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.158\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.213\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.219\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.023\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.193\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.424\n",
      "Model saved succesfully\n",
      "Model saved succesfully by loss\n",
      "Average train loss at eval start: Localization: 0.028221152876461604; Classification: 0.0566198864666602\n",
      "Total number of parameters trained this epoch:  4646218\n",
      "2020-08-23 16:59:54.037297\n",
      "Epoch: 32 of 64\n",
      "Batch: 245 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028069019100570743 Classification 0.05599637418420011\n",
      "Mean and max gradients over whole network:  tensor(16.6099) tensor(190.4125)\n",
      "Mean and max weights over whole network:  tensor(0.2591) tensor(0.7652)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 17:01:13.134762\n",
      "Epoch: 32 of 64\n",
      "Batch: 491 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02816861488813469 Classification 0.05615346721275066\n",
      "Mean and max gradients over whole network:  tensor(20.7327) tensor(252.9993)\n",
      "Mean and max weights over whole network:  tensor(0.2591) tensor(0.7652)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 17:02:31.871916\n",
      "Epoch: 32 of 64\n",
      "Batch: 737 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028353153134829952 Classification 0.05664104160658389\n",
      "Mean and max gradients over whole network:  tensor(13.6856) tensor(166.1140)\n",
      "Mean and max weights over whole network:  tensor(0.2591) tensor(0.7652)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 17:03:48.780134\n",
      "Epoch: 32 of 64\n",
      "Batch: 983 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028084318771917968 Classification 0.05625903184417141\n",
      "Mean and max gradients over whole network:  tensor(16.0795) tensor(181.1018)\n",
      "Mean and max weights over whole network:  tensor(0.2591) tensor(0.7652)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 17:05:07.804113\n",
      "Epoch: 32 of 64\n",
      "Batch: 1229 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027718034898483655 Classification 0.05595416498943396\n",
      "Mean and max gradients over whole network:  tensor(15.0950) tensor(162.6617)\n",
      "Mean and max weights over whole network:  tensor(0.2591) tensor(0.7650)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 17:06:26.319444\n",
      "Epoch: 32 of 64\n",
      "Batch: 1475 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028027184241953582 Classification 0.0567746039449684\n",
      "Mean and max gradients over whole network:  tensor(14.7558) tensor(156.5497)\n",
      "Mean and max weights over whole network:  tensor(0.2591) tensor(0.7650)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "2020-08-23 17:07:44.701812\n",
      "Epoch: 32 of 64\n",
      "Batch: 1721 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028095323011925227 Classification 0.05642093215289155\n",
      "Mean and max gradients over whole network:  tensor(19.6426) tensor(217.1755)\n",
      "Mean and max weights over whole network:  tensor(0.2591) tensor(0.7649)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 17:09:02.991155\n",
      "Epoch: 32 of 64\n",
      "Batch: 1967 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02803868829174255 Classification 0.056303072427992575\n",
      "Mean and max gradients over whole network:  tensor(16.3076) tensor(171.2230)\n",
      "Mean and max weights over whole network:  tensor(0.2591) tensor(0.7647)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 17:10:21.694825\n",
      "Epoch: 32 of 64\n",
      "Batch: 2213 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02818560746162726 Classification 0.056503266863383576\n",
      "Mean and max gradients over whole network:  tensor(19.1701) tensor(247.1223)\n",
      "Mean and max weights over whole network:  tensor(0.2591) tensor(0.7647)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 17:11:38.844853\n",
      "Epoch: 32 of 64\n",
      "Batch: 2459 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02812328703479392 Classification 0.05649554137857303\n",
      "Mean and max gradients over whole network:  tensor(17.5093) tensor(206.6159)\n",
      "Mean and max weights over whole network:  tensor(0.2591) tensor(0.7646)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "Total number of parameters trained this epoch:  4646218\n",
      "2020-08-23 17:14:26.673274\n",
      "Epoch: 33 of 64\n",
      "Batch: 245 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02764447851656737 Classification 0.05566125894142037\n",
      "Mean and max gradients over whole network:  tensor(15.9774) tensor(183.6954)\n",
      "Mean and max weights over whole network:  tensor(0.2591) tensor(0.7648)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 17:15:45.822100\n",
      "Epoch: 33 of 64\n",
      "Batch: 491 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028143747348772476 Classification 0.05624397434193267\n",
      "Mean and max gradients over whole network:  tensor(15.7637) tensor(179.0700)\n",
      "Mean and max weights over whole network:  tensor(0.2591) tensor(0.7647)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 17:17:03.569652\n",
      "Epoch: 33 of 64\n",
      "Batch: 737 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02811246751971684 Classification 0.05613237772853717\n",
      "Mean and max gradients over whole network:  tensor(17.1456) tensor(191.6579)\n",
      "Mean and max weights over whole network:  tensor(0.2591) tensor(0.7647)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 17:18:20.978304\n",
      "Epoch: 33 of 64\n",
      "Batch: 983 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02842244321636876 Classification 0.05632373874345769\n",
      "Mean and max gradients over whole network:  tensor(21.5936) tensor(270.6325)\n",
      "Mean and max weights over whole network:  tensor(0.2591) tensor(0.7646)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "2020-08-23 17:19:41.060007\n",
      "Epoch: 33 of 64\n",
      "Batch: 1229 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028086447548171693 Classification 0.056537497717998215\n",
      "Mean and max gradients over whole network:  tensor(16.4820) tensor(226.2451)\n",
      "Mean and max weights over whole network:  tensor(0.2591) tensor(0.7644)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 17:20:58.990795\n",
      "Epoch: 33 of 64\n",
      "Batch: 1475 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028359396251923023 Classification 0.0563804388732768\n",
      "Mean and max gradients over whole network:  tensor(15.2384) tensor(165.4906)\n",
      "Mean and max weights over whole network:  tensor(0.2591) tensor(0.7645)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 17:22:19.025330\n",
      "Epoch: 33 of 64\n",
      "Batch: 1721 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02846247929484056 Classification 0.056351077629298696\n",
      "Mean and max gradients over whole network:  tensor(18.6014) tensor(224.0854)\n",
      "Mean and max weights over whole network:  tensor(0.2591) tensor(0.7643)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 17:23:38.176385\n",
      "Epoch: 33 of 64\n",
      "Batch: 1967 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02829940907334086 Classification 0.05635751969607542\n",
      "Mean and max gradients over whole network:  tensor(16.7821) tensor(193.7189)\n",
      "Mean and max weights over whole network:  tensor(0.2591) tensor(0.7643)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 17:24:57.753477\n",
      "Epoch: 33 of 64\n",
      "Batch: 2213 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027801679023276498 Classification 0.056274926335346406\n",
      "Mean and max gradients over whole network:  tensor(20.9076) tensor(231.9510)\n",
      "Mean and max weights over whole network:  tensor(0.2591) tensor(0.7642)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 17:26:18.480787\n",
      "Epoch: 33 of 64\n",
      "Batch: 2459 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027778104432230073 Classification 0.05638913337777301\n",
      "Mean and max gradients over whole network:  tensor(16.7081) tensor(199.9361)\n",
      "Mean and max weights over whole network:  tensor(0.2591) tensor(0.7641)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "Validation start...\n",
      "2020-08-23 17:26:35.748901\n",
      "Batch: 9 of 105\n",
      "Loss in the past 480 samples: Localization 0.030455085883537927 Classification 0.05758254081010818\n",
      "Batch: 19 of 105\n",
      "Loss in the past 480 samples: Localization 0.029750275363524755 Classification 0.056485504905382795\n",
      "Batch: 29 of 105\n",
      "Loss in the past 480 samples: Localization 0.03126857802271843 Classification 0.05741486301024755\n",
      "Batch: 39 of 105\n",
      "Loss in the past 480 samples: Localization 0.027355033655961355 Classification 0.05486559222141902\n",
      "Batch: 49 of 105\n",
      "Loss in the past 480 samples: Localization 0.029896819094816843 Classification 0.06001345217227936\n",
      "Batch: 59 of 105\n",
      "Loss in the past 480 samples: Localization 0.0310672827064991 Classification 0.05966974298159281\n",
      "Batch: 69 of 105\n",
      "Loss in the past 480 samples: Localization 0.03025117442011833 Classification 0.059096294144789376\n",
      "Batch: 79 of 105\n",
      "Loss in the past 480 samples: Localization 0.03206159820159276 Classification 0.058658333122730257\n",
      "Batch: 89 of 105\n",
      "Loss in the past 480 samples: Localization 0.031176633884509405 Classification 0.05868662347396215\n",
      "Batch: 99 of 105\n",
      "Loss in the past 480 samples: Localization 0.03228554626305898 Classification 0.059809551139672595\n",
      "loading annotations into memory...\n",
      "Done (t=0.84s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=15.73s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=28.46s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=3.32s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.152\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.271\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.151\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.015\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.126\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.299\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.157\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.211\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.216\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.023\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.186\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.426\n",
      "Model saved succesfully by loss\n",
      "Average train loss at eval start: Localization: 0.028096211059923073; Classification: 0.05630378876652178\n",
      "Total number of parameters trained this epoch:  4646218\n",
      "2020-08-23 17:31:04.969977\n",
      "Epoch: 34 of 64\n",
      "Batch: 245 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027812410746688443 Classification 0.05585483411140235\n",
      "Mean and max gradients over whole network:  tensor(17.9154) tensor(218.5208)\n",
      "Mean and max weights over whole network:  tensor(0.2591) tensor(0.7642)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 17:32:27.415147\n",
      "Epoch: 34 of 64\n",
      "Batch: 491 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028142808141504844 Classification 0.05601154399031223\n",
      "Mean and max gradients over whole network:  tensor(15.9292) tensor(183.3350)\n",
      "Mean and max weights over whole network:  tensor(0.2591) tensor(0.7641)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "2020-08-23 17:33:48.652252\n",
      "Epoch: 34 of 64\n",
      "Batch: 737 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027992200262864753 Classification 0.05617890323242198\n",
      "Mean and max gradients over whole network:  tensor(15.7343) tensor(178.2009)\n",
      "Mean and max weights over whole network:  tensor(0.2591) tensor(0.7639)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 17:35:08.035394\n",
      "Epoch: 34 of 64\n",
      "Batch: 983 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028062277889954364 Classification 0.056125422601454304\n",
      "Mean and max gradients over whole network:  tensor(15.8815) tensor(178.8444)\n",
      "Mean and max weights over whole network:  tensor(0.2590) tensor(0.7638)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 17:36:26.874976\n",
      "Epoch: 34 of 64\n",
      "Batch: 1229 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028453668291733517 Classification 0.05615503617580021\n",
      "Mean and max gradients over whole network:  tensor(19.6252) tensor(276.6474)\n",
      "Mean and max weights over whole network:  tensor(0.2590) tensor(0.7637)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 17:37:50.550924\n",
      "Epoch: 34 of 64\n",
      "Batch: 1475 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028065668252425464 Classification 0.056428458470962235\n",
      "Mean and max gradients over whole network:  tensor(19.9831) tensor(225.6127)\n",
      "Mean and max weights over whole network:  tensor(0.2590) tensor(0.7636)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 17:39:13.140843\n",
      "Epoch: 34 of 64\n",
      "Batch: 1721 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027901022409803175 Classification 0.056295184100546486\n",
      "Mean and max gradients over whole network:  tensor(19.0119) tensor(227.7658)\n",
      "Mean and max weights over whole network:  tensor(0.2590) tensor(0.7637)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 17:40:32.011798\n",
      "Epoch: 34 of 64\n",
      "Batch: 1967 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02777681363428511 Classification 0.05605619342184971\n",
      "Mean and max gradients over whole network:  tensor(18.3499) tensor(191.1854)\n",
      "Mean and max weights over whole network:  tensor(0.2590) tensor(0.7636)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-23 17:41:55.417834\n",
      "Epoch: 34 of 64\n",
      "Batch: 2213 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02776678620274797 Classification 0.056083494852874984\n",
      "Mean and max gradients over whole network:  tensor(16.8319) tensor(178.0205)\n",
      "Mean and max weights over whole network:  tensor(0.2590) tensor(0.7634)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 17:43:17.897248\n",
      "Epoch: 34 of 64\n",
      "Batch: 2459 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027971225283373664 Classification 0.05599340445142451\n",
      "Mean and max gradients over whole network:  tensor(17.1434) tensor(190.2680)\n",
      "Mean and max weights over whole network:  tensor(0.2590) tensor(0.7634)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "Total number of parameters trained this epoch:  4646218\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "2020-08-23 17:46:02.262699\n",
      "Epoch: 35 of 64\n",
      "Batch: 245 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02806327632328036 Classification 0.05611595525570355\n",
      "Mean and max gradients over whole network:  tensor(17.0303) tensor(195.0189)\n",
      "Mean and max weights over whole network:  tensor(0.2590) tensor(0.7633)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 17:47:24.155973\n",
      "Epoch: 35 of 64\n",
      "Batch: 491 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027937593715906466 Classification 0.055716665416229064\n",
      "Mean and max gradients over whole network:  tensor(18.2951) tensor(227.6849)\n",
      "Mean and max weights over whole network:  tensor(0.2590) tensor(0.7633)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 17:48:45.789019\n",
      "Epoch: 35 of 64\n",
      "Batch: 737 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027903795494700512 Classification 0.05594588680884379\n",
      "Mean and max gradients over whole network:  tensor(17.8890) tensor(229.0652)\n",
      "Mean and max weights over whole network:  tensor(0.2590) tensor(0.7633)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 17:50:08.576804\n",
      "Epoch: 35 of 64\n",
      "Batch: 983 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028084254114406543 Classification 0.05587767763189507\n",
      "Mean and max gradients over whole network:  tensor(18.8300) tensor(205.5759)\n",
      "Mean and max weights over whole network:  tensor(0.2590) tensor(0.7633)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 17:51:28.145931\n",
      "Epoch: 35 of 64\n",
      "Batch: 1229 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02785937229630747 Classification 0.05613006522177358\n",
      "Mean and max gradients over whole network:  tensor(20.6582) tensor(240.7645)\n",
      "Mean and max weights over whole network:  tensor(0.2590) tensor(0.7631)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 17:52:47.343185\n",
      "Epoch: 35 of 64\n",
      "Batch: 1475 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027943709789495157 Classification 0.0559396372254948\n",
      "Mean and max gradients over whole network:  tensor(18.5748) tensor(205.2451)\n",
      "Mean and max weights over whole network:  tensor(0.2590) tensor(0.7630)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 17:54:06.302406\n",
      "Epoch: 35 of 64\n",
      "Batch: 1721 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027661515975265 Classification 0.056022602388367745\n",
      "Mean and max gradients over whole network:  tensor(18.3559) tensor(219.1111)\n",
      "Mean and max weights over whole network:  tensor(0.2590) tensor(0.7630)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 17:55:24.568040\n",
      "Epoch: 35 of 64\n",
      "Batch: 1967 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027959170945614658 Classification 0.05586237008090265\n",
      "Mean and max gradients over whole network:  tensor(16.3358) tensor(183.0592)\n",
      "Mean and max weights over whole network:  tensor(0.2590) tensor(0.7631)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 17:56:41.518000\n",
      "Epoch: 35 of 64\n",
      "Batch: 2213 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027880509517743658 Classification 0.05606661284680612\n",
      "Mean and max gradients over whole network:  tensor(38.4396) tensor(438.4189)\n",
      "Mean and max weights over whole network:  tensor(0.2590) tensor(0.7629)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "2020-08-23 17:57:57.387340\n",
      "Epoch: 35 of 64\n",
      "Batch: 2459 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027876389957459637 Classification 0.05610399267214747\n",
      "Mean and max gradients over whole network:  tensor(18.3519) tensor(213.1748)\n",
      "Mean and max weights over whole network:  tensor(0.2590) tensor(0.7630)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "Validation start...\n",
      "2020-08-23 17:58:13.223982\n",
      "Batch: 9 of 105\n",
      "Loss in the past 480 samples: Localization 0.03038435826698939 Classification 0.05767431408166886\n",
      "Batch: 19 of 105\n",
      "Loss in the past 480 samples: Localization 0.029310259471337 Classification 0.05628364731868108\n",
      "Batch: 29 of 105\n",
      "Loss in the past 480 samples: Localization 0.030867402255535126 Classification 0.056937962273756665\n",
      "Batch: 39 of 105\n",
      "Loss in the past 480 samples: Localization 0.027185850590467454 Classification 0.05485180815060933\n",
      "Batch: 49 of 105\n",
      "Loss in the past 480 samples: Localization 0.02985686684648196 Classification 0.05993017355600993\n",
      "Batch: 59 of 105\n",
      "Loss in the past 480 samples: Localization 0.030691678325335186 Classification 0.0592306653658549\n",
      "Batch: 69 of 105\n",
      "Loss in the past 480 samples: Localization 0.0299415685236454 Classification 0.059129600723584495\n",
      "Batch: 79 of 105\n",
      "Loss in the past 480 samples: Localization 0.03180615057547887 Classification 0.058162537217140195\n",
      "Batch: 89 of 105\n",
      "Loss in the past 480 samples: Localization 0.031135927885770798 Classification 0.05867642511924108\n",
      "Batch: 99 of 105\n",
      "Loss in the past 480 samples: Localization 0.031853998204072316 Classification 0.059555607537428536\n",
      "loading annotations into memory...\n",
      "Done (t=0.83s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.37s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=31.70s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=3.17s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.155\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.274\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.155\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.015\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.131\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.304\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.160\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.215\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.220\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.022\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.193\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.426\n",
      "Model saved succesfully\n",
      "Model saved succesfully by loss\n",
      "Average train loss at eval start: Localization: 0.027954566181378728; Classification: 0.05604065074185527\n",
      "Total number of parameters trained this epoch:  4646218\n",
      "2020-08-23 18:02:22.440238\n",
      "Epoch: 36 of 64\n",
      "Batch: 245 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027514262801303774 Classification 0.0553584773204514\n",
      "Mean and max gradients over whole network:  tensor(19.0166) tensor(209.7953)\n",
      "Mean and max weights over whole network:  tensor(0.2590) tensor(0.7629)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 18:03:40.888899\n",
      "Epoch: 36 of 64\n",
      "Batch: 491 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027992676711340907 Classification 0.05544865008211394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean and max gradients over whole network:  tensor(23.3809) tensor(269.0043)\n",
      "Mean and max weights over whole network:  tensor(0.2590) tensor(0.7627)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 18:04:59.784130\n",
      "Epoch: 36 of 64\n",
      "Batch: 737 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027749573322250268 Classification 0.055438233302214604\n",
      "Mean and max gradients over whole network:  tensor(18.1260) tensor(205.4706)\n",
      "Mean and max weights over whole network:  tensor(0.2590) tensor(0.7627)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 18:06:17.718376\n",
      "Epoch: 36 of 64\n",
      "Batch: 983 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027726063085846138 Classification 0.05579901107039232\n",
      "Mean and max gradients over whole network:  tensor(20.9611) tensor(256.7994)\n",
      "Mean and max weights over whole network:  tensor(0.2590) tensor(0.7626)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 18:07:35.375129\n",
      "Epoch: 36 of 64\n",
      "Batch: 1229 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027655468647920987 Classification 0.055584434167479435\n",
      "Mean and max gradients over whole network:  tensor(17.4700) tensor(208.0817)\n",
      "Mean and max weights over whole network:  tensor(0.2590) tensor(0.7626)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 18:08:51.635526\n",
      "Epoch: 36 of 64\n",
      "Batch: 1475 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027975772696781934 Classification 0.056082543581320345\n",
      "Mean and max gradients over whole network:  tensor(18.5139) tensor(189.3901)\n",
      "Mean and max weights over whole network:  tensor(0.2590) tensor(0.7626)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 18:10:08.753200\n",
      "Epoch: 36 of 64\n",
      "Batch: 1721 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02788003369014922 Classification 0.056036284198444385\n",
      "Mean and max gradients over whole network:  tensor(18.6110) tensor(200.1812)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7626)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "2020-08-23 18:11:26.754816\n",
      "Epoch: 36 of 64\n",
      "Batch: 1967 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027830338166133176 Classification 0.055987982064243255\n",
      "Mean and max gradients over whole network:  tensor(17.3290) tensor(191.4618)\n",
      "Mean and max weights over whole network:  tensor(0.2590) tensor(0.7626)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 18:12:41.298672\n",
      "Epoch: 36 of 64\n",
      "Batch: 2213 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028164598883854017 Classification 0.05594017516145215\n",
      "Mean and max gradients over whole network:  tensor(18.8352) tensor(208.3177)\n",
      "Mean and max weights over whole network:  tensor(0.2590) tensor(0.7625)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 18:13:56.850981\n",
      "Epoch: 36 of 64\n",
      "Batch: 2459 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027777849800056882 Classification 0.055655643121821446\n",
      "Mean and max gradients over whole network:  tensor(21.0114) tensor(235.6505)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7625)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "Total number of parameters trained this epoch:  4646218\n",
      "2020-08-23 18:16:35.131939\n",
      "Epoch: 37 of 64\n",
      "Batch: 245 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02776228544632917 Classification 0.055579553976614626\n",
      "Mean and max gradients over whole network:  tensor(16.3968) tensor(192.6557)\n",
      "Mean and max weights over whole network:  tensor(0.2590) tensor(0.7624)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 18:17:52.558702\n",
      "Epoch: 37 of 64\n",
      "Batch: 491 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027571053110406328 Classification 0.055529057212315276\n",
      "Mean and max gradients over whole network:  tensor(20.2937) tensor(270.1170)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7625)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 18:19:10.875777\n",
      "Epoch: 37 of 64\n",
      "Batch: 737 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027703608949050346 Classification 0.05565365232264769\n",
      "Mean and max gradients over whole network:  tensor(16.0833) tensor(188.3797)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7623)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 18:20:28.584022\n",
      "Epoch: 37 of 64\n",
      "Batch: 983 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02745199976817056 Classification 0.05537892472210938\n",
      "Mean and max gradients over whole network:  tensor(19.0192) tensor(221.3615)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7623)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 18:21:46.193821\n",
      "Epoch: 37 of 64\n",
      "Batch: 1229 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02780865198935112 Classification 0.05554573342890597\n",
      "Mean and max gradients over whole network:  tensor(15.8430) tensor(182.1009)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7623)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "2020-08-23 18:23:03.336043\n",
      "Epoch: 37 of 64\n",
      "Batch: 1475 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.028313481165626184 Classification 0.05624353847287212\n",
      "Mean and max gradients over whole network:  tensor(20.0669) tensor(222.7541)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7623)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 18:24:20.412470\n",
      "Epoch: 37 of 64\n",
      "Batch: 1721 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02826725422003405 Classification 0.055896434438260915\n",
      "Mean and max gradients over whole network:  tensor(19.0767) tensor(202.6256)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7622)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 18:25:38.096753\n",
      "Epoch: 37 of 64\n",
      "Batch: 1967 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027233591898871954 Classification 0.05562819661648293\n",
      "Mean and max gradients over whole network:  tensor(22.3198) tensor(256.6643)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7620)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 18:26:55.118691\n",
      "Epoch: 37 of 64\n",
      "Batch: 2213 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027676255071187407 Classification 0.055501426360632995\n",
      "Mean and max gradients over whole network:  tensor(17.0183) tensor(194.3726)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7619)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "2020-08-23 18:28:12.647308\n",
      "Epoch: 37 of 64\n",
      "Batch: 2459 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02826573879415104 Classification 0.055886257510521224\n",
      "Mean and max gradients over whole network:  tensor(18.9031) tensor(209.5657)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7619)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.002\n",
      "Validation start...\n",
      "2020-08-23 18:28:28.885108\n",
      "Batch: 9 of 105\n",
      "Loss in the past 480 samples: Localization 0.030426937093337377 Classification 0.057649927337964375\n",
      "Batch: 19 of 105\n",
      "Loss in the past 480 samples: Localization 0.029351157198349635 Classification 0.05655514349540074\n",
      "Batch: 29 of 105\n",
      "Loss in the past 480 samples: Localization 0.03118226776520411 Classification 0.05732081383466721\n",
      "Batch: 39 of 105\n",
      "Loss in the past 480 samples: Localization 0.02712226485212644 Classification 0.05482383718093236\n",
      "Batch: 49 of 105\n",
      "Loss in the past 480 samples: Localization 0.029977460950613023 Classification 0.0598159596323967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 59 of 105\n",
      "Loss in the past 480 samples: Localization 0.03060139740506808 Classification 0.059105439980824785\n",
      "Batch: 69 of 105\n",
      "Loss in the past 480 samples: Localization 0.03011988972624143 Classification 0.059161879618962604\n",
      "Batch: 79 of 105\n",
      "Loss in the past 480 samples: Localization 0.03185859347383181 Classification 0.05880132814248403\n",
      "Batch: 89 of 105\n",
      "Loss in the past 480 samples: Localization 0.030984878043333688 Classification 0.058638519545396166\n",
      "Batch: 99 of 105\n",
      "Loss in the past 480 samples: Localization 0.032158826291561124 Classification 0.05990212857723236\n",
      "loading annotations into memory...\n",
      "Done (t=0.84s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.39s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=35.80s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=3.19s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.154\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.275\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.153\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.015\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.131\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.301\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.158\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.214\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.219\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.022\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.193\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.427\n",
      "Average train loss at eval start: Localization: 0.02781436915799231; Classification: 0.0557018536880484\n",
      "Total number of parameters trained this epoch:  4646218\n",
      "2020-08-23 18:32:43.938249\n",
      "Epoch: 38 of 64\n",
      "Batch: 245 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027403283202995454 Classification 0.05514590357377277\n",
      "Mean and max gradients over whole network:  tensor(19.6473) tensor(218.2352)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7619)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 18:34:04.263633\n",
      "Epoch: 38 of 64\n",
      "Batch: 491 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02757048116224568 Classification 0.05459887340543716\n",
      "Mean and max gradients over whole network:  tensor(24.4584) tensor(300.6161)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7619)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 18:35:23.465235\n",
      "Epoch: 38 of 64\n",
      "Batch: 737 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027568129322877746 Classification 0.05469991759394566\n",
      "Mean and max gradients over whole network:  tensor(17.5834) tensor(213.1584)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7619)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "2020-08-23 18:36:42.064563\n",
      "Epoch: 38 of 64\n",
      "Batch: 983 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027541689317279714 Classification 0.05476630466982601\n",
      "Mean and max gradients over whole network:  tensor(19.1549) tensor(207.3839)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7619)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 18:37:59.874129\n",
      "Epoch: 38 of 64\n",
      "Batch: 1229 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02723383007515575 Classification 0.05450133028311458\n",
      "Mean and max gradients over whole network:  tensor(19.8673) tensor(254.7277)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7619)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 18:39:17.168368\n",
      "Epoch: 38 of 64\n",
      "Batch: 1475 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02712784517243464 Classification 0.05448215650672189\n",
      "Mean and max gradients over whole network:  tensor(14.6492) tensor(170.1288)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7619)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 18:40:36.178798\n",
      "Epoch: 38 of 64\n",
      "Batch: 1721 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027318783896927264 Classification 0.0543691372160666\n",
      "Mean and max gradients over whole network:  tensor(14.0663) tensor(167.0089)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7619)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 18:41:56.806150\n",
      "Epoch: 38 of 64\n",
      "Batch: 1967 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027209764205141443 Classification 0.05434062196633357\n",
      "Mean and max gradients over whole network:  tensor(16.5818) tensor(181.5202)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7619)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 18:43:20.689037\n",
      "Epoch: 38 of 64\n",
      "Batch: 2213 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02693853886712211 Classification 0.054225150546245784\n",
      "Mean and max gradients over whole network:  tensor(21.0076) tensor(285.9825)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7619)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 18:44:43.599056\n",
      "Epoch: 38 of 64\n",
      "Batch: 2459 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02763538110526758 Classification 0.05448933824048779\n",
      "Mean and max gradients over whole network:  tensor(14.4636) tensor(156.1534)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7618)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "Total number of parameters trained this epoch:  4646218\n",
      "2020-08-23 18:47:50.514221\n",
      "Epoch: 39 of 64\n",
      "Batch: 245 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027100866453515157 Classification 0.054161668974694196\n",
      "Mean and max gradients over whole network:  tensor(23.6327) tensor(276.9454)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7618)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "2020-08-23 18:49:09.942785\n",
      "Epoch: 39 of 64\n",
      "Batch: 491 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027244525141307332 Classification 0.054233072714269324\n",
      "Mean and max gradients over whole network:  tensor(15.2234) tensor(174.2159)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7618)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 18:50:31.366023\n",
      "Epoch: 39 of 64\n",
      "Batch: 737 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027377911992270125 Classification 0.05450510633427922\n",
      "Mean and max gradients over whole network:  tensor(17.7957) tensor(202.2391)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7618)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 18:51:48.667385\n",
      "Epoch: 39 of 64\n",
      "Batch: 983 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027093542224871432 Classification 0.05439100557872596\n",
      "Mean and max gradients over whole network:  tensor(15.6677) tensor(179.8479)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7618)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 18:53:06.700217\n",
      "Epoch: 39 of 64\n",
      "Batch: 1229 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.026829842548706344 Classification 0.05367445344039741\n",
      "Mean and max gradients over whole network:  tensor(21.2429) tensor(274.2606)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7618)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-23 18:54:22.347546\n",
      "Epoch: 39 of 64\n",
      "Batch: 1475 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027302158643115505 Classification 0.05426781675033776\n",
      "Mean and max gradients over whole network:  tensor(17.3164) tensor(206.9308)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7617)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 18:55:40.134992\n",
      "Epoch: 39 of 64\n",
      "Batch: 1721 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02704253332401679 Classification 0.05423245304402943\n",
      "Mean and max gradients over whole network:  tensor(19.5198) tensor(216.2828)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7618)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 18:56:55.033330\n",
      "Epoch: 39 of 64\n",
      "Batch: 1967 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027218345037805354 Classification 0.05409941832386058\n",
      "Mean and max gradients over whole network:  tensor(14.8626) tensor(164.7731)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7618)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 18:58:18.501004\n",
      "Epoch: 39 of 64\n",
      "Batch: 2213 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027203664809546172 Classification 0.05429840174713109\n",
      "Mean and max gradients over whole network:  tensor(16.4547) tensor(172.1275)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7618)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 18:59:39.775699\n",
      "Epoch: 39 of 64\n",
      "Batch: 2459 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02730531443849327 Classification 0.05432467703735279\n",
      "Mean and max gradients over whole network:  tensor(21.7341) tensor(230.5447)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7617)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "Validation start...\n",
      "2020-08-23 18:59:58.024494\n",
      "Batch: 9 of 105\n",
      "Loss in the past 480 samples: Localization 0.030011002967755 Classification 0.05662615199883779\n",
      "Batch: 19 of 105\n",
      "Loss in the past 480 samples: Localization 0.028904481480518978 Classification 0.05551252017418543\n",
      "Batch: 29 of 105\n",
      "Loss in the past 480 samples: Localization 0.030836880207061768 Classification 0.05636264830827713\n",
      "Batch: 39 of 105\n",
      "Loss in the past 480 samples: Localization 0.026773547132809956 Classification 0.05397489716609319\n",
      "Batch: 49 of 105\n",
      "Loss in the past 480 samples: Localization 0.02948840707540512 Classification 0.059110044439633684\n",
      "Batch: 59 of 105\n",
      "Loss in the past 480 samples: Localization 0.030228941639264425 Classification 0.05859599709510803\n",
      "Batch: 69 of 105\n",
      "Loss in the past 480 samples: Localization 0.02959000493089358 Classification 0.05787814905246099\n",
      "Batch: 79 of 105\n",
      "Loss in the past 480 samples: Localization 0.0314316600561142 Classification 0.057726327578226724\n",
      "Batch: 89 of 105\n",
      "Loss in the past 480 samples: Localization 0.030503326406081516 Classification 0.0577114666501681\n",
      "Batch: 99 of 105\n",
      "Loss in the past 480 samples: Localization 0.031664290279150006 Classification 0.05903373757998149\n",
      "loading annotations into memory...\n",
      "Done (t=0.83s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.38s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=27.88s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=3.28s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.159\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.281\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.160\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.017\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.136\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.310\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.163\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.220\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.025\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.200\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.434\n",
      "Model saved succesfully\n",
      "Model saved succesfully by loss\n",
      "Average train loss at eval start: Localization: 0.027261412587793046; Classification: 0.05438584236467934\n",
      "Total number of parameters trained this epoch:  4646218\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "2020-08-23 19:04:47.744984\n",
      "Epoch: 40 of 64\n",
      "Batch: 245 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.026979197220508323 Classification 0.054147509822677464\n",
      "Mean and max gradients over whole network:  tensor(23.3380) tensor(268.6691)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7617)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 19:06:19.137398\n",
      "Epoch: 40 of 64\n",
      "Batch: 491 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027167077658339568 Classification 0.05398052706708753\n",
      "Mean and max gradients over whole network:  tensor(17.5786) tensor(209.3109)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7617)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 19:07:51.866372\n",
      "Epoch: 40 of 64\n",
      "Batch: 737 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027116268696541063 Classification 0.05397091733246315\n",
      "Mean and max gradients over whole network:  tensor(17.8976) tensor(196.2533)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7617)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 19:09:22.319188\n",
      "Epoch: 40 of 64\n",
      "Batch: 983 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02736056767161784 Classification 0.05423396843962553\n",
      "Mean and max gradients over whole network:  tensor(16.4108) tensor(178.6140)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7617)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "2020-08-23 19:10:52.238200\n",
      "Epoch: 40 of 64\n",
      "Batch: 1229 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02683552630185112 Classification 0.053941007794403445\n",
      "Mean and max gradients over whole network:  tensor(13.0053) tensor(162.1917)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7617)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 19:12:20.467406\n",
      "Epoch: 40 of 64\n",
      "Batch: 1475 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027537887951303627 Classification 0.05421605130763558\n",
      "Mean and max gradients over whole network:  tensor(7.9575) tensor(83.9777)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7616)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 19:13:48.690370\n",
      "Epoch: 40 of 64\n",
      "Batch: 1721 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027028050788534368 Classification 0.05420014534781619\n",
      "Mean and max gradients over whole network:  tensor(7.8112) tensor(81.8745)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7616)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 19:15:16.363494\n",
      "Epoch: 40 of 64\n",
      "Batch: 1967 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02704771783273556 Classification 0.05409526671497479\n",
      "Mean and max gradients over whole network:  tensor(8.5624) tensor(91.7699)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7616)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-23 19:16:44.534118\n",
      "Epoch: 40 of 64\n",
      "Batch: 2213 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.026964208484705546 Classification 0.05411039997487856\n",
      "Mean and max gradients over whole network:  tensor(8.8729) tensor(94.3790)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7616)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 19:18:10.895029\n",
      "Epoch: 40 of 64\n",
      "Batch: 2459 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.026898970443826057 Classification 0.053821689108522926\n",
      "Mean and max gradients over whole network:  tensor(7.8489) tensor(85.8081)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7616)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "Total number of parameters trained this epoch:  4646218\n",
      "2020-08-23 19:21:09.858004\n",
      "Epoch: 41 of 64\n",
      "Batch: 245 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.0271141738971559 Classification 0.05394101326623906\n",
      "Mean and max gradients over whole network:  tensor(8.9027) tensor(96.0798)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7616)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 19:22:37.003257\n",
      "Epoch: 41 of 64\n",
      "Batch: 491 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.026988179395151978 Classification 0.05412444213864603\n",
      "Mean and max gradients over whole network:  tensor(8.2797) tensor(98.2899)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7616)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 19:23:57.321232\n",
      "Epoch: 41 of 64\n",
      "Batch: 737 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.026751780867334304 Classification 0.05348608368215199\n",
      "Mean and max gradients over whole network:  tensor(8.3143) tensor(88.0794)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7616)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 19:25:14.548461\n",
      "Epoch: 41 of 64\n",
      "Batch: 983 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02723263018338015 Classification 0.0540689387860983\n",
      "Mean and max gradients over whole network:  tensor(17.3534) tensor(179.7056)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7616)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 19:26:30.551309\n",
      "Epoch: 41 of 64\n",
      "Batch: 1229 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02684763170839325 Classification 0.053894725292517244\n",
      "Mean and max gradients over whole network:  tensor(20.1405) tensor(223.9928)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7616)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 19:27:45.049966\n",
      "Epoch: 41 of 64\n",
      "Batch: 1475 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.026954704421120607 Classification 0.05431557180193382\n",
      "Mean and max gradients over whole network:  tensor(15.4411) tensor(175.7561)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7616)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 19:28:59.305655\n",
      "Epoch: 41 of 64\n",
      "Batch: 1721 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027232401880629985 Classification 0.053926852458537754\n",
      "Mean and max gradients over whole network:  tensor(16.6791) tensor(192.2716)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7616)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 19:30:13.569451\n",
      "Epoch: 41 of 64\n",
      "Batch: 1967 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027215619321639944 Classification 0.054197406017683386\n",
      "Mean and max gradients over whole network:  tensor(21.2404) tensor(246.6980)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7616)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "2020-08-23 19:31:28.670157\n",
      "Epoch: 41 of 64\n",
      "Batch: 2213 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.026886403989703028 Classification 0.05410046269738577\n",
      "Mean and max gradients over whole network:  tensor(9.7621) tensor(112.4971)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7616)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 19:32:45.993144\n",
      "Epoch: 41 of 64\n",
      "Batch: 2459 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02745534247923188 Classification 0.05401778857155544\n",
      "Mean and max gradients over whole network:  tensor(10.2340) tensor(122.7794)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7616)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "Validation start...\n",
      "2020-08-23 19:33:04.018788\n",
      "Batch: 9 of 105\n",
      "Loss in the past 480 samples: Localization 0.029955208549896875 Classification 0.05647180179754893\n",
      "Batch: 19 of 105\n",
      "Loss in the past 480 samples: Localization 0.028845124443372092 Classification 0.055423456927140555\n",
      "Batch: 29 of 105\n",
      "Loss in the past 480 samples: Localization 0.030792878568172456 Classification 0.056110210716724396\n",
      "Batch: 39 of 105\n",
      "Loss in the past 480 samples: Localization 0.026656477153301238 Classification 0.053870666523774466\n",
      "Batch: 49 of 105\n",
      "Loss in the past 480 samples: Localization 0.02936180680990219 Classification 0.05900494158267975\n",
      "Batch: 59 of 105\n",
      "Loss in the past 480 samples: Localization 0.030237188935279845 Classification 0.05829780946175257\n",
      "Batch: 69 of 105\n",
      "Loss in the past 480 samples: Localization 0.029501606772343317 Classification 0.05753997663656871\n",
      "Batch: 79 of 105\n",
      "Loss in the past 480 samples: Localization 0.031406779090563455 Classification 0.05764749397834142\n",
      "Batch: 89 of 105\n",
      "Loss in the past 480 samples: Localization 0.03045451914270719 Classification 0.05762142737706502\n",
      "Batch: 99 of 105\n",
      "Loss in the past 480 samples: Localization 0.03154956003030141 Classification 0.05903508464495341\n",
      "loading annotations into memory...\n",
      "Done (t=0.80s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.35s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=26.35s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=3.10s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.159\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.282\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.160\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.017\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.137\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.311\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.162\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.219\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.224\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.025\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.432\n",
      "Model saved succesfully\n",
      "Model saved succesfully by loss\n",
      "Average train loss at eval start: Localization: 0.027077458677382815; Classification: 0.05403370017219773\n",
      "Total number of parameters trained this epoch:  4646218\n",
      "2020-08-23 19:37:29.773351\n",
      "Epoch: 42 of 64\n",
      "Batch: 245 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.026972977389003526 Classification 0.05378628568597602\n",
      "Mean and max gradients over whole network:  tensor(8.3983) tensor(95.2728)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7616)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 19:38:48.922298\n",
      "Epoch: 42 of 64\n",
      "Batch: 491 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.026666726074042683 Classification 0.05351242526033061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean and max gradients over whole network:  tensor(9.4239) tensor(101.3348)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7616)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 19:40:07.171015\n",
      "Epoch: 42 of 64\n",
      "Batch: 737 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.026762476064729174 Classification 0.053667147671627155\n",
      "Mean and max gradients over whole network:  tensor(8.0334) tensor(87.2319)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7616)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 19:41:24.916888\n",
      "Epoch: 42 of 64\n",
      "Batch: 983 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.026716709207632354 Classification 0.05417352918848436\n",
      "Mean and max gradients over whole network:  tensor(9.8996) tensor(110.5302)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7615)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n"
     ]
    }
   ],
   "source": [
    "# train from scratch\n",
    "import main\n",
    "main.run(train_model=True, load_checkpoint=True, cross_validate=False,\n",
    "        validate=False, mixed_precision=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer : sgd\n",
      "learning_rate : 0.05\n",
      "lr_policy : retina\n",
      "batch_size : 48\n",
      "mapping_threshold : 0.5\n",
      "conf_threshold : 0.1\n",
      "suppress_threshold : 0.5333333333333333\n",
      "weight_decay : 0.0002\n",
      "loss_type : softmax\n",
      "use_focal_loss : 0\n",
      "use_hard_negative_mining : 1\n",
      "n_epochs : 64\n",
      "first_decay : 20\n",
      "second_decay : 38\n",
      "third_decay : 53\n",
      "decay_rate : 0.1\n",
      "freeze_backbone : 0\n",
      "zero_bn_bias_decay : 1\n",
      "input_height : 320\n",
      "input_width : 320\n",
      "warm_up : 3\n",
      "channels_list : [576, 1280, 512, 256, 256, 128]\n",
      "List of anchors per feature map cell:  [4, 6, 6, 6, 6, 6]\n",
      "Model ID:  ssdlite\n",
      "-------------------------------------------------------\n",
      "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Model loaded successfully from epoch:  42\n",
      "Total number of parameters of model:  4646218\n",
      "Total number of trainable parameters of model:  4646218\n",
      "Total number of parameters given to optimizer: \n",
      "4646218\n",
      "Total number of trainable parameters given to optimizer: \n",
      "4646218\n",
      "-------------------------------------------------------\n",
      "loading annotations into memory...\n",
      "Done (t=22.12s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.78s)\n",
      "creating index...\n",
      "index created!\n",
      "Train size:  2464 118287 118287\n",
      "Val size:  105 5000 5000\n",
      "-------------------------------------------------------\n",
      "2020-08-23 19:46:42.360257\n",
      "Total number of parameters trained this epoch:  4646218\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "2020-08-23 19:49:48.954606\n",
      "Epoch: 42 of 64\n",
      "Batch: 245 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027002040084784594 Classification 0.05372910048095837\n",
      "Mean and max gradients over whole network:  tensor(15.2431) tensor(160.4804)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7616)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "2020-08-23 19:51:14.924023\n",
      "Epoch: 42 of 64\n",
      "Batch: 491 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.026667026500028324 Classification 0.05345278158582\n",
      "Mean and max gradients over whole network:  tensor(7.9917) tensor(85.3465)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7616)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 19:52:38.198855\n",
      "Epoch: 42 of 64\n",
      "Batch: 737 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.026693566775499642 Classification 0.0535260045593024\n",
      "Mean and max gradients over whole network:  tensor(7.4259) tensor(79.6248)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7616)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 19:53:58.634709\n",
      "Epoch: 42 of 64\n",
      "Batch: 983 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.026482836164150456 Classification 0.05321878776317689\n",
      "Mean and max gradients over whole network:  tensor(11.0799) tensor(127.5171)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7616)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 19:55:18.626258\n",
      "Epoch: 42 of 64\n",
      "Batch: 1229 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.026784929085957 Classification 0.05363066466197089\n",
      "Mean and max gradients over whole network:  tensor(7.4224) tensor(79.3596)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7615)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 19:56:36.157689\n",
      "Epoch: 42 of 64\n",
      "Batch: 1475 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02669327793930604 Classification 0.053530415848180204\n",
      "Mean and max gradients over whole network:  tensor(8.6132) tensor(99.6749)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7615)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 19:57:53.313522\n",
      "Epoch: 42 of 64\n",
      "Batch: 1721 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027067624128405965 Classification 0.053276645680914725\n",
      "Mean and max gradients over whole network:  tensor(12.1978) tensor(151.2638)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7616)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 19:59:10.666985\n",
      "Epoch: 42 of 64\n",
      "Batch: 1967 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.026824965553110855 Classification 0.05365555592103379\n",
      "Mean and max gradients over whole network:  tensor(7.3157) tensor(89.5791)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7615)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 20:00:28.656091\n",
      "Epoch: 42 of 64\n",
      "Batch: 2213 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02664267215221555 Classification 0.05341397740734302\n",
      "Mean and max gradients over whole network:  tensor(7.6276) tensor(88.7105)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7615)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 20:01:48.567994\n",
      "Epoch: 42 of 64\n",
      "Batch: 2459 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02640052186198997 Classification 0.0530193451701141\n",
      "Mean and max gradients over whole network:  tensor(20.1537) tensor(247.9772)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7615)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "Total number of parameters trained this epoch:  4646218\n",
      "2020-08-23 20:04:31.697015\n",
      "Epoch: 43 of 64\n",
      "Batch: 245 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.026826833079500897 Classification 0.05309381764028777\n",
      "Mean and max gradients over whole network:  tensor(19.3965) tensor(239.4452)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7615)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 20:05:49.990388\n",
      "Epoch: 43 of 64\n",
      "Batch: 491 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.026932945888903406 Classification 0.05359928647111748\n",
      "Mean and max gradients over whole network:  tensor(16.9564) tensor(205.4403)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7615)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 20:07:07.950041\n",
      "Epoch: 43 of 64\n",
      "Batch: 737 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.026654046367056324 Classification 0.05361702965527046\n",
      "Mean and max gradients over whole network:  tensor(19.0153) tensor(233.1175)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7615)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 20:08:24.864719\n",
      "Epoch: 43 of 64\n",
      "Batch: 983 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.0266690088895359 Classification 0.05355228784526913\n",
      "Mean and max gradients over whole network:  tensor(15.0758) tensor(161.3660)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7615)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 20:09:38.320091\n",
      "Epoch: 43 of 64\n",
      "Batch: 1229 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.026318399200271462 Classification 0.05304836128462298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean and max gradients over whole network:  tensor(17.6608) tensor(205.6218)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7615)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 20:10:52.909932\n",
      "Epoch: 43 of 64\n",
      "Batch: 1475 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02669324996934189 Classification 0.053399765313802375\n",
      "Mean and max gradients over whole network:  tensor(19.3519) tensor(243.9951)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7615)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 20:12:06.610343\n",
      "Epoch: 43 of 64\n",
      "Batch: 1721 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02673624907203806 Classification 0.0535121438747176\n",
      "Mean and max gradients over whole network:  tensor(15.9051) tensor(171.0041)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7615)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "2020-08-23 20:13:21.367378\n",
      "Epoch: 43 of 64\n",
      "Batch: 1967 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.026794859150116684 Classification 0.05315621574800512\n",
      "Mean and max gradients over whole network:  tensor(16.0348) tensor(183.5807)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7615)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 20:14:37.353684\n",
      "Epoch: 43 of 64\n",
      "Batch: 2213 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02660796412728666 Classification 0.05317878676704598\n",
      "Mean and max gradients over whole network:  tensor(17.6322) tensor(194.9662)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7615)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 20:15:50.939837\n",
      "Epoch: 43 of 64\n",
      "Batch: 2459 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.0264095616574856 Classification 0.052770753600571534\n",
      "Mean and max gradients over whole network:  tensor(17.4431) tensor(197.4625)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7615)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "Validation start...\n",
      "2020-08-23 20:16:08.282717\n",
      "Batch: 9 of 105\n",
      "Loss in the past 480 samples: Localization 0.029944446682929993 Classification 0.056302203238010405\n",
      "Batch: 19 of 105\n",
      "Loss in the past 480 samples: Localization 0.028788989782333373 Classification 0.055363895495732625\n",
      "Batch: 29 of 105\n",
      "Loss in the past 480 samples: Localization 0.030756773054599763 Classification 0.05597852716843287\n",
      "Batch: 39 of 105\n",
      "Loss in the past 480 samples: Localization 0.026658139377832412 Classification 0.05375131169954936\n",
      "Batch: 49 of 105\n",
      "Loss in the past 480 samples: Localization 0.029337280491987864 Classification 0.05886179059743881\n",
      "Batch: 59 of 105\n",
      "Loss in the past 480 samples: Localization 0.030069421231746673 Classification 0.05818315297365188\n",
      "Batch: 69 of 105\n",
      "Loss in the past 480 samples: Localization 0.02946595475077629 Classification 0.05767274349927902\n",
      "Batch: 79 of 105\n",
      "Loss in the past 480 samples: Localization 0.03138339395324389 Classification 0.05752804974714915\n",
      "Batch: 89 of 105\n",
      "Loss in the past 480 samples: Localization 0.030435900390148162 Classification 0.05746125231186549\n",
      "Batch: 99 of 105\n",
      "Loss in the past 480 samples: Localization 0.031485833475987116 Classification 0.05893559902906418\n",
      "loading annotations into memory...\n",
      "Done (t=0.81s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.35s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=33.45s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.59s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.160\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.283\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.160\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.017\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.138\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.313\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.163\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.220\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.025\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.200\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.433\n",
      "Model saved succesfully\n",
      "Model saved succesfully by loss\n",
      "Average train loss at eval start: Localization: 0.0266920070050993; Classification: 0.053361450862820826\n",
      "Total number of parameters trained this epoch:  4646218\n",
      "2020-08-23 20:20:14.219058\n",
      "Epoch: 44 of 64\n",
      "Batch: 245 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.0267777608601543 Classification 0.05344174218775457\n",
      "Mean and max gradients over whole network:  tensor(24.8156) tensor(276.2627)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7615)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 20:21:34.236327\n",
      "Epoch: 44 of 64\n",
      "Batch: 491 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.0270573090620561 Classification 0.05395505950864415\n",
      "Mean and max gradients over whole network:  tensor(16.6359) tensor(193.0732)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7615)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 20:22:53.811291\n",
      "Epoch: 44 of 64\n",
      "Batch: 737 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.026994521989610783 Classification 0.05355327982243484\n",
      "Mean and max gradients over whole network:  tensor(17.1537) tensor(194.5062)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7614)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 20:24:12.352225\n",
      "Epoch: 44 of 64\n",
      "Batch: 983 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02675485629638844 Classification 0.05335984750572582\n",
      "Mean and max gradients over whole network:  tensor(20.6988) tensor(232.8442)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7614)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 20:25:29.761314\n",
      "Epoch: 44 of 64\n",
      "Batch: 1229 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027148506460272198 Classification 0.053879880202494984\n",
      "Mean and max gradients over whole network:  tensor(21.7876) tensor(273.7700)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7614)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "2020-08-23 20:26:47.360553\n",
      "Epoch: 44 of 64\n",
      "Batch: 1475 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.026564927332527268 Classification 0.053445495180482784\n",
      "Mean and max gradients over whole network:  tensor(18.5351) tensor(200.2459)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7614)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 20:28:08.372029\n",
      "Epoch: 44 of 64\n",
      "Batch: 1721 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02692759729578566 Classification 0.05355352710498381\n",
      "Mean and max gradients over whole network:  tensor(17.1741) tensor(187.9218)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7614)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 20:29:30.003653\n",
      "Epoch: 44 of 64\n",
      "Batch: 1967 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02644971220029725 Classification 0.05338072887846448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean and max gradients over whole network:  tensor(17.7421) tensor(183.1655)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7614)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 20:30:49.950236\n",
      "Epoch: 44 of 64\n",
      "Batch: 2213 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.026705083212636028 Classification 0.05376982081146421\n",
      "Mean and max gradients over whole network:  tensor(19.7345) tensor(218.7263)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7613)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "2020-08-23 20:32:09.526333\n",
      "Epoch: 44 of 64\n",
      "Batch: 2459 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.026932897651946643 Classification 0.0537697557551751\n",
      "Mean and max gradients over whole network:  tensor(11.5915) tensor(135.2820)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7613)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "Total number of parameters trained this epoch:  4646218\n",
      "2020-08-23 20:34:45.358072\n",
      "Epoch: 45 of 64\n",
      "Batch: 245 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.026777208265331056 Classification 0.05324754456113671\n",
      "Mean and max gradients over whole network:  tensor(8.9903) tensor(107.1236)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7613)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 20:36:05.753275\n",
      "Epoch: 45 of 64\n",
      "Batch: 491 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.026639278725718418 Classification 0.05340563713858121\n",
      "Mean and max gradients over whole network:  tensor(8.9635) tensor(105.3924)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7613)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 20:37:25.741475\n",
      "Epoch: 45 of 64\n",
      "Batch: 737 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.027002890475679865 Classification 0.053561037633477186\n",
      "Mean and max gradients over whole network:  tensor(10.2031) tensor(116.0767)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7613)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 20:38:45.627461\n",
      "Epoch: 45 of 64\n",
      "Batch: 983 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.0268950369713833 Classification 0.0535549596759685\n",
      "Mean and max gradients over whole network:  tensor(10.5278) tensor(123.6415)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7612)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 20:40:02.899000\n",
      "Epoch: 45 of 64\n",
      "Batch: 1229 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02678800872993986 Classification 0.05376868386094163\n",
      "Mean and max gradients over whole network:  tensor(9.2972) tensor(101.5346)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7613)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 20:41:20.751774\n",
      "Epoch: 45 of 64\n",
      "Batch: 1475 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.026944239974668032 Classification 0.05351143590803069\n",
      "Mean and max gradients over whole network:  tensor(10.3354) tensor(124.4670)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7613)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 20:42:39.470779\n",
      "Epoch: 45 of 64\n",
      "Batch: 1721 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.026817823717305008 Classification 0.05315253524195534\n",
      "Mean and max gradients over whole network:  tensor(10.5945) tensor(120.6083)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7613)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 20:43:58.194196\n",
      "Epoch: 45 of 64\n",
      "Batch: 1967 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.026938346186829453 Classification 0.05345033624065601\n",
      "Mean and max gradients over whole network:  tensor(17.3823) tensor(208.8647)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7613)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 20:45:15.131388\n",
      "Epoch: 45 of 64\n",
      "Batch: 2213 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.026724618862113008 Classification 0.05364810941907448\n",
      "Mean and max gradients over whole network:  tensor(19.3818) tensor(201.4180)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7613)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 20:46:31.246075\n",
      "Epoch: 45 of 64\n",
      "Batch: 2459 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.026562761363944386 Classification 0.05373992031909586\n",
      "Mean and max gradients over whole network:  tensor(17.0317) tensor(181.5561)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7612)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "Validation start...\n",
      "2020-08-23 20:46:46.779155\n",
      "Batch: 9 of 105\n",
      "Loss in the past 480 samples: Localization 0.029913326849540074 Classification 0.05625621825456619\n",
      "Batch: 19 of 105\n",
      "Loss in the past 480 samples: Localization 0.028876364727814994 Classification 0.055331818262736004\n",
      "Batch: 29 of 105\n",
      "Loss in the past 480 samples: Localization 0.03082717830936114 Classification 0.055961355566978455\n",
      "Batch: 39 of 105\n",
      "Loss in the past 480 samples: Localization 0.026622289170821507 Classification 0.05379912356535594\n",
      "Batch: 49 of 105\n",
      "Loss in the past 480 samples: Localization 0.029385721186796825 Classification 0.05870941480000814\n",
      "Batch: 59 of 105\n",
      "Loss in the past 480 samples: Localization 0.030017094562451045 Classification 0.05813136796156566\n",
      "Batch: 69 of 105\n",
      "Loss in the past 480 samples: Localization 0.0294048177699248 Classification 0.05762709577878316\n",
      "Batch: 79 of 105\n",
      "Loss in the past 480 samples: Localization 0.03120490536093712 Classification 0.05730444689591726\n",
      "Batch: 89 of 105\n",
      "Loss in the past 480 samples: Localization 0.03031914234161377 Classification 0.05750039368867874\n",
      "Batch: 99 of 105\n",
      "Loss in the past 480 samples: Localization 0.03138273879885674 Classification 0.0588263417283694\n",
      "loading annotations into memory...\n",
      "Done (t=0.82s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.35s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=30.21s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=3.09s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.160\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.283\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.160\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.017\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.137\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.314\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.163\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.220\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.025\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.435\n",
      "Model saved succesfully\n",
      "Model saved succesfully by loss\n",
      "Average train loss at eval start: Localization: 0.026819180441820613; Classification: 0.05355046619959752\n",
      "Total number of parameters trained this epoch:  4646218\n",
      "2020-08-23 20:50:58.301392\n",
      "Epoch: 46 of 64\n",
      "Batch: 245 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.026523131695462436 Classification 0.05342870736671334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean and max gradients over whole network:  tensor(18.5198) tensor(186.9685)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7612)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n",
      "2020-08-23 20:52:21.558995\n",
      "Epoch: 46 of 64\n",
      "Batch: 491 of 2464\n",
      "Loss in the past 11808 samples: Localization 0.02694187752478491 Classification 0.05326218644616403\n",
      "Mean and max gradients over whole network:  tensor(21.7740) tensor(304.9279)\n",
      "Mean and max weights over whole network:  tensor(0.2589) tensor(0.7612)\n",
      "-------------------------------------------------------\n",
      "Current learning_rate: 0.00020000000000000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 421, in execute_request\n",
      "    self._abort_queues()\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 636, in _abort_queues\n",
      "    self._abort_queue(stream)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 661, in _abort_queue\n",
      "    poller.poll(50)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\zmq\\sugar\\poll.py\", line 99, in poll\n",
      "    return zmq_poll(self.sockets, timeout=timeout)\n",
      "  File \"zmq\\backend\\cython\\_poll.pyx\", line 123, in zmq.backend.cython._poll.zmq_poll\n",
      "  File \"zmq\\backend\\cython\\checkrc.pxd\", line 12, in zmq.backend.cython.checkrc._check_rc\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# train from scratch\n",
    "import main\n",
    "main.run(train_model=True, load_checkpoint=True, cross_validate=False,\n",
    "        validate=False, mixed_precision=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer : sgd\n",
      "learning_rate : 0.015\n",
      "lr_policy : retina\n",
      "batch_size : 48\n",
      "mapping_threshold : 0.5\n",
      "conf_threshold : 0.1\n",
      "suppress_threshold : 0.5333333333333333\n",
      "weight_decay : 4e-05\n",
      "loss_type : softmax\n",
      "use_focal_loss : 0\n",
      "use_hard_negative_mining : 1\n",
      "n_epochs : 80\n",
      "first_decay : 28\n",
      "second_decay : 51\n",
      "third_decay : 68\n",
      "decay_rate : 0.1\n",
      "freeze_backbone : 0\n",
      "zero_bn_bias_decay : 1\n",
      "input_height : 320\n",
      "input_width : 320\n",
      "warm_up : 4\n",
      "channels_list : [576, 1280, 512, 256, 256, 128]\n",
      "List of anchors per feature map cell:  [4, 6, 6, 6, 6, 6]\n",
      "Model ID:  ssdlite\n",
      "-------------------------------------------------------\n",
      "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Model loaded successfully from epoch:  78\n",
      "Total number of parameters of model:  4646218\n",
      "Total number of trainable parameters of model:  4646218\n",
      "Total number of parameters given to optimizer: \n",
      "4646218\n",
      "Total number of trainable parameters given to optimizer: \n",
      "4646218\n",
      "-------------------------------------------------------\n",
      "loading annotations into memory...\n",
      "Done (t=0.72s)\n",
      "creating index...\n",
      "index created!\n",
      "[0.01, 0.03, 0.05, 0.06999999999999999, 0.09]\n",
      "[0.45, 0.5166666666666667, 0.5833333333333334]\n",
      "Current best hyperparams: \n",
      "Confidence:  0 Suppress:  0\n",
      "Currently trying:  0.01 0.45\n",
      "Done  1  batches\n",
      "Done  51  batches\n",
      "Done  101  batches\n",
      "loading annotations into memory...\n",
      "Done (t=0.72s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=2.74s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=43.34s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=5.77s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.175\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.316\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.173\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.156\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.340\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.180\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.248\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.256\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.038\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.246\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.481\n",
      "Current mAP:  0.17486652720266388\n",
      "New best values found\n",
      "Params saved succesfully\n",
      "Current best hyperparams: \n",
      "Confidence:  0.01 Suppress:  0.45\n",
      "Currently trying:  0.01 0.5166666666666667\n",
      "Done  1  batches\n",
      "Done  51  batches\n",
      "Done  101  batches\n",
      "loading annotations into memory...\n",
      "Done (t=0.71s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=2.89s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=48.33s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=6.26s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.176\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.315\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.174\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.158\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.341\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.180\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.254\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.265\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.041\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.258\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.493\n",
      "Current mAP:  0.17585358658339031\n",
      "New best values found\n",
      "Params saved succesfully\n",
      "Current best hyperparams: \n",
      "Confidence:  0.01 Suppress:  0.5166666666666667\n",
      "Currently trying:  0.01 0.5833333333333334\n",
      "Done  1  batches\n",
      "Done  51  batches\n",
      "Done  101  batches\n",
      "loading annotations into memory...\n",
      "Done (t=0.72s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=3.16s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=54.16s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=6.81s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.176\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.311\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.176\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.022\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.159\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.341\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.180\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.260\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.275\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.044\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.270\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.508\n",
      "Current mAP:  0.17609507838302507\n",
      "New best values found\n",
      "Params saved succesfully\n",
      "Current best hyperparams: \n",
      "Confidence:  0.01 Suppress:  0.5833333333333334\n",
      "Currently trying:  0.03 0.45\n",
      "Done  1  batches\n",
      "Done  51  batches\n",
      "Done  101  batches\n",
      "loading annotations into memory...\n",
      "Done (t=0.71s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=1.15s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=41.45s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=5.44s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.175\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.316\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.173\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.156\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.340\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.180\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.248\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.256\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.038\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.245\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.481\n",
      "Current mAP:  0.17480796249877978\n",
      "Current best hyperparams: \n",
      "Confidence:  0.01 Suppress:  0.5833333333333334\n",
      "Currently trying:  0.03 0.5166666666666667\n",
      "Done  1  batches\n",
      "Done  51  batches\n",
      "Done  101  batches\n",
      "loading annotations into memory...\n",
      "Done (t=0.70s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=2.70s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=46.65s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=5.88s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.176\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.315\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.174\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.158\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.341\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.180\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.253\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.265\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.041\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.257\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current mAP:  0.17579712169150216\n",
      "Current best hyperparams: \n",
      "Confidence:  0.01 Suppress:  0.5833333333333334\n",
      "Currently trying:  0.03 0.5833333333333334\n",
      "Done  1  batches\n",
      "Done  51  batches\n",
      "Done  101  batches\n",
      "loading annotations into memory...\n",
      "Done (t=0.70s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=2.96s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=52.42s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=6.50s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.176\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.311\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.176\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.022\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.159\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.341\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.180\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.259\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.274\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.043\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.268\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.507\n",
      "Current mAP:  0.176042949245811\n",
      "Current best hyperparams: \n",
      "Confidence:  0.01 Suppress:  0.5833333333333334\n",
      "Currently trying:  0.05 0.45\n",
      "Done  1  batches\n",
      "Done  51  batches\n",
      "Done  101  batches\n",
      "loading annotations into memory...\n",
      "Done (t=0.70s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=2.22s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=37.96s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.55s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.174\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.315\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.173\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.020\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.155\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.339\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.179\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.245\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.252\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.036\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.241\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.476\n",
      "Current mAP:  0.17443989503207855\n",
      "Current best hyperparams: \n",
      "Confidence:  0.01 Suppress:  0.5833333333333334\n",
      "Currently trying:  0.05 0.5166666666666667\n",
      "Done  1  batches\n",
      "Done  51  batches\n",
      "Done  101  batches\n",
      "loading annotations into memory...\n",
      "Done (t=0.71s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=2.40s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=41.86s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.88s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.175\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.314\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.174\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.158\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.340\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.179\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.250\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.261\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.039\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.253\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.486\n",
      "Current mAP:  0.17538698935222477\n",
      "Current best hyperparams: \n",
      "Confidence:  0.01 Suppress:  0.5833333333333334\n",
      "Currently trying:  0.05 0.5833333333333334\n",
      "Done  1  batches\n",
      "Done  51  batches\n",
      "Done  101  batches\n",
      "loading annotations into memory...\n",
      "Done (t=0.71s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=2.69s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=46.77s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=5.17s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.176\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.310\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.175\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.022\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.158\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.340\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.179\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.256\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.270\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.042\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.264\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.498\n",
      "Current mAP:  0.17569154470523557\n",
      "Current best hyperparams: \n",
      "Confidence:  0.01 Suppress:  0.5833333333333334\n",
      "Currently trying:  0.06999999999999999 0.45\n",
      "Done  1  batches\n",
      "Done  51  batches\n",
      "Done  101  batches\n",
      "loading annotations into memory...\n",
      "Done (t=0.70s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=1.89s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=31.92s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=3.61s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.174\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.312\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.172\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.019\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.154\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.338\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.177\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.239\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.246\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.033\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.232\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.466\n",
      "Current mAP:  0.1735433981307778\n",
      "Current best hyperparams: \n",
      "Confidence:  0.01 Suppress:  0.5833333333333334\n",
      "Currently trying:  0.06999999999999999 0.5166666666666667\n",
      "Done  1  batches\n",
      "Done  51  batches\n",
      "Done  101  batches\n",
      "loading annotations into memory...\n",
      "Done (t=0.70s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=1.99s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=35.41s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=3.80s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.175\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.312\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.173\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.020\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.156\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.339\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.177\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.244\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.253\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.035\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.242\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current mAP:  0.17454092512440636\n",
      "Current best hyperparams: \n",
      "Confidence:  0.01 Suppress:  0.5833333333333334\n",
      "Currently trying:  0.06999999999999999 0.5833333333333334\n",
      "Done  1  batches\n",
      "Done  51  batches\n",
      "Done  101  batches\n",
      "loading annotations into memory...\n",
      "Done (t=0.71s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=2.12s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=39.08s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.08s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.175\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.308\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.175\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.157\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.339\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.177\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.250\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.261\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.037\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.252\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.487\n",
      "Current mAP:  0.17483165788871766\n",
      "Current best hyperparams: \n",
      "Confidence:  0.01 Suppress:  0.5833333333333334\n",
      "Currently trying:  0.09 0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-2-60f97f3f599e>\", line 4, in <module>\n",
      "    validate=False, mixed_precision=True)\n",
      "  File \"C:\\Users\\Andrei Popovici\\Documents\\GitHub\\drl_zice_ca_se_poate_schimba_DA_MA\\main.py\", line 87, in run\n",
      "    model, detection_loss, valid_loader, model_evaluator, params, stats)\n",
      "  File \"C:\\Users\\Andrei Popovici\\Documents\\GitHub\\drl_zice_ca_se_poate_schimba_DA_MA\\misc\\cross_validation.py\", line 30, in cross_validate\n",
      "    cur_mAP = model_evaluator.only_mAP(model)\n",
      "  File \"C:\\Users\\Andrei Popovici\\Documents\\GitHub\\drl_zice_ca_se_poate_schimba_DA_MA\\train\\validate.py\", line 84, in only_mAP\n",
      "    for batch_idx, (input_, label, image_info) in enumerate(self.valid_loader):\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 279, in __iter__\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 719, in __init__\n",
      "    w.start()\n",
      "  File \"c:\\program files\\python36\\lib\\multiprocessing\\process.py\", line 105, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"c:\\program files\\python36\\lib\\multiprocessing\\context.py\", line 223, in _Popen\n",
      "    return _default_context.get_context().Process._Popen(process_obj)\n",
      "  File \"c:\\program files\\python36\\lib\\multiprocessing\\context.py\", line 322, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"c:\\program files\\python36\\lib\\multiprocessing\\popen_spawn_win32.py\", line 65, in __init__\n",
      "    reduction.dump(process_obj, to_child)\n",
      "  File \"c:\\program files\\python36\\lib\\multiprocessing\\reduction.py\", line 60, in dump\n",
      "    ForkingPickler(file, protocol).dump(obj)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1148, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"c:\\program files\\python36\\lib\\inspect.py\", line 1480, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"c:\\program files\\python36\\lib\\inspect.py\", line 1438, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"c:\\program files\\python36\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"c:\\program files\\python36\\lib\\inspect.py\", line 736, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"c:\\program files\\python36\\lib\\inspect.py\", line 705, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"c:\\program files\\python36\\lib\\inspect.py\", line 690, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"c:\\program files\\python36\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "# train from scratch\n",
    "import main\n",
    "main.run(train_model=False, load_checkpoint=True, cross_validate=True,\n",
    "        validate=False, mixed_precision=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dorel\\Documents\\COCO\n",
      "True\n",
      "Weigths loaded successfully\n",
      "Source directory:  C:\\Users\\Dorel\\Documents\\GitHub\\MIRPR-pedestrian-and-vehicle-detection-SSDLite\\custom_inference\\samples\n",
      "Source directory:  C:\\Users\\Dorel\\Documents\\GitHub\\MIRPR-pedestrian-and-vehicle-detection-SSDLite\\custom_inference\\video_sample\\video.mp4\n",
      "Video FPS:  30.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Running custom inference\n",
    "\"\"\"\n",
    "from custom_inference import run\n",
    "inferer = run.Custom_Infernce()\n",
    "\n",
    "# run inference on image(s) placed in custom_inference/samples\n",
    "inferer.run_image()\n",
    "\n",
    "# run inference on video placed in custom_inference/video_sample\n",
    "inferer.run_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weigths loaded successfully\n",
      "loading annotations into memory...\n",
      "Done (t=0.93s)\n",
      "creating index...\n",
      "index created!\n",
      "Current custom settings:  (0.5, 0.15, 'cuda:0')\n",
      "Done  100  runs\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total time of model:  3.1691508293151855\n",
      "Mean time model:  0.03169150829315186\n",
      "Total time of pre nms:  0.10195088386535645\n",
      "Mean time pre nms:  0.0010195088386535645\n",
      "Total time of nms:  0.3348081111907959\n",
      "Mean time nms:  0.003348081111907959\n",
      "Mean number of boxes processed by nms:  23.70\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total time taken:  3.605909824371338\n",
      "Percentage of model:  87.89\n",
      "Percentage of pre nms:  2.83\n",
      "Percentage of nms:  9.28\n",
      "---------------------------------\n",
      "Current custom settings:  (0.5, 0.15, 'cpu')\n",
      "Done  100  runs\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total time of model:  8.41919994354248\n",
      "Mean time model:  0.08419199943542481\n",
      "Total time of pre nms:  0.07995748519897461\n",
      "Mean time pre nms:  0.0007995748519897461\n",
      "Total time of nms:  0.3307921886444092\n",
      "Mean time nms:  0.003307921886444092\n",
      "Mean number of boxes processed by nms:  23.70\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total time taken:  8.829949617385864\n",
      "Percentage of model:  95.35\n",
      "Percentage of pre nms:  0.91\n",
      "Percentage of nms:  3.75\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Running a speed test\n",
    "\"\"\"\n",
    "from custom_inference import speed_test\n",
    "\n",
    "# runs on the first 100 images of the COCO validation set\n",
    "speed = speed_test.Speed_testing(runs=100, print_each_run=False)\n",
    "\n",
    "# nms threshold, conf_threshold, device\n",
    "speed.speed_test((0.5, 0.15, \"cuda:0\"))\n",
    "print(\"---------------------------------\")\n",
    "speed.speed_test((0.5, 0.15, \"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
